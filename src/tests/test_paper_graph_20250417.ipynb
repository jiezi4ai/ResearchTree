{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1e2a84a",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fac205",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a8b0d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from typing import List, Dict, Optional, Union, Tuple, Literal # Added Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d23ce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "453dbfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph.paper_graph import PaperGraph\n",
    "from graph.graph_viz import GraphViz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e13e6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_evolution = {}\n",
    "\n",
    "graph_stats = {}\n",
    "\n",
    "similarity_threshold = 0.7\n",
    "top_k_similar_papers = 20\n",
    "similar_papers = {}\n",
    "\n",
    "top_l_key_authors = 20\n",
    "key_authors = {}\n",
    "\n",
    "crossref_papers = {}\n",
    "top_m_corssref_papers = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "717ecc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "candit_edges_pool = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08bf45ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# driving examples\n",
    "llm_api_key = os.getenv('GEMINI_API_KEY_3')\n",
    "llm_model_name=\"gemini-2.0-flash\"\n",
    "embed_api_key = os.getenv('GEMINI_API_KEY_3')\n",
    "embed_model_name=\"models/text-embedding-004\"\n",
    "\n",
    "research_topic = \"llm literature review\"\n",
    "seed_dois = ['10.48550/arXiv.2406.10252',  # AutoSurvey: Large Language Models Can Automatically Write Surveys\n",
    "            '10.48550/arXiv.2412.10415',  # Generative Adversarial Reviews: When LLMs Become the Critic\n",
    "            '10.48550/arXiv.2402.12928',  # A Literature Review of Literature Reviews in Pattern Analysis and Machine Intelligence \n",
    "            ]\n",
    "seed_titles = ['PaperRobot: Incremental Draft Generation of Scientific Ideas',\n",
    "            'From Hypothesis to Publication: A Comprehensive Survey of AI-Driven Research Support Systems'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1be897f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def get_graph_stats(graph):\n",
    "    \"\"\"basic stats for graph\"\"\"\n",
    "    graph_stats = {}\n",
    "    graph_stats['node_cnt'] = len(graph.nodes)\n",
    "    graph_stats['edge_cnt'] = len(graph.edges)\n",
    "    print(f\"Graph has {len(graph.nodes)} nodes and {len(graph.edges)} edges.\")\n",
    "\n",
    "    # check node types\n",
    "    node_types = [node_data.get('nodeType') for _, node_data in graph.nodes(data=True)]\n",
    "    node_types_cnt = Counter(node_types)\n",
    "    sorted_node_counts = node_types_cnt.most_common()  # rank order by descending\n",
    "    graph_stats['node_type'] = sorted_node_counts  # format like [(node type, nodes count), ...]\n",
    "    print(f\"There are {len(sorted_node_counts)} node types in this graph, they are:\\n{sorted_node_counts}\")\n",
    "\n",
    "    # check edge types\n",
    "    edge_types = [d.get('relationshipType') for _, _, d in graph.edges(data=True)]\n",
    "    edge_types_cnt = Counter(edge_types)\n",
    "    sorted_egdes_counts = edge_types_cnt.most_common()  # rank order by descending\n",
    "    graph_stats['edge_type'] = sorted_egdes_counts  # format like [(node type, nodes count), ...]\n",
    "    print(f\"There are {len(sorted_egdes_counts)} edge types in this graph, they are:\\n{sorted_egdes_counts}\")\n",
    "\n",
    "    return graph_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f612429a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paper_stats(graph, seed_paper_dois):\n",
    "    \"\"\"get paper statistic in paper graph\"\"\"\n",
    "    papers_stats = []\n",
    "    for nid, node_data in graph.nodes(data=True):\n",
    "        if node_data.get('nodeType') == 'Paper':\n",
    "            # paper infos\n",
    "            title = graph.nodes[nid].get('title')\n",
    "            in_seed = True if nid in seed_paper_dois else False\n",
    "            overall_cite_cnt = node_data.get('citationCount')\n",
    "            overall_inf_cite_cnt = node_data.get('influentialCitationCount')\n",
    "            overall_ref_cnt = node_data.get('influentialCitationCount')\n",
    "\n",
    "            # for in edges\n",
    "            in_edges_info = graph.in_edges(nid, data=True)\n",
    "            local_citation_cnt = 0  # local paper graph cites papers (other cites this one)\n",
    "            sim_cnt_1 = 0  # local paper graph similar papers to this one\n",
    "            max_sim_to_seed_1 = -1  # max similarity of this paper to seed papers\n",
    "            for u, _, edge_data in in_edges_info:\n",
    "                if edge_data.get('relationshipType') == 'CITES':\n",
    "                    local_citation_cnt += 1\n",
    "                elif edge_data.get('relationshipType') == 'SIMILAR_TO':\n",
    "                    sim_cnt_1 += 1\n",
    "                    if u in seed_paper_dois:\n",
    "                        if edge_data.get('weight') > max_sim_to_seed_1:\n",
    "                            max_sim_to_seed_1 = edge_data.get('weight')\n",
    "\n",
    "            # for out edges\n",
    "            out_edges_info = graph.out_edges(nid, data=True)\n",
    "            local_ref_cnt = 0  # local paper graph cites papers (other cites this one)\n",
    "            sim_cnt_2 = 0  # local paper graph similar papers to this one\n",
    "            max_sim_to_seed_2 = -1  # max similarity of this paper to seed papers\n",
    "            for _, v, edge_data in out_edges_info:\n",
    "                if edge_data.get('relationshipType') == 'CITES':\n",
    "                    local_ref_cnt += 1\n",
    "                elif edge_data.get('relationshipType') == 'SIMILAR_TO':\n",
    "                    sim_cnt_2 += 1\n",
    "                    if v in seed_paper_dois:\n",
    "                        if edge_data.get('weight') > max_sim_to_seed_2:\n",
    "                            max_sim_to_seed_2 = edge_data.get('weight')\n",
    "\n",
    "            # author infors\n",
    "            author_ids_lst = [x['authorId'] for x in node_data.get('authors', []) if x.get('authorId') is not None]\n",
    "            tot_author_cnt = len(author_ids_lst)\n",
    "\n",
    "            # get author order and h-index\n",
    "            h_index_lst, author_order_lst = [], []\n",
    "            for idx, aid in enumerate(author_ids_lst):\n",
    "                author_order = idx + 1\n",
    "                h_index = graph.nodes[aid].get('hIndex')\n",
    "                if h_index is not None:\n",
    "                    h_index_lst.append(h_index)\n",
    "                    author_order_lst.append(author_order)\n",
    "\n",
    "            if len(h_index_lst) > 0:\n",
    "                avg_h_index = np.average(h_index_lst)\n",
    "                weight_h_index = sum([x / y for x, y in zip(h_index_lst, author_order_lst)]) / len(h_index_lst)\n",
    "            else:\n",
    "                avg_h_index = None\n",
    "                weight_h_index = None\n",
    "\n",
    "            paper_stats = {\"doi\":nid, \"title\":title, \"if_seed\": in_seed,\n",
    "                           \"local_citation_cnt\":local_citation_cnt, \"local_reference_cnt\": local_ref_cnt, \n",
    "                           \"local_similarity_cnt\":sim_cnt_1+sim_cnt_2, \"max_sim_to_seed\":max(max_sim_to_seed_1, max_sim_to_seed_2),\n",
    "                           \"global_citaion_cnt\":overall_cite_cnt, \"influencial_citation_cnt\":overall_inf_cite_cnt, \"global_refence_cnt\": overall_ref_cnt,\n",
    "                           \"author_cnt\":tot_author_cnt, \"avg_h_index\":avg_h_index, 'weighted_h_index':weight_h_index}\n",
    "            papers_stats.append(paper_stats)\n",
    "    return papers_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d77994c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_stats(graph, seed_author_ids):\n",
    "    \"\"\"get author statistic in paper graph\"\"\"\n",
    "\n",
    "    h_index_ref = {nid:node_data['hIndex'] for nid, node_data in graph.nodes(data=True) if node_data.get('nodeType') == 'Author' \n",
    "                   and node_data.get('hIndex') is not None}\n",
    "\n",
    "    authors_stats = []\n",
    "    for nid, node_data in graph.nodes(data=True):\n",
    "        if node_data.get('nodeType') == 'Author':\n",
    "            # properties\n",
    "            author_name = node_data.get('name')\n",
    "            h_index = node_data.get('hIndex')\n",
    "            in_seed = True if nid in seed_author_ids else False\n",
    "            global_paper_cnt = node_data.get('paperCount')\n",
    "            global_citation_cnt = node_data.get('citationCount')\n",
    "\n",
    "            # local stats\n",
    "            out_edges_info = graph.out_edges(nid, data=True)\n",
    "            local_paper_cnt = sum([1 for _, _, data in out_edges_info if data.get('relationshipType') == 'WRITES'])\n",
    "            # get coauthors\n",
    "            coauthor_ids = []\n",
    "            for u,v, edge_data in out_edges_info:\n",
    "                if edge_data.get('relationshipType') == 'WRITES':\n",
    "                    coauthors = edge_data.get('coauthors', [])\n",
    "                    coauthor_ids.extend([x['authorId'] for x in coauthors if x.get('authorId') is not None])\n",
    "            \n",
    "            # get top coauthors\n",
    "            coauthor_cnt = Counter(coauthor_ids)\n",
    "            top_coauthors = coauthor_cnt.most_common()[0:5]  # rank order by descending\n",
    "\n",
    "            # calculate top coauthor h-index\n",
    "            coauthor_cnt = 0\n",
    "            sum_coauthor_h_index = 0\n",
    "            for idx, item in enumerate(top_coauthors):\n",
    "                coauthor_id = item[0]\n",
    "                coauthor_hindex = h_index_ref.get(coauthor_id)\n",
    "                if coauthor_hindex is not None:\n",
    "                    sum_coauthor_h_index += coauthor_hindex /(idx + 1)\n",
    "                    coauthor_cnt += 1\n",
    "            weighted_coauthor_h_index = sum_coauthor_h_index / coauthor_cnt if coauthor_cnt > 0 else None\n",
    "\n",
    "            author_stat = {\"author_id\":nid, \"author_name\":author_name, \"is_seed\":in_seed,\n",
    "                           \"h_index\":h_index, \"global_paper_cnt\":global_paper_cnt, \"global_citation_cnt\":global_citation_cnt,\n",
    "                           \"local_paper_cnt\":local_paper_cnt, \n",
    "                           \"top_coauthors\":top_coauthors, \"weighted_coauthor_h_index\": weighted_coauthor_h_index\n",
    "                          }\n",
    "            authors_stats.append(author_stat)\n",
    "    return authors_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "330530e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from typing import List, Dict, Union, List, Set, Tuple, Hashable, Literal, Optional\n",
    "\n",
    "NodeType = Hashable # 节点类型通常是可哈希的\n",
    "\n",
    "def find_wcc_subgraphs(\n",
    "    graph,\n",
    "    target_nodes: Union[NodeType, List[NodeType], Set[NodeType], Tuple[NodeType]]\n",
    ") -> List[nx.MultiDiGraph]:\n",
    "    \"\"\"查找包含一个或多个指定节点的弱连通分量对应的子图。\n",
    "    Args:\n",
    "        graph: NetworkX MultiDiGraph 图对象。\n",
    "        target_nodes: 一个节点 ID，或一个包含节点 ID 的列表、集合或元组。\n",
    "    Returns:\n",
    "        一个包含所有找到的弱连通分量子图 (作为独立的 MultiDiGraph 副本) 的列表。\n",
    "        如果目标节点不在图中或找不到对应的连通分量，则返回空列表。\n",
    "        注意：如果多个目标节点在同一个连通分量中，该分量的子图只会被返回一次。\n",
    "    \"\"\"\n",
    "    # 1. 标准化输入为集合\n",
    "    if isinstance(target_nodes, (list, set, tuple)):\n",
    "        target_nodes_set = set(target_nodes)\n",
    "    else:\n",
    "        # 假设是单个节点 ID\n",
    "        target_nodes_set = {target_nodes}\n",
    "\n",
    "    # 2. 检查所有目标节点是否存在于图中\n",
    "    missing_nodes = target_nodes_set - set(graph.nodes())\n",
    "    if missing_nodes:\n",
    "        print(f\"警告：以下目标节点不在图中，将被忽略: {missing_nodes}\")\n",
    "        target_nodes_set -= missing_nodes # 移除不存在的节点\n",
    "\n",
    "    if not target_nodes_set:\n",
    "        print(\"错误：没有有效的目标节点可供查找。\")\n",
    "        return []\n",
    "\n",
    "    # 3. 查找并收集包含任何目标节点的弱连通分量\n",
    "    found_subgraphs = []\n",
    "    found_components_nodes = set() # 用于跟踪已添加的分量的节点集，避免重复\n",
    "\n",
    "    for component_nodes in nx.weakly_connected_components(graph):\n",
    "        component_set = set(component_nodes)\n",
    "        # 4. 检查当前分量是否包含任何目标节点 (使用集合交集)\n",
    "        if not target_nodes_set.isdisjoint(component_set): # 如果交集非空\n",
    "            # 检查这个分量是否已经添加过 (基于其节点集合)\n",
    "            # frozenset 是可哈希的，可以放入集合中\n",
    "            component_frozenset = frozenset(component_set)\n",
    "            if component_frozenset not in found_components_nodes:\n",
    "                # 5. 提取子图并添加到结果列表\n",
    "                subgraph = graph.subgraph(component_nodes).copy()\n",
    "                found_subgraphs.append(subgraph)\n",
    "                found_components_nodes.add(component_frozenset)\n",
    "\n",
    "                # Optional: 如果我们确定一个目标节点只能属于一个WCC,\n",
    "                # 可以在这里从 target_nodes_set 中移除 component_set 里的目标节点\n",
    "                # 以可能稍微提高后续迭代的效率，但这通常不是必需的\n",
    "                # target_nodes_set -= component_set\n",
    "\n",
    "    return found_subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25569669",
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_limit = 100\n",
    "\n",
    "if len(seed_dois) < 10 or len(seed_titles) < 10:\n",
    "    search_limit = 100\n",
    "    recommend_limit = 100\n",
    "else:\n",
    "    search_limit = 50\n",
    "    recommend_limit = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47f42628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/jiezi4ai/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from paper_extension import PaperCollector\n",
    "\n",
    "ps = PaperCollector(   \n",
    "    research_topic = research_topic,   \n",
    "    seed_paper_titles = seed_titles, \n",
    "    seed_paper_dois = seed_dois,\n",
    "    llm_api_key = llm_api_key,\n",
    "    llm_model_name = llm_model_name,\n",
    "    embed_api_key = embed_api_key,\n",
    "    embed_model_name = embed_model_name,\n",
    "    from_dt = '2020-01-01',\n",
    "    to_dt = '2025-04-30',\n",
    "    fields_of_study = ['Computer Science'],\n",
    "    search_limit = search_limit,\n",
    "    recommend_limit = recommend_limit,\n",
    "    citation_limit = citation_limit\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052cef30",
   "metadata": {},
   "source": [
    "## Initial Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f90f455",
   "metadata": {},
   "outputs": [],
   "source": [
    "round = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16184e2b",
   "metadata": {},
   "source": [
    "### Data Geneeration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8c9f8d",
   "metadata": {},
   "source": [
    "It may take 30 seconds to 2 mins to complete data generation task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b6dc0a",
   "metadata": {},
   "source": [
    "How to get user actively invovled?  \n",
    "- a progress bar?\n",
    "- showing realtime progress? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "110521a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 14:42:29,106 - INFO - SemanticScholarKit initialized with max_concurrency=10, sleep_interval=3.0s\n",
      "2025-04-21 14:42:29,107 - INFO - Fetching papers by 3 DOIs...\n",
      "2025-04-21 14:42:29,108 - INFO - Fetching papers by title: 'PaperRobot: Incremental Draft Generation of Scientific Ideas...'\n",
      "2025-04-21 14:42:29,108 - INFO - Fetching papers by title: 'From Hypothesis to Publication: A Comprehensive Survey of AI-Driven Research Support Systems...'\n",
      "2025-04-21 14:42:29,109 - INFO - Fetching papers by topic: 'llm literature review...'\n",
      "2025-04-21 14:42:29,110 - INFO - Running 4 initial query tasks concurrently...\n",
      "2025-04-21 14:42:29,111 - INFO - async_search_paper_by_ids: Creating 1 tasks for 3 IDs.\n",
      "2025-04-21 14:42:29,112 - INFO - async_search_paper_by_ids: Gathering 1 tasks...\n",
      "2025-04-21 14:42:29,113 - INFO - async_search_paper_by_keywords: Searching papers by keyword: 'PaperRobot: Incremental Draft Generation of Scient...' with effective limit 100.\n",
      "2025-04-21 14:42:29,114 - INFO - _sync_search_paper_by_keywords: Thread started for query 'PaperRobot: Incremental Draft Generation of Scient...' with limit 100.\n",
      "2025-04-21 14:42:29,114 - INFO - async_search_paper_by_keywords: Searching papers by keyword: 'From Hypothesis to Publication: A Comprehensive Su...' with effective limit 100.\n",
      "2025-04-21 14:42:29,117 - INFO - _sync_search_paper_by_keywords: Thread started for query 'From Hypothesis to Publication: A Comprehensive Su...' with limit 100.\n",
      "2025-04-21 14:42:29,117 - INFO - async_search_paper_by_keywords: Searching papers by keyword: 'llm literature review...' with effective limit 100.\n",
      "2025-04-21 14:42:29,119 - INFO - _sync_search_paper_by_keywords: Thread started for query 'llm literature review...' with limit 100.\n",
      "2025-04-21 14:42:29,120 - INFO - _sync_get_papers: Thread started for batch (3 IDs, first 5: ['10.48550/arXiv.2406.10252', '10.48550/arXiv.2412.10415', '10.48550/arXiv.2402.12928']...).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Initial Query for Seed Papers Information ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 14:42:30,281 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=llm%20literature%20review&fields=abstract,authors,citationCount,citationStyles,corpusId,externalIds,fieldsOfStudy,influentialCitationCount,isOpenAccess,journal,openAccessPdf,paperId,publicationDate,publicationTypes,publicationVenue,referenceCount,s2FieldsOfStudy,title,url,venue,year&offset=0&limit=100 \"HTTP/1.1 429 \"\n",
      "2025-04-21 14:42:30,330 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=From%20Hypothesis%20to%20Publication:%20A%20Comprehensive%20Survey%20of%20AI-Driven%20Research%20Support%20Systems&fields=abstract,authors,citationCount,citationStyles,corpusId,externalIds,fieldsOfStudy,influentialCitationCount,isOpenAccess,journal,openAccessPdf,paperId,publicationDate,publicationTypes,publicationVenue,referenceCount,s2FieldsOfStudy,title,url,venue,year&offset=0&limit=100 \"HTTP/1.1 429 \"\n",
      "2025-04-21 14:42:30,449 - INFO - HTTP Request: POST https://api.semanticscholar.org/graph/v1/paper/batch?fields=abstract,authors,citationCount,citationStyles,corpusId,externalIds,fieldsOfStudy,influentialCitationCount,isOpenAccess,journal,openAccessPdf,paperId,publicationDate,publicationTypes,publicationVenue,referenceCount,s2FieldsOfStudy,title,url,venue,year \"HTTP/1.1 200 OK\"\n",
      "2025-04-21 14:42:30,452 - INFO - _sync_get_papers: API call successful for batch (first 5: ['10.48550/arXiv.2406.10252', '10.48550/arXiv.2412.10415', '10.48550/arXiv.2402.12928']...), returning 3 items.\n",
      "2025-04-21 14:42:30,453 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=PaperRobot:%20Incremental%20Draft%20Generation%20of%20Scientific%20Ideas&fields=abstract,authors,citationCount,citationStyles,corpusId,externalIds,fieldsOfStudy,influentialCitationCount,isOpenAccess,journal,openAccessPdf,paperId,publicationDate,publicationTypes,publicationVenue,referenceCount,s2FieldsOfStudy,title,url,venue,year&offset=0&limit=100 \"HTTP/1.1 200 OK\"\n",
      "2025-04-21 14:42:30,455 - INFO - _sync_search_paper_by_keywords: API call successful for query 'PaperRobot: Incremental Draft Generation of Scient...', returning 1 items.\n",
      "2025-04-21 14:42:33,454 - INFO - async_search_paper_by_ids: Gather complete. Processing results.\n",
      "2025-04-21 14:43:01,050 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=llm%20literature%20review&fields=abstract,authors,citationCount,citationStyles,corpusId,externalIds,fieldsOfStudy,influentialCitationCount,isOpenAccess,journal,openAccessPdf,paperId,publicationDate,publicationTypes,publicationVenue,referenceCount,s2FieldsOfStudy,title,url,venue,year&offset=0&limit=100 \"HTTP/1.1 429 \"\n",
      "2025-04-21 14:43:01,366 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=From%20Hypothesis%20to%20Publication:%20A%20Comprehensive%20Survey%20of%20AI-Driven%20Research%20Support%20Systems&fields=abstract,authors,citationCount,citationStyles,corpusId,externalIds,fieldsOfStudy,influentialCitationCount,isOpenAccess,journal,openAccessPdf,paperId,publicationDate,publicationTypes,publicationVenue,referenceCount,s2FieldsOfStudy,title,url,venue,year&offset=0&limit=100 \"HTTP/1.1 200 OK\"\n",
      "2025-04-21 14:43:01,371 - INFO - _sync_search_paper_by_keywords: API call successful for query 'From Hypothesis to Publication: A Comprehensive Su...', returning 3 items.\n",
      "2025-04-21 14:43:33,245 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=llm%20literature%20review&fields=abstract,authors,citationCount,citationStyles,corpusId,externalIds,fieldsOfStudy,influentialCitationCount,isOpenAccess,journal,openAccessPdf,paperId,publicationDate,publicationTypes,publicationVenue,referenceCount,s2FieldsOfStudy,title,url,venue,year&offset=0&limit=100 \"HTTP/1.1 200 OK\"\n",
      "2025-04-21 14:43:34,759 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=llm%20literature%20review&fields=abstract,authors,citationCount,citationStyles,corpusId,externalIds,fieldsOfStudy,influentialCitationCount,isOpenAccess,journal,openAccessPdf,paperId,publicationDate,publicationTypes,publicationVenue,referenceCount,s2FieldsOfStudy,title,url,venue,year&offset=100&limit=100 \"HTTP/1.1 429 \"\n",
      "2025-04-21 14:44:05,825 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=llm%20literature%20review&fields=abstract,authors,citationCount,citationStyles,corpusId,externalIds,fieldsOfStudy,influentialCitationCount,isOpenAccess,journal,openAccessPdf,paperId,publicationDate,publicationTypes,publicationVenue,referenceCount,s2FieldsOfStudy,title,url,venue,year&offset=100&limit=100 \"HTTP/1.1 429 \"\n",
      "2025-04-21 14:44:36,616 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=llm%20literature%20review&fields=abstract,authors,citationCount,citationStyles,corpusId,externalIds,fieldsOfStudy,influentialCitationCount,isOpenAccess,journal,openAccessPdf,paperId,publicationDate,publicationTypes,publicationVenue,referenceCount,s2FieldsOfStudy,title,url,venue,year&offset=100&limit=100 \"HTTP/1.1 429 \"\n",
      "2025-04-21 14:45:08,623 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=llm%20literature%20review&fields=abstract,authors,citationCount,citationStyles,corpusId,externalIds,fieldsOfStudy,influentialCitationCount,isOpenAccess,journal,openAccessPdf,paperId,publicationDate,publicationTypes,publicationVenue,referenceCount,s2FieldsOfStudy,title,url,venue,year&offset=100&limit=100 \"HTTP/1.1 200 OK\"\n",
      "2025-04-21 14:45:09,400 - INFO - _sync_search_paper_by_keywords: API call successful for query 'llm literature review...', returning 100 items.\n",
      "2025-04-21 14:45:12,434 - INFO - Graph state after initial search tasks. Nodes: 664, Edges: 574\n"
     ]
    }
   ],
   "source": [
    "# --- INITIAL QUERY on SEED ---\n",
    "# initial query for seed papers basic information\n",
    "print(\"--- Running Initial Query for Seed Papers Information ---\")\n",
    "await ps.init_search(\n",
    "    research_topic=ps.research_topic,\n",
    "    seed_paper_titles=ps.seed_paper_titles,\n",
    "    seed_paper_dois=ps.seed_paper_dois,\n",
    "    round=round,\n",
    "    search_limit=ps.search_limit,\n",
    "    from_dt=ps.from_dt,\n",
    "    to_dt=ps.to_dt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76440c6d",
   "metadata": {},
   "source": [
    "### Basic Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "537aecd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 27\n",
      "4 27\n"
     ]
    }
   ],
   "source": [
    "# get seed DOIs\n",
    "seed_paper_dois = [node['id'] for node in ps.nodes_json if node['labels'] == ['Paper'] and node['properties'].get('from_seed')==True]\n",
    "seed_author_ids = []\n",
    "for node in ps.nodes_json:\n",
    "    if node['labels'] == ['Paper'] and node['properties'].get('from_seed')==True and isinstance(node['properties'].get('authors'), list):\n",
    "        authors_id = [x['authorId'] for x in node['properties']['authors'] if x['authorId'] is not None] \n",
    "        seed_author_ids.extend(authors_id)\n",
    "seed_paper_json = [node for node in ps.nodes_json if node['labels'] == ['Paper'] and node['properties'].get('from_seed')==True]\n",
    "\n",
    "print(len(seed_paper_dois), len(seed_author_ids))\n",
    "print(len(ps.seeds['paper']), len(ps.seeds['author']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66e3016c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph has 664 nodes and 574 edges.\n",
      "There are 4 node types in this graph, they are:\n",
      "[('Author', 459), ('Paper', 102), ('Journal', 56), ('Venue', 47)]\n",
      "There are 3 edge types in this graph, they are:\n",
      "[('WRITES', 464), ('PRINTS_ON', 59), ('RELEASES_IN', 51)]\n"
     ]
    }
   ],
   "source": [
    "# basic stats\n",
    "G_init = PaperGraph(name='Paper Graph Init Search')\n",
    "G_init.add_graph_nodes(ps.nodes_json)\n",
    "G_init.add_graph_edges(ps.edges_json)\n",
    "g_stat = get_graph_stats(G_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d6394eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'init_search' not in graph_stats.keys():\n",
    "    graph_stats['init_search'] = {}\n",
    "graph_stats['init_search']['wo_similarity'] = g_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce50db66",
   "metadata": {},
   "source": [
    "**Interactive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e42af0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have successfully captured 4 seed papers.\n",
      "I would recommend you further explore the following information:\n",
      "    - seed paper citation chain to trace reference and citing papers;\n",
      "    - seed paper authors to see if any related work\n",
      "    - let me recommend similar papers on the topic\n"
     ]
    }
   ],
   "source": [
    "print(f\"I have successfully captured {len(seed_paper_dois)} seed papers.\")\n",
    "print(\"\"\"I would recommend you further explore the following information:\n",
    "    - seed paper citation chain to trace reference and citing papers;\n",
    "    - seed paper authors to see if any related work\n",
    "    - let me recommend similar papers on the topic\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820e5972",
   "metadata": {},
   "source": [
    "### Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cc0e93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 14:45:29,319 - INFO - Generating embeddings for 94 papers...\n",
      "2025-04-21 14:45:37,603 - INFO - Shape of embeds_1: (94, 768)\n",
      "2025-04-21 14:45:37,603 - INFO - Shape of embeds_2: (94, 768)\n",
      "2025-04-21 14:45:37,603 - INFO - Calculating similarity matrix...\n",
      "2025-04-21 14:45:37,605 - INFO - Processing similarity matrix to create relationships...\n"
     ]
    }
   ],
   "source": [
    "# --- INTERMEDIATE: CALCULATE SIMILARITY ---\n",
    "# get all paper infos\n",
    "paper_nodes_json = [node for node in ps.nodes_json \n",
    "                    if node['labels'] == ['Paper'] and \n",
    "                    node['properties'].get('title') is not None and node['properties'].get('abstract') is not None]\n",
    "paper_dois = [node['id'] for node in paper_nodes_json]\n",
    "\n",
    "# calculate paper nodes similarity\n",
    "semantic_similar_pool = await ps.cal_embed_and_similarity(\n",
    "    paper_nodes_json=paper_nodes_json,\n",
    "    paper_dois_1=paper_dois, \n",
    "    paper_dois_2=paper_dois,\n",
    "    similarity_threshold=similarity_threshold,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc0e57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_json = semantic_similar_pool\n",
    "if type(edges_json) == dict:\n",
    "    edges_json = [edges_json]\n",
    "\n",
    "nx_edges_info = []\n",
    "for item in edges_json:\n",
    "    source_id = item['startNodeId']\n",
    "    target_id = item['endNodeId']\n",
    "    properties = item['properties']\n",
    "    properties['relationshipType'] = item['relationshipType']\n",
    "    # be aware that relationship shall take the form like (4, 5, dict(route=282)) for networkX\n",
    "    nx_edges_info.append((source_id, target_id, properties))  \n",
    "    item['dataGeneration'] = {'round': 1, 'source': 'init_search'}\n",
    "\n",
    "G_init.add_edges_from(nx_edges_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1a1730",
   "metadata": {},
   "source": [
    "### Filtering & Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bf8abd",
   "metadata": {},
   "source": [
    "Basic Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79b553b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph has 664 nodes and 1447 edges.\n",
      "There are 4 node types in this graph, they are:\n",
      "[('Author', 459), ('Paper', 102), ('Journal', 56), ('Venue', 47)]\n",
      "There are 4 edge types in this graph, they are:\n",
      "[('SIMILAR_TO', 873), ('WRITES', 464), ('PRINTS_ON', 59), ('RELEASES_IN', 51)]\n"
     ]
    }
   ],
   "source": [
    "# basic stats\n",
    "g_stat = get_graph_stats(G_init)\n",
    "graph_stats['init_search']['w_similarity'] = g_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6f29c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all paper infos\n",
    "paper_nodes_json = [node for node in ps.nodes_json \n",
    "                    if node['labels'] == ['Paper'] and \n",
    "                    node['properties'].get('title') is not None and node['properties'].get('abstract') is not None]\n",
    "paper_dois = [node['id'] for node in paper_nodes_json]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852d2314",
   "metadata": {},
   "source": [
    "Paper Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c4febe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now the paper does not have citation chain\n",
    "paper_stats = get_paper_stats(G_init, seed_paper_dois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c335c748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter similar papers to help build cross reference\n",
    "sorted_paper_similarity = sorted(paper_stats, key=lambda x:x['max_sim_to_seed'], reverse=True)\n",
    "\n",
    "candit_paper_dois = []\n",
    "filtered_papers_stats = []\n",
    "i = 0\n",
    "for x in sorted_paper_similarity:\n",
    "    if i < 20:\n",
    "        if (x['if_seed'] == False  # exclude seed papers \n",
    "            and x['local_similarity_cnt'] > (len(paper_dois) / 5)):  # select most similar to others\n",
    "            candit_paper_dois.append(x['doi'])\n",
    "            filtered_papers_stats.append(x)\n",
    "            i += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "similar_papers['init_search'] = filtered_papers_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c2c927",
   "metadata": {},
   "source": [
    "Author Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "774b5bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_stats = get_author_stats(G_init, seed_author_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e08a4828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'author_id': '2341358168', 'author_name': 'Dilani Wickramaarachchi', 'is_seed': False, 'h_index': None, 'global_paper_cnt': None, 'global_citation_cnt': None, 'local_paper_cnt': 2, 'top_coauthors': [('2341358168', 2)], 'weighted_coauthor_h_index': None}\n",
      "{'author_id': '74214430', 'author_name': 'R. Ślepaczuk', 'is_seed': False, 'h_index': None, 'global_paper_cnt': None, 'global_citation_cnt': None, 'local_paper_cnt': 2, 'top_coauthors': [('74214430', 2)], 'weighted_coauthor_h_index': None}\n",
      "{'author_id': '144992211', 'author_name': 'Shubham Agarwal', 'is_seed': False, 'h_index': None, 'global_paper_cnt': None, 'global_citation_cnt': None, 'local_paper_cnt': 2, 'top_coauthors': [('144992211', 2), ('3266173', 2), ('2275240361', 2), ('1778839', 1), ('2267339519', 1)], 'weighted_coauthor_h_index': None}\n",
      "{'author_id': '3266173', 'author_name': 'I. Laradji', 'is_seed': False, 'h_index': None, 'global_paper_cnt': None, 'global_citation_cnt': None, 'local_paper_cnt': 2, 'top_coauthors': [('3266173', 2), ('2275240361', 2), ('1778839', 1), ('144992211', 1), ('2267339519', 1)], 'weighted_coauthor_h_index': None}\n",
      "{'author_id': '2275240361', 'author_name': 'Christopher Pal', 'is_seed': False, 'h_index': None, 'global_paper_cnt': None, 'global_citation_cnt': None, 'local_paper_cnt': 2, 'top_coauthors': [('144992211', 2), ('3266173', 2), ('2275240361', 2), ('2267339519', 1), ('2310436656', 1)], 'weighted_coauthor_h_index': None}\n",
      "{'author_id': '2087834161', 'author_name': 'Gregg A. Steven', 'is_seed': False, 'h_index': None, 'global_paper_cnt': None, 'global_citation_cnt': None, 'local_paper_cnt': 1, 'top_coauthors': [('2087834161', 1), ('2116018412', 1), ('32267793', 1), ('14259133', 1)], 'weighted_coauthor_h_index': None}\n",
      "{'author_id': '2116018412', 'author_name': 'Tony Nguyen', 'is_seed': False, 'h_index': None, 'global_paper_cnt': None, 'global_citation_cnt': None, 'local_paper_cnt': 1, 'top_coauthors': [('2116018412', 1), ('32267793', 1), ('14259133', 1)], 'weighted_coauthor_h_index': None}\n",
      "{'author_id': '32267793', 'author_name': 'Rachel C. Lerner', 'is_seed': False, 'h_index': None, 'global_paper_cnt': None, 'global_citation_cnt': None, 'local_paper_cnt': 1, 'top_coauthors': [('2087834161', 1), ('32267793', 1), ('14259133', 1)], 'weighted_coauthor_h_index': None}\n",
      "{'author_id': '14259133', 'author_name': 'Phill Jo', 'is_seed': False, 'h_index': None, 'global_paper_cnt': None, 'global_citation_cnt': None, 'local_paper_cnt': 1, 'top_coauthors': [('2087834161', 1), ('2116018412', 1), ('14259133', 1)], 'weighted_coauthor_h_index': None}\n",
      "{'author_id': '2053882660', 'author_name': 'Mark A. James', 'is_seed': False, 'h_index': None, 'global_paper_cnt': None, 'global_citation_cnt': None, 'local_paper_cnt': 1, 'top_coauthors': [('2053882660', 1), ('6659909', 1), ('2100698939', 1), ('145003479', 1), ('2070068981', 1)], 'weighted_coauthor_h_index': None}\n",
      "{'author_id': '6659909', 'author_name': 'T. Mendo', 'is_seed': False, 'h_index': None, 'global_paper_cnt': None, 'global_citation_cnt': None, 'local_paper_cnt': 1, 'top_coauthors': [('6659909', 1), ('2100698939', 1), ('145003479', 1), ('2070068981', 1), ('2133682792', 1)], 'weighted_coauthor_h_index': None}\n",
      "{'author_id': '2100698939', 'author_name': 'F. Spoors', 'is_seed': False, 'h_index': None, 'global_paper_cnt': None, 'global_citation_cnt': None, 'local_paper_cnt': 1, 'top_coauthors': [('2053882660', 1), ('2100698939', 1), ('145003479', 1), ('2070068981', 1), ('2133682792', 1)], 'weighted_coauthor_h_index': None}\n",
      "{'author_id': '145003479', 'author_name': 'René J. Swift', 'is_seed': False, 'h_index': None, 'global_paper_cnt': None, 'global_citation_cnt': None, 'local_paper_cnt': 1, 'top_coauthors': [('2053882660', 1), ('6659909', 1), ('145003479', 1), ('2070068981', 1), ('2133682792', 1)], 'weighted_coauthor_h_index': None}\n",
      "{'author_id': '2070068981', 'author_name': 'P. McCann', 'is_seed': False, 'h_index': None, 'global_paper_cnt': None, 'global_citation_cnt': None, 'local_paper_cnt': 1, 'top_coauthors': [('2053882660', 1), ('6659909', 1), ('2100698939', 1), ('2070068981', 1), ('2133682792', 1)], 'weighted_coauthor_h_index': None}\n",
      "{'author_id': '2133682792', 'author_name': 'S. Crowe', 'is_seed': False, 'h_index': None, 'global_paper_cnt': None, 'global_citation_cnt': None, 'local_paper_cnt': 1, 'top_coauthors': [('2053882660', 1), ('6659909', 1), ('2100698939', 1), ('145003479', 1), ('2133682792', 1)], 'weighted_coauthor_h_index': None}\n",
      "{'author_id': '119755364', 'author_name': 'Anna Mujal', 'is_seed': False, 'h_index': None, 'global_paper_cnt': None, 'global_citation_cnt': None, 'local_paper_cnt': 1, 'top_coauthors': [('2053882660', 1), ('6659909', 1), ('2100698939', 1), ('145003479', 1), ('2070068981', 1)], 'weighted_coauthor_h_index': None}\n",
      "{'author_id': '2190052368', 'author_name': 'Colilles', 'is_seed': False, 'h_index': None, 'global_paper_cnt': None, 'global_citation_cnt': None, 'local_paper_cnt': 1, 'top_coauthors': [('2053882660', 1), ('6659909', 1), ('2100698939', 1), ('145003479', 1), ('2070068981', 1)], 'weighted_coauthor_h_index': None}\n",
      "{'author_id': '31727676', 'author_name': 'Lachlan McGinness', 'is_seed': False, 'h_index': None, 'global_paper_cnt': None, 'global_citation_cnt': None, 'local_paper_cnt': 1, 'top_coauthors': [('31727676', 1), ('2303557186', 1), ('2282414081', 1), ('2282412592', 1)], 'weighted_coauthor_h_index': None}\n",
      "{'author_id': '2303557186', 'author_name': 'Peter Baumgartner', 'is_seed': False, 'h_index': None, 'global_paper_cnt': None, 'global_citation_cnt': None, 'local_paper_cnt': 1, 'top_coauthors': [('2303557186', 1), ('2282414081', 1), ('2282412592', 1)], 'weighted_coauthor_h_index': None}\n",
      "{'author_id': '2282414081', 'author_name': 'Esther Onyango', 'is_seed': False, 'h_index': None, 'global_paper_cnt': None, 'global_citation_cnt': None, 'local_paper_cnt': 1, 'top_coauthors': [('31727676', 1), ('2282414081', 1), ('2282412592', 1)], 'weighted_coauthor_h_index': None}\n"
     ]
    }
   ],
   "source": [
    "sorted_author_writes = sorted(author_stats, key=lambda x:x['local_paper_cnt'], reverse=True)\n",
    "filtered_authors = [x for x in sorted_author_writes if x['is_seed'] == False][0:top_l_key_authors]\n",
    "for item in filtered_authors:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c45ba6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_authors['init_search'] = filtered_authors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee1ef95",
   "metadata": {},
   "source": [
    "### Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef3656d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_graphs = find_wcc_subgraphs(graph=G_init, target_nodes=seed_dois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40df15ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph has 552 nodes and 1352 edges.\n",
      "There are 4 node types in this graph, they are:\n",
      "[('Author', 384), ('Paper', 87), ('Journal', 44), ('Venue', 37)]\n",
      "There are 4 edge types in this graph, they are:\n",
      "[('SIMILAR_TO', 873), ('WRITES', 389), ('PRINTS_ON', 48), ('RELEASES_IN', 42)]\n"
     ]
    }
   ],
   "source": [
    "g_stat = get_graph_stats(sub_graphs[0])\n",
    "graph_stats['init_search']['after_pruning'] = g_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7a453b",
   "metadata": {},
   "source": [
    "### Graph Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9235a857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from graph.graph_viz import GraphViz\n",
    "viz = GraphViz(G_init, 'Paper Graph After Init Search')\n",
    "viz.preprocessing()\n",
    "viz.visulization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1beb59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from graph.graph_viz import GraphViz\n",
    "viz = GraphViz(sub_graphs[0], 'Paper Graph After Init Search - after prunning')\n",
    "viz.preprocessing()\n",
    "viz.visulization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2105dadc",
   "metadata": {},
   "source": [
    "## Basic Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b137be30",
   "metadata": {},
   "source": [
    "Search for more related information based on seed papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68adbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume user want to continue with citation chain, author and recommendations\n",
    "search_citation = 'both'\n",
    "search_author = True\n",
    "find_recommend = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d42cbe",
   "metadata": {},
   "source": [
    "Based on current status (# of nodes and authors) to decide search limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be062548",
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_limit = 100\n",
    "\n",
    "if len(seed_dois) > 20 or len(seed_titles) > 20 or len(paper_dois) > 100:\n",
    "    search_limit = 50\n",
    "    recommend_limit = 50\n",
    "else :\n",
    "    search_limit = 100\n",
    "    recommend_limit = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29ef8e4",
   "metadata": {},
   "source": [
    "### Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0f3be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MORE INFORMATION on SEED ---\n",
    "print(\"--- Getting More Information Related to Seed Papers ---\")\n",
    "# basic search for seed papers\n",
    "# may include seed paper authors, seed paper citation chain, recommendations based on seed papers \n",
    "await ps.paper_search(\n",
    "    seed_paper_dois=seed_paper_dois,\n",
    "    seed_author_ids=seed_author_ids,\n",
    "    search_citation = search_citation,\n",
    "    search_author = search_author,\n",
    "    round = 1,\n",
    "    find_recommend = find_recommend,\n",
    "    recommend_limit = recommend_limit,\n",
    "    citation_limit = citation_limit,\n",
    "    from_dt=ps.from_dt,\n",
    "    to_dt=ps.to_dt,\n",
    "    fields_of_study = ps.fields_of_study,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17544fd",
   "metadata": {},
   "source": [
    "### Basic Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b14ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic stats\n",
    "G = PaperGraph(name='Paper Graph Basic Search')\n",
    "G.add_graph_nodes(ps.nodes_json)\n",
    "G.add_graph_edges(ps.edges_json)\n",
    "\n",
    "g_stat = get_graph_stats(G)\n",
    "graph_stats['basic_search'] = {}\n",
    "graph_stats['basic_search']['wo_similarity'] = g_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75d6e55",
   "metadata": {},
   "source": [
    "### Calculate Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a047e60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- INTERMEDIATE: CALCULATE SIMILARITY ---\n",
    "# get all paper infos\n",
    "paper_nodes_json = [node for node in ps.nodes_json \n",
    "                    if node['labels'] == ['Paper'] and \n",
    "                    node['properties'].get('title') is not None and node['properties'].get('abstract') is not None]\n",
    "paper_dois = [node['id'] for node in paper_nodes_json]\n",
    "\n",
    "# calculate paper nodes similarity\n",
    "semantic_similar_pool = await ps.cal_embed_and_similarity(\n",
    "    paper_nodes_json=paper_nodes_json,\n",
    "    paper_dois_1=paper_dois, \n",
    "    paper_dois_2=paper_dois,\n",
    "    similarity_threshold=similarity_threshold,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de91e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_json = semantic_similar_pool\n",
    "if type(edges_json) == dict:\n",
    "    edges_json = [edges_json]\n",
    "\n",
    "nx_edges_info = []\n",
    "for item in edges_json:\n",
    "    source_id = item['startNodeId']\n",
    "    target_id = item['endNodeId']\n",
    "    properties = item['properties']\n",
    "    properties['relationshipType'] = item['relationshipType']\n",
    "    nx_edges_info.append((source_id, target_id, properties))  \n",
    "    item['dataGeneration'] = {'round': 1, 'source': 'init_search'}\n",
    "\n",
    "G.add_edges_from(nx_edges_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655e8848",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_stat = get_graph_stats(G)\n",
    "graph_stats['basic_search']['w_similarity'] = g_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9e5b63",
   "metadata": {},
   "source": [
    "### Filtering & Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89143013",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_stats = get_paper_stats(G, seed_paper_dois)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f94e49",
   "metadata": {},
   "source": [
    "Paper By Local References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54df825",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_paper_similarity = sorted(paper_stats, key=lambda x:x['local_citation_cnt'], reverse=True)\n",
    "filtered_papers_stats = [x for x in sorted_paper_similarity if x['if_seed'] == False][0:top_m_corssref_papers]\n",
    "filtered_papers_dois = [x['doi'] for x in filtered_papers_stats]\n",
    "for item in filtered_papers_stats:\n",
    "    print(item)\n",
    "\n",
    "crossref_papers['basic_search'] = filtered_papers_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e77f86",
   "metadata": {},
   "source": [
    "Paper By Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7046857",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_paper_similarity = sorted(paper_stats, key=lambda x:x['local_similarity_cnt'], reverse=True)\n",
    "filtered_papers_stats = [x for x in sorted_paper_similarity if x['if_seed'] == False][0:100]\n",
    "filtered_papers_dois = [x['doi'] for x in filtered_papers_stats]\n",
    "for item in filtered_papers_stats:\n",
    "    print(item)\n",
    "\n",
    "crossref_papers['basic_search'] = filtered_papers_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd80a41",
   "metadata": {},
   "source": [
    "Author By Writes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4680c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_stats = get_author_stats(G, seed_author_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f165322f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_author_writes = sorted(author_stats, key=lambda x:x['local_paper_cnt'], reverse=True)\n",
    "filtered_authors = [x for x in sorted_author_writes if x['is_seed'] == False][0:top_l_key_authors]\n",
    "for item in filtered_authors:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dfbb2d",
   "metadata": {},
   "source": [
    "### Graph Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20c1c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from graph.graph_viz import GraphViz\n",
    "viz = GraphViz(G, 'Paper Graph After Init Search')\n",
    "viz.preprocessing()\n",
    "viz.visulization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62d8054",
   "metadata": {},
   "source": [
    "## Expanded Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76306d83",
   "metadata": {},
   "source": [
    "### Expand Citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a96906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossref_info = crossref_papers['basic_search']\n",
    "\n",
    "candit_crossref_cnt = 0 \n",
    "for item in crossref_info:\n",
    "    if item['local_citation_cnt'] > len(seed_dois):\n",
    "        candit_crossref_cnt += 1\n",
    "    else:\n",
    "        break\n",
    "print(candit_crossref_cnt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125303d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if_expanded_citations = 'reference' \n",
    "citation_limit = 100\n",
    "\n",
    "if candit_crossref_cnt > 10:\n",
    "    top_k_similar_papers = 20\n",
    "else:\n",
    "    top_k_similar_papers = 50\n",
    "\n",
    "candit_paper_dois = [x['doi'] for x in crossref_info][0:top_k_similar_papers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aa6903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- EXPAND to CITATIONS over SIMILAR PAPERS ---\n",
    "# get most similar papers to seed papers\n",
    "# track citation chain of these papers\n",
    "if if_expanded_citations is not None:\n",
    "    print(f\"\\n--- Get crossref papers: ---\")\n",
    "    await ps.citation_expansion(\n",
    "        seed_paper_dois = seed_paper_dois,\n",
    "        candit_paper_dois = candit_paper_dois,  # user input of candit paper dois to search for citations\n",
    "        search_citation = 'reference',\n",
    "        round = 1,\n",
    "        citation_limit = citation_limit,\n",
    "        from_dt = ps.from_dt,\n",
    "        to_dt = ps.to_dt,\n",
    "        fields_of_study = ps.fields_of_study,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16d9083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic stats\n",
    "G_citation = PaperGraph(name='Paper Graph After Citation Expansion')\n",
    "G_citation.add_graph_nodes(ps.nodes_json)\n",
    "G_citation.add_graph_edges(ps.edges_json)\n",
    "g_stat = get_graph_stats(G)\n",
    "\n",
    "graph_stats['expanded_search'] = {}\n",
    "graph_stats['expanded_search']['citation_expansion'] = g_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd8d75c",
   "metadata": {},
   "source": [
    "Filtering & Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de65684c",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_stats = get_paper_stats(G_citation, seed_paper_dois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05edaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_paper_similarity = sorted(paper_stats, key=lambda x:x['local_citation_cnt'], reverse=True)\n",
    "filtered_papers_stats = [x for x in sorted_paper_similarity if x['if_seed'] == False][0:top_m_corssref_papers]\n",
    "filtered_papers_dois = [x['doi'] for x in filtered_papers_stats]\n",
    "for item in filtered_papers_stats:\n",
    "    print(item)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade6280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossref_papers['expanded_search'] = filtered_papers_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90438604",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_stats = get_author_stats(G_citation, seed_author_ids)\n",
    "\n",
    "sorted_author_writes = sorted(author_stats, key=lambda x:x['local_paper_cnt'], reverse=True)\n",
    "filtered_authors = [x for x in sorted_author_writes if x['is_seed'] == False][0:100]\n",
    "for item in filtered_authors:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c362ddf6",
   "metadata": {},
   "source": [
    "### Expanded Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711dc437",
   "metadata": {},
   "source": [
    "Topic Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66231ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_topics_json = await ps.topic_generation(\n",
    "    seed_paper_json = seed_paper_json,\n",
    "    llm_api_key= ps.llm_api_key,\n",
    "    llm_model_name = ps.llm_model_name,\n",
    "    round = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da425f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_queries = [x for x in keywords_topics_json.get('queries', []) if x not in ps.explored_nodes['topic']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7842b124",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thefuzz import fuzz # pip install thefuzz  https://github.com/seatgeek/thefuzz\n",
    "ration_1 = fuzz.ratio('llm literature review', 'LLM for automated literature review'.lower())\n",
    "ration_2 = fuzz.ratio('llm literature review', 'AI assisted peer review'.lower())\n",
    "ration_3 = fuzz.ratio('llm literature review', 'AI support for scientific research'.lower())\n",
    "ration_4 = fuzz.ratio('llm literature review', 'evaluation of AI generated literature reviews'.lower())\n",
    "print(ration_1, ration_2, ration_3, ration_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1df412",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.explored_nodes['topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e33f5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4457442",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(paper_dois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c0fa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all paper infos\n",
    "paper_nodes_json = [node for node in ps.nodes_json \n",
    "                    if node['labels'] == ['Paper'] and \n",
    "                    node['properties'].get('title') is not None and node['properties'].get('abstract') is not None]\n",
    "paper_dois = [node['id'] for node in paper_nodes_json]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebe43fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(topic_queries) > 4 or len(paper_dois) > 1000:\n",
    "    search_limit = 50\n",
    "\n",
    "if_related_topic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bb5fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- EXPAND to RELATED TOPICS over SEED ---\n",
    "# get related topics based on abstracts of seed papers\n",
    "# search for related topics for more papers\n",
    "print(\"--- Extend Related Topics from Seed Papers ---\")\n",
    "if if_related_topic:\n",
    "    await ps.topic_extension(\n",
    "        candit_topic_queries = topic_queries,\n",
    "        round = 1,\n",
    "        search_limit = search_limit,\n",
    "        from_dt = ps.from_dt,\n",
    "        to_dt = ps.to_dt,\n",
    "        fields_of_study = ps.fields_of_study,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd0dea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- INTERMEDIATE: CALCULATE SIMILARITY ---\n",
    "# calculate paper nodes similarity\n",
    "semantic_similar_pool = await ps.cal_embed_and_similarity(\n",
    "    paper_nodes_json=paper_nodes_json,\n",
    "    paper_dois_1=paper_dois, \n",
    "    paper_dois_2=paper_dois,\n",
    "    similarity_threshold=similarity_threshold,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jiezi4ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
