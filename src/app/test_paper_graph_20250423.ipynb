{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad67f75e",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7766de8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from typing import List, Dict, Optional, Union, Tuple, Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "438adae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12cbac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph.paper_graph import PaperGraph\n",
    "from graph.graph_viz import GraphViz\n",
    "from app.paper_data_collect import PaperSearch\n",
    "from graph.graph_stats import get_graph_stats, get_author_stats, get_paper_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa3fc05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # params for paper collection\n",
    "    'search_limit': 100,\n",
    "    'recommend_limit': 50,\n",
    "    'citation_limit': 100,\n",
    "    # params for expanded search\n",
    "    'similarity_threshold': 0.7,\n",
    "    'top_k_similar_papers': 20,\n",
    "    'top_l_key_authors': 20,\n",
    "    # paprams for stopping criteria\n",
    "    'min_paper_cnt': 50,\n",
    "    'min_author_cnt': 50,\n",
    "    'min_corssref_papers': 20,\n",
    "    'min_key_authors': 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee40269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# driving examples\n",
    "llm_api_key = os.getenv('GEMINI_API_KEY_3')\n",
    "llm_model_name=\"gemini-2.0-flash\"\n",
    "embed_api_key = os.getenv('GEMINI_API_KEY_3')\n",
    "embed_model_name=\"models/text-embedding-004\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dccb29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from user input\n",
    "research_topics = [\"llm literature review\"]\n",
    "seed_dois = ['10.48550/arXiv.2406.10252',  # AutoSurvey: Large Language Models Can Automatically Write Surveys\n",
    "            '10.48550/arXiv.2412.10415',  # Generative Adversarial Reviews: When LLMs Become the Critic\n",
    "            '10.48550/arXiv.2402.12928',  # A Literature Review of Literature Reviews in Pattern Analysis and Machine Intelligence \n",
    "            ]\n",
    "seed_titles = ['PaperRobot: Incremental Draft Generation of Scientific Ideas',\n",
    "            'From Hypothesis to Publication: A Comprehensive Survey of AI-Driven Research Support Systems'\n",
    "            ]\n",
    "# constraints\n",
    "from_dt = '2020-01-01'\n",
    "to_dt = '2025-04-30'\n",
    "fields_of_study = ['Computer Science']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1e8a3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 17:15:03,852 - INFO - SemanticScholarKit initialized with max_concurrency=20, sleep_interval=3.0s\n",
      "2025-04-23 17:15:03,853 - INFO - SemanticScholarKit initialized with max_concurrency=20, sleep_interval=3.0s\n",
      "2025-04-23 17:15:03,854 - INFO - SemanticScholarKit initialized with max_concurrency=20, sleep_interval=3.0s\n",
      "2025-04-23 17:15:03,855 - INFO - SemanticScholarKit initialized with max_concurrency=20, sleep_interval=3.0s\n"
     ]
    }
   ],
   "source": [
    "ps = PaperSearch(   \n",
    "    seed_research_topics = research_topics,   \n",
    "    seed_paper_titles = seed_titles, \n",
    "    seed_paper_dois = seed_dois,\n",
    "    from_dt = from_dt,\n",
    "    to_dt = to_dt,\n",
    "    fields_of_study = fields_of_study,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f2e719",
   "metadata": {},
   "source": [
    "# Round 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d369e328",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 1\n",
    "citation_limit = 100\n",
    "recommend_limit = 100\n",
    "search_limit = 50\n",
    "\n",
    "from_dt = '2020-01-01'\n",
    "to_dt = '2025-04-30'\n",
    "fields_of_study = ['Computer Science']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d85d6a",
   "metadata": {},
   "source": [
    "## Initial Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9603246b",
   "metadata": {},
   "source": [
    "### Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595a6e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 17:15:08,391 - INFO - Search 1 topics, 2 paper titles and 3 for paper information.\n",
      "2025-04-23 17:15:08,392 - INFO - Fetching papers by 3 DOIs...\n",
      "2025-04-23 17:15:08,393 - INFO - Fetching papers by title: 'PaperRobot: Incremental Draft Generation of Scientific Ideas...'\n",
      "2025-04-23 17:15:08,394 - INFO - Fetching papers by title: 'From Hypothesis to Publication: A Comprehensive Survey of AI-Driven Research Support Systems...'\n",
      "2025-04-23 17:15:08,394 - INFO - Fetching papers by topic: 'llm literature review...'\n",
      "2025-04-23 17:15:08,395 - INFO - Running 4 initial query tasks concurrently...\n",
      "2025-04-23 17:15:08,397 - INFO - async_search_paper_by_ids: Creating 1 tasks for 3 IDs.\n",
      "2025-04-23 17:15:08,398 - INFO - async_search_paper_by_ids: Gathering 1 tasks...\n",
      "2025-04-23 17:15:08,398 - INFO - async_search_paper_by_keywords: Searching papers by keyword: 'PaperRobot: Incremental Draft Generation of Scient...' with effective limit 50.\n",
      "2025-04-23 17:15:08,399 - INFO - _sync_search_paper_by_keywords: Thread started for query 'PaperRobot: Incremental Draft Generation of Scient...' with limit 50.\n",
      "2025-04-23 17:15:08,399 - INFO - async_search_paper_by_keywords: Searching papers by keyword: 'From Hypothesis to Publication: A Comprehensive Su...' with effective limit 50.\n",
      "2025-04-23 17:15:08,402 - INFO - _sync_search_paper_by_keywords: Thread started for query 'From Hypothesis to Publication: A Comprehensive Su...' with limit 50.\n",
      "2025-04-23 17:15:08,403 - INFO - async_search_paper_by_keywords: Searching papers by keyword: 'llm literature review...' with effective limit 50.\n",
      "2025-04-23 17:15:08,404 - INFO - _sync_search_paper_by_keywords: Thread started for query 'llm literature review...' with limit 50.\n",
      "2025-04-23 17:15:08,406 - INFO - _sync_get_papers: Thread started for batch (3 IDs, first 5: ['10.48550/arXiv.2406.10252', '10.48550/arXiv.2412.10415', '10.48550/arXiv.2402.12928']...).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Round 1 Query for Papers Information ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 17:15:09,168 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=llm%20literature%20review&fieldsOfStudy=Computer%20Science&fields=abstract,authors,citationCount,citationStyles,corpusId,externalIds,fieldsOfStudy,influentialCitationCount,isOpenAccess,journal,openAccessPdf,paperId,publicationDate,publicationTypes,publicationVenue,referenceCount,s2FieldsOfStudy,title,url,venue,year&offset=0&limit=50 \"HTTP/1.1 429 \"\n",
      "2025-04-23 17:15:09,326 - INFO - HTTP Request: POST https://api.semanticscholar.org/graph/v1/paper/batch?fields=abstract,authors,citationCount,citationStyles,corpusId,externalIds,fieldsOfStudy,influentialCitationCount,isOpenAccess,journal,openAccessPdf,paperId,publicationDate,publicationTypes,publicationVenue,referenceCount,s2FieldsOfStudy,title,url,venue,year \"HTTP/1.1 200 OK\"\n",
      "2025-04-23 17:15:09,331 - INFO - _sync_get_papers: API call successful for batch (first 5: ['10.48550/arXiv.2406.10252', '10.48550/arXiv.2412.10415', '10.48550/arXiv.2402.12928']...), returning 3 items.\n",
      "2025-04-23 17:15:09,777 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search/match?query=PaperRobot:%20Incremental%20Draft%20Generation%20of%20Scientific%20Ideas&fieldsOfStudy=Computer%20Science&fields=abstract,authors,citationCount,citationStyles,corpusId,externalIds,fieldsOfStudy,influentialCitationCount,isOpenAccess,journal,openAccessPdf,paperId,publicationDate,publicationTypes,publicationVenue,referenceCount,s2FieldsOfStudy,title,url,venue,year&offset=0&limit=50 \"HTTP/1.1 200 OK\"\n",
      "2025-04-23 17:15:10,235 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search/match?query=From%20Hypothesis%20to%20Publication:%20A%20Comprehensive%20Survey%20of%20AI-Driven%20Research%20Support%20Systems&fieldsOfStudy=Computer%20Science&fields=abstract,authors,citationCount,citationStyles,corpusId,externalIds,fieldsOfStudy,influentialCitationCount,isOpenAccess,journal,openAccessPdf,paperId,publicationDate,publicationTypes,publicationVenue,referenceCount,s2FieldsOfStudy,title,url,venue,year&offset=0&limit=50 \"HTTP/1.1 200 OK\"\n",
      "2025-04-23 17:15:12,334 - INFO - async_search_paper_by_ids: Gather complete. Processing results.\n",
      "2025-04-23 17:15:39,827 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=llm%20literature%20review&fieldsOfStudy=Computer%20Science&fields=abstract,authors,citationCount,citationStyles,corpusId,externalIds,fieldsOfStudy,influentialCitationCount,isOpenAccess,journal,openAccessPdf,paperId,publicationDate,publicationTypes,publicationVenue,referenceCount,s2FieldsOfStudy,title,url,venue,year&offset=0&limit=50 \"HTTP/1.1 429 \"\n"
     ]
    }
   ],
   "source": [
    "# --- ROUND 1 QUERY ---\n",
    "# initial query for seed papers basic information\n",
    "print(f\"--- Running Round {iteration} Query for Papers Information ---\")\n",
    "await ps.consolidated_search(\n",
    "    topics=ps.research_topics,\n",
    "    paper_titles=ps.seed_paper_titles,\n",
    "    paper_dois=ps.seed_paper_dois,\n",
    "    # ref_paper_dois=ps.seed_paper_dois,\n",
    "    # citing_paper_dois=ps.seed_paper_dois,\n",
    "    # pos_paper_dois=ps.seed_paper_dois,\n",
    "    from_dt=ps.from_dt,\n",
    "    to_dt=ps.to_dt,\n",
    "    fields_of_study=ps.fields_of_study\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8c0747",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ps.nodes_json), len(ps.edges_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b401e095",
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(results, Paper.Paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd782ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in ps.nodes_json:\n",
    "    if item.get('labels') == ['Author'] and item.get('properties', {}).get('is_complete'):\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e268f6",
   "metadata": {},
   "source": [
    "### Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc58d1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "candit_dois, candit_author_ids = [], []\n",
    "candit_ref_dois, candit_citing_dois = [], []\n",
    "candit_topics = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897df153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# core papers and core authors nodes\n",
    "core_paper_dois = [node['id'] for node in ps.nodes_json \n",
    "                   if node['labels'] == ['Paper'] and node['id'] in seed_dois]\n",
    "core_author_ids = []\n",
    "for item in ps.nodes_json:\n",
    "    if item['id'] in core_paper_dois and isinstance(item['properties'].get('authors'), list):\n",
    "        authors_id = [x['authorId'] for x in item['properties']['authors'] if x['authorId'] is not None] \n",
    "        core_author_ids.extend(authors_id)\n",
    "core_author_ids = list(set(core_author_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a00bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.paper_similarity_calculation import PaperSim\n",
    "\n",
    "sim = PaperSim(\n",
    "    embed_api_key = embed_api_key,\n",
    "    embed_model_name = embed_model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb35119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate paper graph from nodes / edges json\n",
    "G_pre = PaperGraph(name='Paper Graph Init Search')\n",
    "G_pre.add_graph_nodes(ps.nodes_json)\n",
    "G_pre.add_graph_edges(ps.edges_json)\n",
    "\n",
    "# check core paper completeness\n",
    "# paper complete\n",
    "candit_dois.extend([doi for doi in core_paper_dois if doi not in G_pre.nodes()]) \n",
    "# citation complete\n",
    "candit_ref_dois.extend([doi for doi in core_paper_dois if doi not in ps.explored_nodes['reference']])\n",
    "candit_citing_dois.extend([doi for doi in core_paper_dois if doi not in ps.explored_nodes['citing']])\n",
    "# author complete\n",
    "candit_author_ids.extend([aid for aid in core_author_ids if aid not in ps.explored_nodes['author']]) \n",
    "\n",
    "# --- Graph Stat ---\n",
    "g_stat = get_graph_stats(G_pre)   # graph stats\n",
    "\n",
    "# valid paper with abstracts\n",
    "complete_paper_json = [node for node in ps.nodes_json \n",
    "                        if node['labels'] == ['Paper'] \n",
    "                        and node['properties'].get('title') is not None and node['properties'].get('abstract') is not None]\n",
    "complete_paper_dois = [node['id'] for node in complete_paper_json]\n",
    "\n",
    "# --- SIMILARITY CALCULATION ---\n",
    "# check if similarity with edge type\n",
    "edge_types = [x[0] for x in g_stat['edge_type']]\n",
    "\n",
    "if 'SIMILAR_TO' not in edge_types:\n",
    "    # calculate paper nodes similarity\n",
    "    semantic_similar_pool = await sim.cal_embed_and_similarity(\n",
    "        paper_nodes_json = complete_paper_json,\n",
    "        paper_dois_1 = complete_paper_dois, \n",
    "        paper_dois_2 = complete_paper_dois,\n",
    "        similarity_threshold=params['similarity_threshold'],\n",
    "        )\n",
    "\n",
    "    # add similarity edges to graph\n",
    "    G_pre.add_graph_edges(semantic_similar_pool)  \n",
    "\n",
    "# --- PRUNNING ---\n",
    "# pruning by connectivity\n",
    "sub_graphs = G_pre.find_wcc_subgraphs(target_nodes=core_paper_dois)\n",
    "if sub_graphs is not None and len(sub_graphs) > 0:\n",
    "    G_post  = sub_graphs[0]\n",
    "    # get stats after prunning\n",
    "    g_stat = get_graph_stats(G_post)\n",
    "else:\n",
    "    G_post = G_pre\n",
    "\n",
    "# --- GET KEY STATS ---\n",
    "# check paper count and author count\n",
    "paper_cnt, author_cnt = 0, 0\n",
    "for item in g_stat['node_type']:\n",
    "    if item[0] == 'Paper':\n",
    "        paper_cnt = item[1]\n",
    "    elif item[0] == 'Author':\n",
    "        author_cnt = item[1]\n",
    "\n",
    "paper_stats = get_paper_stats(G_post, core_paper_dois)  # paper stats on graph\n",
    "author_stats = get_author_stats(G_post, core_author_ids)  # author stats on graph\n",
    "\n",
    "# check crossref\n",
    "crossref_stats = []\n",
    "for x in paper_stats:\n",
    "    if (x['if_seed'] == False  # exclude seed papers \n",
    "        and x['local_citation_cnt'] > min(len(core_paper_dois),  5)):  # select most refered papers in graph\n",
    "        crossref_stats.append(x)\n",
    "\n",
    "# check key authors\n",
    "key_authors_stats = []\n",
    "for x in author_stats:\n",
    "    if (x['if_seed'] == False  # exclude seed authors \n",
    "        and x['local_paper_cnt'] > min(len(core_paper_dois), 5)):  # select most refered papers in graph\n",
    "        key_authors_stats.append(x)\n",
    "\n",
    "# check paper similarity\n",
    "sorted_paper_similarity = sorted(paper_stats, key=lambda x:x['max_sim_to_seed'], reverse=True)\n",
    "\n",
    "# if cross ref insufficient, further expand similar papers on citation chain\n",
    "if len(crossref_stats) < params['min_corssref_papers']:\n",
    "    # filter top similar papers (to help build crossref)\n",
    "    i = 0\n",
    "    for item in sorted_paper_similarity:\n",
    "        if i < params['top_k_similar_papers']:\n",
    "            if item['if_seed'] == False and item['doi'] not in ps.explored_nodes['reference']:\n",
    "                candit_ref_dois.append(item['doi'])\n",
    "                i += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "# if key authors not have complete information\n",
    "if len(key_authors_stats) > params['min_key_authors']:\n",
    "    sorted_key_authors = sorted(key_authors_stats, key=lambda x:x['local_paper_cnt'], reverse=True)\n",
    "    # filter key authors (to amplify information)\n",
    "    i = 0\n",
    "    for item in sorted_key_authors:\n",
    "        if i < params['top_l_key_authors']:\n",
    "            if item['if_seed'] == False and item['author_id'] not in ps.explored_nodes['author']:\n",
    "                candit_author_ids.append(item['author_id'])\n",
    "                i += 1\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fde995",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_authors_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4be0147",
   "metadata": {},
   "outputs": [],
   "source": [
    "candit_dois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7e1c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(core_author_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316cd742",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(candit_author_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d2787f",
   "metadata": {},
   "outputs": [],
   "source": [
    "candit_ref_dois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1417454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(candit_ref_dois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea1bd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(candit_citing_dois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802364da",
   "metadata": {},
   "outputs": [],
   "source": [
    "candit_dois, candit_author_ids = [], []\n",
    "candit_ref_dois, candit_citing_dois = [], []\n",
    "candit_topics = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc93709",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_ids = [nid for nid, node_data in G_post.nodes(data=True) if node_data.get('node_type') == 'Topic']\n",
    "topic_stats = []\n",
    "for tid in topic_ids:\n",
    "    i = 0\n",
    "    topic = G_post.nodes(tid).get('topic_name')\n",
    "    for u, v, edge_data in G_post.in_edges(tid, data=True):\n",
    "        if edge_data.get('relationshipType') == 'DISCUSS':\n",
    "            i += 1\n",
    "    topic_stats.append({'topic_id':tid, 'topic_name':topic, 'related_papers':i})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb8b49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_paper_json = [x for x in complete_paper_json if x['id'] in core_paper_dois]\n",
    "if len(topic_stats) < 4:\n",
    "    keywords_topics_json = await ps.topic_generation(\n",
    "        seed_paper_json=core_paper_json,\n",
    "        llm_api_key=ps.llm_api_key,\n",
    "        llm_model_name=ps.llm_model_name,\n",
    "        round=1\n",
    "        )\n",
    "    candit_topics.extend(keywords_topics_json.get('queries', []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5412ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "candit_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a74ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_authors_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90325293",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_post.nodes('2112678409')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb097a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "candit_author_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7cbea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "candit_dois\n",
    "candit_author_ids\n",
    "candit_ref_dois, candit_citing_dois = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a3cd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9113c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in complete_paper_json:\n",
    "    print(item.get('properties', {}).get('title'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bb1595",
   "metadata": {},
   "outputs": [],
   "source": [
    "candit_citing_dois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42cf5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "candit_ref_dois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfb27bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jiezi4ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
