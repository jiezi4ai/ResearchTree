编写函数处理semantic scholar (s2)的元数据。
其中函数align_paper_metadata修订元数据中的键值；
函数filter_papers对元数据进行过滤；
函数process_paper_data将paper元数据转换为neo4j兼容的json格式。

具体实现代码如下：


```python
import re
from typing import Optional, List, Dict, Literal

from utils.data_process import generate_hash_key, remove_kth_element, remove_key_values, filter_and_reorder_dict

def align_paper_metadata(s2_papers_metadata: List[Dict]|Dict):
    """reset id and keys for paper metadata"""
    if isinstance(s2_papers_metadata, dict):
        s2_papers_metadata = [s2_papers_metadata]

    s2_papers_dict = []
    for item in s2_papers_metadata:
        # set up paper id
        s2_paper_id = item.get('paperId')
        
        if s2_paper_id is not None:
            doi = item.get('externalIds',{}).get('DOI')  # doi
            arxiv_id = item.get('externalIds',{}).get('ArXiv')  # arxiv id

            if doi is not None and doi.startswith('10.48550/arXiv.') and arxiv_id is None:
                arxiv_id = doi

            arxiv_id_rvsd = None
            if arxiv_id is not None:
                arxiv_no = arxiv_id.replace('10.48550/arXiv.', '')   # get rid of doi prefix
                arxiv_id_rvsd = re.sub(r'v\d+$', '', arxiv_no)   # get rid of version info
                version_match = re.search(r'v\d+$', arxiv_no)  # get version info
                # generate arxiv related info
                item['version'] = version_match.group(0) if version_match else ""
                item['arxivUrl'] = f"https://arxiv.org/abs/{arxiv_no}"
                item['isOpenAccess'] = True
                item['openAccessPdf'] = f"https://arxiv.org/pdf/{arxiv_no}"
                item['arxivId'] = arxiv_id_rvsd

            if doi is None:
                if arxiv_id_rvsd is not None:
                    doi = f"10.48550/arXiv.{arxiv_id_rvsd}"  # assign 10.48550/arXiv. for arxiv id https://info.arxiv.org/help/doi.html
                else:
                    doi = s2_paper_id
            item['doi'] = doi

            # process publish date
            publish_dt = item.get('publicationDate')
            year = item.get('year')
            if publish_dt is None:
                if arxiv_id_rvsd is not None:
                    item['publicationDate'] = f"20{arxiv_id_rvsd[:2]}-{arxiv_id_rvsd[2:4]}-01"
                elif year is not None:
                    item['publicationDate'] = f"{year}-01-01"
                else:
                    item['publicationDate'] = '2000-01-01'

            # cut down author information
            item['authors'] = item.get('authors', [])[0:10]

            s2_papers_dict.append(item)
    return s2_papers_dict
            

def filter_papers(
    aligned_s2_papers: List[Dict]|Dict,  # paper data already process by align_paper_metadata
    from_dt: Optional[str] = None,   # filter publish dt no earlier than
    to_dt: Optional[str] = None,   # filter publish dt no late than
    fields_of_study: Optional[List[str]] = None,  # list of field of study
    min_citation_cnt: Optional[int] = 0,  # citation count no less than
    author_ids: Optional[List[str]] = None,  # restrcted to list of authors' ids
    # institutions: Optional[List[str]] = None,  # restrcted to list of institutions, to be implemented
    # journals: Optional[List[str]] = None,  # restrcted to list of journals, to be implemented
):
    """filter paper metadata (from semantic scholar) based on given criteria"""
    review_result = {
        'off_dt_range': set(),
        'off_fields_of_study': set(),
        'below_min_citation': set(),
        'off_author_scope': set(),
    }

    filter_fos_set = set(fields_of_study) if fields_of_study is not None else None
    filter_author_id_set = set(author_ids) if author_ids is not None else None

    for item in aligned_s2_papers:
        paper_doi = item.get('doi')
        if paper_doi is None:
            continue

        publish_dt = item.get('publicationDate')
        paper_author_ids_set = set(x.get('authorId') for x in item.get('authors', []) if x.get('authorId') is not None)
        paper_fos_set = set(item.get('fieldsOfStudy', []))
        paper_citation_cnt = item.get('referenceCount', 0)
        
        # --- Filtering Logic ---
        # exclude paper out of time scope
        if from_dt is not None and to_dt  is not None and (publish_dt < from_dt or publish_dt > to_dt):  
            review_result['off_dt_range'].add(paper_doi)
        
        # exclude paper not in fields of study
        if filter_fos_set is not None and paper_fos_set is not None and not filter_fos_set.intersection(paper_fos_set): 
            review_result['off_fields_of_study'].add(paper_doi)

        # exclude paper not meeting citation criteria
        if min_citation_cnt is not None and paper_citation_cnt < min_citation_cnt:   
            review_result['below_min_citation'].add(paper_doi)
        
        # exclude paper not in author list
        if filter_author_id_set is not None and not filter_author_id_set.intersection(paper_author_ids_set):
            review_result['off_author_scope'].add(paper_doi)

    return review_result


def process_paper_data(
        s2_papers_metadata: List[Dict]|Dict,
        from_dt: Optional[str] = None,   # filter publish dt no earlier than
        to_dt: Optional[str] = None,   # filter publish dt no late than
        fields_of_study: Optional[List[str]] = None,  # list of field of study
        ):
    """standardize paper metadata to better suit neo4j format
    Argss:
        s2_papers_metadata ([List[Dict]|Dict]): paper metadata that has been reset and filtered
    Returns:
        - the json has to be preprocessed to in format like:
                        [{'type': 'node',
                        'id': '2345003971',
                        'labels': ['Author'],
                        'properties': {'authorId': '2345003971', 'name': 'Mark Schone'}},
                        {'type': 'relationship',
                        'relationshipType': 'WRITES',
                        'startNodeId': '2345003971',
                        'endNodeId': '10.48550/arXiv.2502.07827',
                        'properties': {'authorOrder': 1,
                        'coauthors': [{'authorId': '2345003971', 'name': 'Mark Schone'},]}}]    
    """
    # align ids and keys for paper metadata
    aligned_papers_dict = align_paper_metadata(s2_papers_metadata)

    # get paper filter results
    exclusion_info = filter_papers(aligned_papers_dict, from_dt, to_dt, fields_of_study)
    exc_dois = (exclusion_info['off_dt_range'] | exclusion_info['off_fields_of_study'] |
                exclusion_info['below_min_citation'] | exclusion_info['off_author_scope'])

    # Process into standard JSON format, separating included/excluded
    inc_json, exc_json = [], []
    # Use separate sets for deduplication within each list
    inc_node_ids, exc_node_ids = set(), set()
    inc_edge_tuples, exc_edge_tuples = set(), set()
    
    # Define paper properties to include (excluding 'authors')
    paper_props = ['doi', 'title', 'abstract', 'year', 'publicationDate',
                    'citationCount', 'referenceCount', 'influentialCitationCount', 'arxivId', 'arxivUrl',
                    'isOpenAccess', 'openAccessPdf', 'version', 'paperId',
                    'fieldsOfStudy'] # Add/remove as needed

    for item in aligned_papers_dict:
        paper_doi = item.get('doi') 
        if paper_doi is None:
            continue 

        if paper_doi in exc_dois:
            s2_paper_json = exc_json
            processed_node_ids = exc_node_ids
            processed_edge_tuples = exc_edge_tuples
        else:
            s2_paper_json = inc_json
            processed_node_ids = inc_node_ids
            processed_edge_tuples = inc_edge_tuples

        # --- Process Paper Node ---

        paper_properties = {k: v for k, v in item.items() if k in paper_props and v is not None}
        paper_node = {
            "type": "node",
            "id": paper_doi,
            "labels": ["Paper"],
            "properties": paper_properties # Use filtered properties
            }
        s2_paper_json.append(paper_node)
        processed_node_ids.add(paper_doi)

        # --- Process Authors ---
        authors = item.get('authors', [])[:10]
        for idx, author in enumerate(authors):
            # process author node
            author_id = author.get('authorId')
            if author_id is not None:
                if author_id not in processed_node_ids:
                    author_props = {k: v for k, v in author.items() if k in ['authorId', 'name'] and v is not None}
                    author_node = {
                        "type": "node",
                        "id": author_id,
                        "labels": ["Author"],
                        "properties": author_props}
                    s2_paper_json.append(author_node)
                    processed_node_ids.add(author_id)
            
                # process author -> WRITES -> paper
                edge_tuple = (author_id, paper_doi, "WRITES")
                if edge_tuple not in processed_edge_tuples:
                    author_order = idx + 1
                    author_paper_relationship = {
                        "type": "relationship",
                        "relationshipType": "WRITES",
                        "startNodeId": author_id,
                        "endNodeId": paper_doi,
                        "properties": {'authorOrder': author_order}
                        }
                    s2_paper_json.append(author_paper_relationship)
                    processed_edge_tuples.add(edge_tuple)

        # --- Process Journal ---
        journal = item.get('journal', {})

        paper_in_journal_props = {}
        if isinstance(journal, dict):
            journal_name = journal.get('name')  
            paper_in_journal_props['volume'] = journal.get('volume')
            paper_in_journal_props['pages'] = journal.get('pages')
            # Filter None values from properties
            paper_in_journal_props = {k:v for k,v in paper_in_journal_props.items() if v is not None}
        else:
            journal_name = None

        if journal_name is not None:
            journal_hash_id = generate_hash_key(journal_name)
            if journal_hash_id not in processed_node_ids:
                journal_props = {"journal_hash_id": journal_hash_id, "name": journal_name, "hash_method":"hashlib.sha256"}
                journal_node = {
                    "type": "node",
                    "id": journal_hash_id,
                    "labels": ["Journal"],
                    "properties": journal_props}
                s2_paper_json.append(journal_node)
                processed_node_ids.add(journal_hash_id)
            
            # process paper -> PRINTS_ON -> journal
            edge_tuple = (paper_doi, journal_hash_id, "PRINTS_ON")
            if edge_tuple not in processed_edge_tuples:
                if 'arxiv' not in journal_name.lower():  # exclude arxiv from journal
                    paper_journal_relationship = {
                        "type": "relationship",
                        "relationshipType": "PRINTS_ON",
                        "startNodeId": paper_doi,
                        "endNodeId": journal_hash_id,
                        "properties": paper_in_journal_props}
                    s2_paper_json.append(paper_journal_relationship)
                    processed_edge_tuples.add(edge_tuple)

        # --- Process Venue ---
        venue = item.get('publicationVenue', {})
        venue_id = venue.get('id') if isinstance(venue, dict) else None
        venue_name = venue.get('name', '') if isinstance(venue, dict) else ''
        if venue_id is not None:
            if venue_id not in processed_node_ids:
                venue_props = {k: v for k, v in venue.items() if k in ['id', 'name', 'type', 'url'] and v is not None}
                venue_node = {
                    "type": "node",
                    "id": venue_id,
                    "labels": ["Venue"],
                    "properties": venue_props
                    }
                s2_paper_json.append(venue_node)
                processed_node_ids.add(venue_id)
            
            # process paper -> RELEASES_IN -> venue
            edge_tuple = (paper_doi, venue_id, "RELEASES_IN")
            if edge_tuple not in processed_edge_tuples:
                if 'arxiv' not in venue_name.lower():  # exclude arxiv from venue
                    paper_venue_relationship = {
                        "type": "relationship",
                        "relationshipType": "RELEASES_IN",
                        "startNodeId": paper_doi,
                        "endNodeId": venue_id,
                        "properties": {}}
                    s2_paper_json.append(paper_venue_relationship)
                    processed_edge_tuples.add(edge_tuple)

    processed_result = {'include': inc_json,
                        'exclude': exc_json,
                        'exclusion_info':exclusion_info}
    return processed_result
```

在以上函数的基础上，编写process_citation_data函数，以处理s2的citation数据处理为满足neo4j的json格式，函数代码如下：

```python
def process_citation_data(
        original_paper_doi: str,
        s2_citations: List[Dict]|Dict,
        citation_type: Literal['citingPaper','citedPaper'],
        from_dt: Optional[str] = None,   # filter publish dt no earlier than
        to_dt: Optional[str] = None,   # filter publish dt no late than
        fields_of_study: Optional[List[str]] = None,  # list of field of study    
        ):
    """standardize paper citation relationships to better suit neo4j format
    Argss:
        s2_citation_metadata ([List[Dict]|Dict]): citing or cited by metadata
    Returns:
        - the json has to be preprocessed to in format like:
                        [{'type': 'node',
                        'id': '2345003971',
                        'labels': ['Author'],
                        'properties': {'authorId': '2345003971', 'name': 'Mark Schone'}},
                        {'type': 'relationship',
                        'relationshipType': 'WRITES',
                        'startNodeId': '2345003971',
                        'endNodeId': '10.48550/arXiv.2502.07827',
                        'properties': {'authorOrder': 1,
                        'coauthors': [{'authorId': '2345003971', 'name': 'Mark Schone'},]}}]    
    """
    # for citations (citing or cited papers)
    if isinstance(s2_citations, dict):
        s2_citations = [s2_citations] 

    # Process into standard JSON format, separating included/excluded
    inc_json, exc_json = [], []
    # Use separate sets for deduplication within each list
    inc_node_ids, exc_node_ids = set(), set()
    inc_edge_tuples, exc_edge_tuples = set(), set()

    exclusion_info = {
        'off_dt_range': set(),
        'off_fields_of_study': set(),
        'below_min_citation': set(),
        'off_author_scope': set(),
    }

    for item in s2_citations:
        # each item corresponindg to one paper
        s2_papers = item.get(citation_type)  # get either citing or cited paper metadata
        if isinstance(s2_papers, dict):
            # process s2 papers
            papers_processed = process_paper_data(s2_papers, from_dt, to_dt, fields_of_study)
            
            for item in papers_processed['include']:
                if item['type'] == 'node' and item['id'] not in inc_node_ids:
                    inc_json.append(item)
                    inc_node_ids.add(item['id'])
                elif item['type'] == 'relationship':
                    edge_tuple = (item['startNodeId'], item['endNodeId'], item['relationshipType'])
                    if edge_tuple not in inc_edge_tuples:
                        inc_json.append(item)
                        inc_edge_tuples.add(edge_tuple)
            
            for item in papers_processed['exclude']:
                if item['type'] == 'node' and item['id'] not in exc_node_ids:
                    exc_json.append(item)
                    exc_node_ids.add(item['id'])
                elif item['type'] == 'relationship':
                    edge_tuple = (item['startNodeId'], item['endNodeId'], item['relationshipType'])
                    if edge_tuple not in exc_edge_tuples:
                        exc_json.append(item)
                        exc_edge_tuples.add(edge_tuple)

        # get all paper dois in inc_json (supposed to have only one)
        paper_dois = [x['id'] for x in inc_json if x['type'] == 'node' and x['label'] == ['Paper']]
        
        if len(paper_dois) > 0:
            target_paper_doi = paper_dois[0]
            if citation_type == 'citedPaper':  # source paper citing target papers
                start_node_id = original_paper_doi
                end_node_id = target_paper_doi
            else:  # source paper cited by target papers
                start_node_id = target_paper_doi
                end_node_id = original_paper_doi 

            # append paper -> CITES -> paper relationship
            edge_tuple = (start_node_id, end_node_id, 'CITES')
            if edge_tuple not in inc_edge_tuples:
                properties = filter_and_reorder_dict(item, ['isInfluential', 'contexts', 'intents', 'contextsWithIntent'])
                paper_cites_relationship = {
                    "type": "relationship",
                    "relationshipType": "CITES",
                    "startNodeId": start_node_id,
                    "endNodeId": end_node_id,
                    "properties": properties}
                inc_json.append(paper_cites_relationship)
                inc_edge_tuples.add(edge_tuple)

            exclusion_info['off_dt_range'].update(papers_processed['exclusion_info']['off_dt_range'])
            exclusion_info['off_fields_of_study'].update(papers_processed['exclusion_info']['off_fields_of_study'])
            exclusion_info['below_min_citation'].update(papers_processed['exclusion_info']['below_min_citation'])
            exclusion_info['off_author_scope'].update(papers_processed['exclusion_info']['off_author_scope'])
            
    processed_result = {'include': inc_json,
                      'exclude': exc_json,
                      'exclusion_info':exclusion_info}

    return processed_result
```

注意citation元数据分为cited paper和citing paper，其中可能嵌套paper元数据，因此在其中调用process_paper_data函数进一步处理。

请检查process_citation_data函数，完成以下任务：
1. 检查代码是否存在显著错误，如有，请逐个说明；
2. 备注其它的可优化项。

