{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f670ae1b",
   "metadata": {},
   "source": [
    "# Paper Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24acc952",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeef614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from paper_collect import PaperCollector"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:src/running_test_collect.ipynb
   "execution_count": null,
=======
   "execution_count": 7,
   "id": "9754fc44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'abc'.startswith('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
>>>>>>> b9769cdb0d936c3d4f24b69f4523e28fe23ca398:src/running_test_collect_bkp.ipynb
   "id": "abd73eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_api_key = os.getenv('GEMINI_API_KEY_3')\n",
    "llm_model_name=\"gemini-2.0-flash\"\n",
    "embed_api_key = os.getenv('GEMINI_API_KEY_3')\n",
    "embed_model_name=\"models/text-embedding-004\"\n",
    "\n",
    "research_topic = \"llm literature review\"\n",
    "seed_dois = ['10.48550/arXiv.2406.10252',  # AutoSurvey: Large Language Models Can Automatically Write Surveys\n",
    "            '10.48550/arXiv.2412.10415',  # Generative Adversarial Reviews: When LLMs Become the Critic\n",
    "            '10.48550/arXiv.2402.12928',  # A Literature Review of Literature Reviews in Pattern Analysis and Machine Intelligence \n",
    "            ]\n",
    "seed_titles = ['PaperRobot: Incremental Draft Generation of Scientific Ideas',\n",
    "            'From Hypothesis to Publication: A Comprehensive Survey of AI-Driven Research Support Systems'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41739da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PaperCollector(   \n",
    "    research_topic = research_topic,   \n",
    "    seed_paper_titles = seed_titles, \n",
    "    seed_paper_dois = seed_dois,\n",
    "    llm_api_key = llm_api_key,\n",
    "    llm_model_name = llm_model_name,\n",
    "    embed_api_key = embed_api_key,\n",
    "    embed_model_name = embed_model_name,\n",
    "    from_dt = '2020-01-01',\n",
    "    to_dt = '2025-04-30',\n",
    "    fields_of_study = ['Computer Science'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705bb1bc",
   "metadata": {},
   "source": [
    "## Inital Search\n",
    "- initial search for seed paper metadata\n",
    "- basic search takes about 30-60 seconds "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb61e95",
   "metadata": {},
   "source": [
    "### Paper Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26918ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- INITIAL QUERY on SEED ---\n",
    "# initial query for seed papers basic information\n",
    "print(\"--- Running Initial Query for Seed Papers Information ---\")\n",
    "await ps.init_search(\n",
    "    ps.research_topic,\n",
    "    ps.seed_paper_titles,\n",
    "    ps.seed_paper_dois,\n",
    "    ps.search_limit,\n",
    "    ps.from_dt,\n",
    "    ps.to_dt\n",
    ")\n",
    "# get seed DOIs\n",
    "seed_paper_dois = [node['id'] for node in ps.nodes_json if node['labels'] == ['Paper'] and node['properties'].get('from_seed')==True]\n",
    "seed_author_ids = []\n",
    "for node in ps.nodes_json:\n",
    "    if node['labels'] == ['Paper'] and node['properties'].get('from_seed')==True and isinstance(node['properties'].get('authors'), list):\n",
    "        authors_id = [x['authorId'] for x in node['properties']['authors'] if x['authorId'] is not None] \n",
    "        seed_author_ids.extend(authors_id)\n",
    "seed_paper_json = [node for node in ps.nodes_json if node['labels'] == ['Paper'] and node['properties'].get('from_seed')==True]\n",
    "ps.explored_nodes['seed'].extend(seed_paper_dois) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fd06b8",
   "metadata": {},
   "source": [
    "### Graph Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c28ae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from collections import Counter\n",
    "\n",
    "g = copy.deepcopy(ps.pg.graph)\n",
    "print(len(ps.nodes_json), len(ps.edges_json), len(g.nodes), len(g.edges))\n",
    "\n",
    "# check node types\n",
    "node_types = [g.nodes[nid].get('nodeType') for nid in g.nodes]\n",
    "node_types_cnt = Counter(node_types)\n",
    "# 按计数降序排序\n",
    "sorted_node_counts = node_types_cnt.most_common()\n",
    "print(sorted_node_counts)\n",
    "\n",
    "# check node types\n",
    "edge_types = [d.get('relationshipType') for u, v, d in g.edges(data=True)]\n",
    "edge_types_cnt = Counter(edge_types)\n",
    "# 按计数降序排序\n",
    "sorted_egdes_counts = edge_types_cnt.most_common()\n",
    "print(sorted_egdes_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb9e8b4",
   "metadata": {},
   "source": [
    "### Graph Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ab8de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from graph.graph_viz import GraphViz\n",
    "viz = GraphViz(g, 'test')\n",
    "viz.preprocessing()\n",
    "viz.visulization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df28f699",
   "metadata": {},
   "source": [
    "## Basic Search\n",
    "- basic search for the following information based on user input:\n",
    "    - search_citation: enable search along citation chain\n",
    "        - 'reference': papers cited by seeds\n",
    "        - 'citing': papers cites seeds\n",
    "        - 'both': all of the above\n",
    "    - search_author: search on seed papers authors\n",
    "        - would get authors information and other publications from the authors\n",
    "    - find_recommend: get recommended papers based on seed papers\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a1dc74",
   "metadata": {},
   "source": [
    "### Paper Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eefe5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_citation = \"both\"\n",
    "search_author = True\n",
    "find_recommend = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3586ee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MORE INFORMATION on SEED ---\n",
    "print(\"--- Getting More Information Related to Seed Papers ---\")\n",
    "# basic search for seed papers\n",
    "# may include seed paper authors, seed paper citation chain, recommendations based on seed papers \n",
    "await ps.collect(\n",
    "    seed_paper_dois=seed_paper_dois,\n",
    "    seed_author_ids=seed_author_ids,\n",
    "    search_citation = search_citation,\n",
    "    search_author = search_author,\n",
    "    find_recommend = find_recommend,\n",
    "    recommend_limit = ps.recommend_limit,\n",
    "    citation_limit = ps.citation_limit,\n",
    "    from_dt = ps.from_dt,\n",
    "    to_dt = ps.to_dt,\n",
    "    fields_of_study = ps.fields_of_study,\n",
    "    )\n",
    "\n",
    "if search_citation in ['reference', 'both']:\n",
    "    ps.explored_nodes['reference'].extend(seed_paper_dois) \n",
    "if search_citation in ['citing', 'both']:\n",
    "    ps.explored_nodes['citing'].extend(seed_paper_dois) \n",
    "if search_author:\n",
    "    ps.explored_nodes['author'].extend(seed_author_ids) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec67615",
   "metadata": {},
   "source": [
    "### Graph Stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3668f7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from collections import Counter\n",
    "\n",
    "g = copy.deepcopy(ps.pg.graph)\n",
    "print(len(ps.nodes_json), len(ps.edges_json), len(g.nodes), len(g.edges))\n",
    "\n",
    "# check node types\n",
    "node_types = [g.nodes[nid].get('nodeType') for nid in g.nodes]\n",
    "node_types_cnt = Counter(node_types)\n",
    "# 按计数降序排序\n",
    "sorted_node_counts = node_types_cnt.most_common()\n",
    "print(sorted_node_counts)\n",
    "\n",
    "# check node types\n",
    "edge_types = [d.get('relationshipType') for u, v, d in g.edges(data=True)]\n",
    "edge_types_cnt = Counter(edge_types)\n",
    "# 按计数降序排序\n",
    "sorted_egdes_counts = edge_types_cnt.most_common()\n",
    "print(sorted_egdes_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb88619c",
   "metadata": {},
   "source": [
    "### Graph Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e5e31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# from graph.graph_viz import GraphViz\n",
    "viz = GraphViz(g, 'paper graph after basic search')\n",
    "viz.preprocessing()\n",
    "viz.visulization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a482bd1",
   "metadata": {},
   "source": [
    "### Filter & Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a177f7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed papers\n",
    "seed_paper_dois = [nid for nid in g.nodes \n",
    "                   if g.nodes[nid].get('nodeType')=='Paper' and\n",
    "                      g.nodes[nid].get('from_seed') == True]\n",
    "seed_paper_nodes = [g.nodes[nid] for nid in g.nodes \n",
    "                    if g.nodes[nid].get('nodeType')=='Paper' and\n",
    "                        g.nodes[nid].get('from_seed') == True]\n",
    "\n",
    "seed_author_ids, seed_author_nodes = [], []\n",
    "for doi in seed_paper_dois:\n",
    "    pre_ids = g.predecessors(doi)\n",
    "    for id in pre_ids:\n",
    "        if g.nodes[id].get('nodeType')=='Author':\n",
    "            seed_author_ids.append(id)\n",
    "            seed_author_nodes.append(g.nodes[id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8e2c62",
   "metadata": {},
   "source": [
    "Paper Ranking  \n",
    "- most cited papers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588f51a3",
   "metadata": {},
   "source": [
    "The purpose of most cited papers is to build a common citation chain for seed papers.  \n",
    "A filtering condition is:  \n",
    "- paper cited more than min(# of seed papers, 4)  \n",
    "- rank order by cited in descending, get more than 10 of the papers  \n",
    "- not in seed papers  \n",
    "- may add significance citeria in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d768b09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_stat = []\n",
    "for n in g.nodes:\n",
    "    if g.nodes[n].get('nodeType') == 'Paper':\n",
    "        in_edges_info = g.in_edges(n, data=True)\n",
    "        cite_cnt = sum([1 for u, v, data in in_edges_info if data.get('relationshipType') == 'CITES'])\n",
    "        paper_stat.append((n, cite_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c5b241",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_seed_paper_cnt = len(seed_paper_dois)\n",
    "tot_paper_cnt = len([nid for nid in g.nodes if g.nodes[nid].get('nodeType')=='Paper'])\n",
    "print(tot_seed_paper_cnt, tot_paper_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe986657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sorted_by_cite = sorted(paper_stat, key=lambda item: item[1], reverse=True)\n",
    "print(sorted_by_cite[0:20])\n",
    "\n",
    "for item in sorted_by_cite[0:20]:\n",
    "    n = item[0]\n",
    "    cite_cnt = item[1]\n",
    "    # paper infos\n",
    "    title = g.nodes[n].get('title')\n",
    "    in_seed = True if item[0] in seed_paper_dois else False\n",
    "    overall_cite_cnt = g.nodes[n].get('citationCount')\n",
    "    influential_cite_cnt = g.nodes[n].get('influentialCitationCount')\n",
    "    # author infors\n",
    "    hindex_lst = []\n",
    "    for u in g.predecessors(n):\n",
    "        if g.nodes[u].get('nodeType') == 'Author':\n",
    "            hIndex = g.nodes[u].get('hIndex')\n",
    "            if hIndex:\n",
    "                hindex_lst.append(hIndex)\n",
    "            paperCount = g.nodes[u].get('paperCount')\n",
    "            citationCount = g.nodes[u].get('citationCount')\n",
    "    h_index = np.average(hindex_lst)\n",
    "\n",
    "    paper_info = {\"doi\":n, \"title\":title, \"if_seed\": in_seed,\n",
    "                  \"local_refs\":cite_cnt, \"global_refs\":overall_cite_cnt, \"inf_cite_cnt\":influential_cite_cnt,\n",
    "                  \"h_index\": h_index}\n",
    "    print(paper_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181a4d0e",
   "metadata": {},
   "source": [
    "Author Ranking  \n",
    "- most cited authors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42e519f",
   "metadata": {},
   "source": [
    "The purpose of most cited authors is to get key authors info, which may lead to further investigation.  \n",
    "A filtering condition is:  \n",
    "- author cited more than min(0.1 * total papers, 10)  \n",
    "- rank order by cited in descending, get more than 10 of the authors  \n",
    "- not in seed authors  \n",
    "- may add significance citeria in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f90049",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_stat = []\n",
    "for n in g.nodes:\n",
    "    if g.nodes[n].get('nodeType') == 'Author':\n",
    "        out_edges_info = g.out_edges(n, data=True)\n",
    "        write_cnt = sum([1 for u, v, data in out_edges_info if data.get('relationshipType') == 'WRITES'])\n",
    "        author_stat.append((n, write_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9897aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_writes = sorted(author_stat, key=lambda item: item[1], reverse=True)\n",
    "for item in sorted_by_writes[0:20]:\n",
    "    aid = item[0]\n",
    "    a_name = g.nodes[aid].get('name')\n",
    "    hIndex = g.nodes[aid].get('hIndex')\n",
    "    in_seed = True if aid in seed_author_ids else False\n",
    "    global_paper_cnt = g.nodes[aid].get('paperCount')\n",
    "    global_citation_cnt = g.nodes[aid].get('citationCount')\n",
    "    print({\"author_id\":aid, \"author_name\":a_name, \"write_cnt\":item[1], \"is_seed\":in_seed,\n",
    "           \"hIndex\":hIndex, \"global_paper_cnt\":global_paper_cnt, \"global_citation_cnt\":global_citation_cnt, })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd1c5ac",
   "metadata": {},
   "source": [
    "### Similarity Check\n",
    "- check similar papers to seed, see if they are worth exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de649c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_threshold = 0.7\n",
    "expanded_k_papers = 20\n",
    "non_seed_paper_dois = [node['id'] for node in ps.nodes_json if node['labels'] == ['Paper'] and node['id'] not in seed_paper_dois]\n",
    "paper_nodes_json = [node for node in ps.nodes_json \n",
    "                    if node['labels'] == ['Paper'] and \n",
    "                    node['properties'].get('title') is not None and node['properties'].get('abstract') is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0b0db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate paper nodes similarity\n",
    "semantic_similar_pool = await ps.cal_embed_and_similarity(\n",
    "    paper_nodes_json=paper_nodes_json,\n",
    "    paper_dois_1=seed_paper_dois, \n",
    "    paper_dois_2=non_seed_paper_dois,\n",
    "    similarity_threshold=similarity_threshold,\n",
    "    )\n",
    "\n",
    "if len(semantic_similar_pool) > 0:\n",
    "    candit_items = []\n",
    "    for item in semantic_similar_pool:\n",
    "        wt = item.get('properties', {}).get('weight')\n",
    "        if (wt > 0.7 and wt < 0.95) or (wt > 0.7 and wt < 0.95):\n",
    "            if item['startNodeId'] in seed_paper_dois and item['endNodeId'] not in seed_paper_dois:\n",
    "                candit_items.append((item['endNodeId'], wt))\n",
    "            elif item['startNodeId'] not in seed_paper_dois and item['endNodeId'] in seed_paper_dois:\n",
    "                candit_items.append((item['startNodeId'], wt))\n",
    "    sorted_items = sorted(candit_items, key=lambda item: item[1], reverse=True)\n",
    "\n",
    "    # filter top k similarities\n",
    "    expanded_paper_dois = [x[0] for x in sorted_items[0:expanded_k_papers]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2fffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doi in expanded_paper_dois:\n",
    "    # paper infos\n",
    "    title = g.nodes[doi].get('title')\n",
    "    in_seed = True if doi in seed_paper_dois else False\n",
    "    overall_cite_cnt = g.nodes[doi].get('citationCount')\n",
    "    influential_cite_cnt = g.nodes[doi].get('influentialCitationCount')\n",
    "    # author infors\n",
    "    hindex_lst = []\n",
    "    for u in g.predecessors(doi):\n",
    "        if g.nodes[u].get('nodeType') == 'Author':\n",
    "            hIndex = g.nodes[u].get('hIndex')\n",
    "            if hIndex:\n",
    "                hindex_lst.append(hIndex)\n",
    "            paperCount = g.nodes[u].get('paperCount')\n",
    "            citationCount = g.nodes[u].get('citationCount')\n",
    "    h_index = np.average(hindex_lst)\n",
    "\n",
    "    paper_info = {\"doi\":doi, \"title\":title, \"if_seed\": in_seed,\n",
    "                  \"global_refs\":overall_cite_cnt, \"inf_cite_cnt\":influential_cite_cnt,\n",
    "                  \"h_index\": h_index}\n",
    "    print(paper_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0509d52a",
   "metadata": {},
   "source": [
    "## Expanded Search － Related Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e706371f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if_related_topic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b0d95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- EXPAND to RELATED TOPICS over SEED ---\n",
    "# get related topics based on abstracts of seed papers\n",
    "# search for related topics for more papers\n",
    "if if_related_topic:\n",
    "    await ps.expand(\n",
    "        seed_paper_json=seed_paper_json, \n",
    "        llm_api_key=ps.llm_api_key, \n",
    "        llm_model_name=ps.llm_model_name,\n",
    "        search_limit=ps.search_limit,\n",
    "        from_dt=ps.from_dt,\n",
    "        to_dt=ps.to_dt,\n",
    "        fields_of_study = ps.fields_of_study,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19afd6a",
   "metadata": {},
   "source": [
    "### Graph Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a4c02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from collections import Counter\n",
    "\n",
    "g2 = copy.deepcopy(ps.pg.graph)\n",
    "print(len(ps.nodes_json), len(ps.edges_json), len(g2.nodes), len(g2.edges))\n",
    "\n",
    "# check node types\n",
    "node_types = [g2.nodes[nid].get('nodeType') for nid in g2.nodes]\n",
    "node_types_cnt = Counter(node_types)\n",
    "# 按计数降序排序\n",
    "sorted_node_counts = node_types_cnt.most_common()\n",
    "print(sorted_node_counts)\n",
    "\n",
    "# check node types\n",
    "edge_types = [d.get('relationshipType') for u, v, d in g2.edges(data=True)]\n",
    "edge_types_cnt = Counter(edge_types)\n",
    "# 按计数降序排序\n",
    "sorted_egdes_counts = edge_types_cnt.most_common()\n",
    "print(sorted_egdes_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd78677",
   "metadata": {},
   "source": [
    "### Filter & Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378a06b8",
   "metadata": {},
   "source": [
    "Expanded topic would not affect paper citation information.  \n",
    "It may impact author stats.\n",
    "Since only seed author explored, the top authors cited would also tend to be seed authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3915b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_stat2 = []\n",
    "for n in g2.nodes:\n",
    "    if g2.nodes[n].get('nodeType') == 'Author':\n",
    "        out_edges_info = g2.out_edges(n, data=True)\n",
    "        write_cnt = sum([1 for u, v, data in out_edges_info if data.get('relationshipType') == 'WRITES'])\n",
    "        author_stat2.append((n, write_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02935344",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_writes2 = sorted(author_stat2, key=lambda item: item[1], reverse=True)\n",
    "for item in sorted_by_writes2[0:20]:\n",
    "    aid = item[0]\n",
    "    a_name = g2.nodes[aid].get('name')\n",
    "    hIndex = g2.nodes[aid].get('hIndex')\n",
    "    in_seed = True if aid in seed_author_ids else False\n",
    "    global_paper_cnt = g2.nodes[aid].get('paperCount')\n",
    "    global_citation_cnt = g2.nodes[aid].get('citationCount')\n",
    "    print({\"author_id\":aid, \"author_name\":a_name, \"write_cnt\":item[1], \"is_seed\":in_seed,\n",
    "           \"hIndex\":hIndex, \"global_paper_cnt\":global_paper_cnt, \"global_citation_cnt\":global_citation_cnt, })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385f936f",
   "metadata": {},
   "source": [
    "### Similarity Check\n",
    "- data reveals that after topic expansion, the top similar papers does not change much from original ones.\n",
    "- Hence, the topic expansion is relatively isolated from author expansion and citation expansion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873b60b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_threshold = 0.7\n",
    "expanded_k_papers = 20\n",
    "non_seed_paper_dois = [node['id'] for node in ps.nodes_json if node['labels'] == ['Paper'] and node['id'] not in seed_paper_dois]\n",
    "paper_nodes_json = [node for node in ps.nodes_json \n",
    "                    if node['labels'] == ['Paper'] and \n",
    "                    node['properties'].get('title') is not None and node['properties'].get('abstract') is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc98c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate paper nodes similarity\n",
    "semantic_similar_pool = await ps.cal_embed_and_similarity(\n",
    "    paper_nodes_json=paper_nodes_json,\n",
    "    paper_dois_1=seed_paper_dois, \n",
    "    paper_dois_2=non_seed_paper_dois,\n",
    "    similarity_threshold=similarity_threshold,\n",
    "    )\n",
    "\n",
    "if len(semantic_similar_pool) > 0:\n",
    "    candit_items = []\n",
    "    for item in semantic_similar_pool:\n",
    "        wt = item.get('properties', {}).get('weight')\n",
    "        if (wt > 0.7 and wt < 0.95) or (wt > 0.7 and wt < 0.95):\n",
    "            if item['startNodeId'] in seed_paper_dois and item['endNodeId'] not in seed_paper_dois:\n",
    "                candit_items.append((item['endNodeId'], wt))\n",
    "            elif item['startNodeId'] not in seed_paper_dois and item['endNodeId'] in seed_paper_dois:\n",
    "                candit_items.append((item['startNodeId'], wt))\n",
    "    sorted_items = sorted(candit_items, key=lambda item: item[1], reverse=True)\n",
    "\n",
    "    # filter top k similarities\n",
    "    expanded_paper_dois = [x[0] for x in sorted_items[0:expanded_k_papers]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c2b302",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doi in expanded_paper_dois:\n",
    "    # paper infos\n",
    "    title = g2.nodes[doi].get('title')\n",
    "    in_seed = True if doi in seed_paper_dois else False\n",
    "    overall_cite_cnt = g2.nodes[doi].get('citationCount')\n",
    "    influential_cite_cnt = g2.nodes[doi].get('influentialCitationCount')\n",
    "    # author infors\n",
    "    hindex_lst = []\n",
    "    for u in g2.predecessors(doi):\n",
    "        if g2.nodes[u].get('nodeType') == 'Author':\n",
    "            hIndex = g2.nodes[u].get('hIndex')\n",
    "            if hIndex:\n",
    "                hindex_lst.append(hIndex)\n",
    "            paperCount = g2.nodes[u].get('paperCount')\n",
    "            citationCount = g2.nodes[u].get('citationCount')\n",
    "    h_index = np.average(hindex_lst)\n",
    "\n",
    "    paper_info = {\"doi\":doi, \"title\":title, \"if_seed\": in_seed,\n",
    "                  \"global_refs\":overall_cite_cnt, \"inf_cite_cnt\":influential_cite_cnt,\n",
    "                  \"h_index\": h_index}\n",
    "    print(paper_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed78fa7d",
   "metadata": {},
   "source": [
    "### Grpah Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8b014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# from graph.graph_viz import GraphViz\n",
    "viz2 = GraphViz(g2, 'paper graph after topic expansion')\n",
    "viz2.preprocessing()\n",
    "viz2.visulization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d553b0b2",
   "metadata": {},
   "source": [
    "## Expanded Search - Similar Papers Citation Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b266842",
   "metadata": {},
   "outputs": [],
   "source": [
    "if_expanded_citations = 'reference' # by default search only reference for similar papers\n",
    "print(expanded_paper_dois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fddd2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CHECK CROSSREF PAPERS ---\n",
    "# get most similar papers to seed papers\n",
    "# track citation chain of these papers\n",
    "# retrieve citation for top k similar papers\n",
    "await ps.collect(\n",
    "    seed_paper_dois=expanded_paper_dois,\n",
    "    search_citation = if_expanded_citations,\n",
    "    citation_limit = ps.citation_limit,\n",
    "    from_dt=ps.from_dt,\n",
    "    to_dt=ps.to_dt,\n",
    "    fields_of_study = ps.fields_of_study,\n",
    "    )\n",
    "if if_expanded_citations in ['reference', 'both']:\n",
    "    ps.explored_nodes['reference'].extend(expanded_paper_dois) \n",
    "if if_expanded_citations in ['citing', 'both']:\n",
    "    ps.explored_nodes['citing'].extend(expanded_paper_dois) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8d0278",
   "metadata": {},
   "source": [
    "### Graph Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d982df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from collections import Counter\n",
    "\n",
    "g3 = copy.deepcopy(ps.pg.graph)\n",
    "print(len(ps.nodes_json), len(ps.edges_json), len(g3.nodes), len(g3.edges))\n",
    "\n",
    "# check node types\n",
    "node_types = [g3.nodes[nid].get('nodeType') for nid in g3.nodes]\n",
    "node_types_cnt = Counter(node_types)\n",
    "# 按计数降序排序\n",
    "sorted_node_counts = node_types_cnt.most_common()\n",
    "print(sorted_node_counts)\n",
    "\n",
    "# check node types\n",
    "edge_types = [d.get('relationshipType') for u, v, d in g3.edges(data=True)]\n",
    "edge_types_cnt = Counter(edge_types)\n",
    "# 按计数降序排序\n",
    "sorted_egdes_counts = edge_types_cnt.most_common()\n",
    "print(sorted_egdes_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d540f2",
   "metadata": {},
   "source": [
    "### Filtering and Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e008c7c",
   "metadata": {},
   "source": [
    "Author  \n",
    "- not impacted much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe21da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_stat3 = []\n",
    "for n in g3.nodes:\n",
    "    if g3.nodes[n].get('nodeType') == 'Author':\n",
    "        out_edges_info = g3.out_edges(n, data=True)\n",
    "        write_cnt = sum([1 for u, v, data in out_edges_info if data.get('relationshipType') == 'WRITES'])\n",
    "        author_stat3.append((n, write_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb92bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_writes3 = sorted(author_stat3, key=lambda item: item[1], reverse=True)\n",
    "for item in sorted_by_writes3[0:20]:\n",
    "    aid = item[0]\n",
    "    a_name = g3.nodes[aid].get('name')\n",
    "    hIndex = g3.nodes[aid].get('hIndex')\n",
    "    in_seed = True if aid in seed_author_ids else False\n",
    "    global_paper_cnt = g3.nodes[aid].get('paperCount')\n",
    "    global_citation_cnt = g3.nodes[aid].get('citationCount')\n",
    "    print({\"author_id\":aid, \"author_name\":a_name, \"write_cnt\":item[1], \"is_seed\":in_seed,\n",
    "           \"hIndex\":hIndex, \"global_paper_cnt\":global_paper_cnt, \"global_citation_cnt\":global_citation_cnt, })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14190df5",
   "metadata": {},
   "source": [
    "Paper  \n",
    "- most cited papers changed moderately\n",
    "- more reliable to serve as cross ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ba32b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_stat = []\n",
    "for n in g3.nodes:\n",
    "    if g3.nodes[n].get('nodeType') == 'Paper':\n",
    "        in_edges_info = g3.in_edges(n, data=True)\n",
    "        cite_cnt = sum([1 for u, v, data in in_edges_info if data.get('relationshipType') == 'CITES'])\n",
    "        paper_stat.append((n, cite_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1ef491",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_seed_paper_cnt = len(seed_paper_dois)\n",
    "tot_paper_cnt = len([nid for nid in g3.nodes if g3.nodes[nid].get('nodeType')=='Paper'])\n",
    "print(tot_seed_paper_cnt, tot_paper_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ceefde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sorted_by_cite = sorted(paper_stat, key=lambda item: item[1], reverse=True)\n",
    "print(sorted_by_cite[0:30])\n",
    "\n",
    "for item in sorted_by_cite[0:30]:\n",
    "    n = item[0]\n",
    "    cite_cnt = item[1]\n",
    "    # paper infos\n",
    "    title = g3.nodes[n].get('title')\n",
    "    in_seed = True if item[0] in seed_paper_dois else False\n",
    "    overall_cite_cnt = g3.nodes[n].get('citationCount')\n",
    "    influential_cite_cnt = g3.nodes[n].get('influentialCitationCount')\n",
    "    # author infors\n",
    "    hindex_lst = []\n",
    "    for u in g3.predecessors(n):\n",
    "        if g3.nodes[u].get('nodeType') == 'Author':\n",
    "            hIndex = g3.nodes[u].get('hIndex')\n",
    "            if hIndex:\n",
    "                hindex_lst.append(hIndex)\n",
    "            paperCount = g3.nodes[u].get('paperCount')\n",
    "            citationCount = g3.nodes[u].get('citationCount')\n",
    "    h_index = np.average(hindex_lst)\n",
    "\n",
    "    paper_info = {\"doi\":n, \"title\":title, \"if_seed\": in_seed,\n",
    "                  \"local_refs\":cite_cnt, \"global_refs\":overall_cite_cnt, \"inf_cite_cnt\":influential_cite_cnt,\n",
    "                  \"h_index\": h_index}\n",
    "    print(paper_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1615a8e4",
   "metadata": {},
   "source": [
    "### Graph Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bce1eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from graph.graph_viz import GraphViz\n",
    "viz3 = GraphViz(g3, 'paper graph after topic expansion')\n",
    "viz3.preprocessing()\n",
    "viz3.visulization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649944ff",
   "metadata": {},
   "source": [
    "## Expanded Search - High Impact Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff33c0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "if_expanded_authors = True\n",
    "expanded_l_authors = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb090823",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "expanded_author_ids = []\n",
    "for item in sorted_by_writes3:\n",
    "    if i < expanded_l_authors:\n",
    "        aid = item[0]\n",
    "        if aid not in seed_author_ids:\n",
    "            a_name = g3.nodes[aid].get('name')\n",
    "            hIndex = g3.nodes[aid].get('hIndex')\n",
    "            global_paper_cnt = g3.nodes[aid].get('paperCount')\n",
    "            global_citation_cnt = g3.nodes[aid].get('citationCount')\n",
    "            print({\"author_id\":aid, \"author_name\":a_name, \"write_cnt\":item[1],\n",
    "                \"hIndex\":hIndex, \"global_paper_cnt\":global_paper_cnt, \"global_citation_cnt\":global_citation_cnt, })\n",
    "            expanded_author_ids.append(aid)\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7a2f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CHECK SIGNIFICANT AUTHORS ---\n",
    "# filter most refered papers from graph\n",
    "# then search for author information\n",
    "if if_expanded_authors:\n",
    "    print(f\"\\n--- Get most cited authors: ---\")\n",
    "\n",
    "    # retrieve citation for top l most significant authors\n",
    "    await ps.collect(\n",
    "        seed_author_ids=expanded_author_ids,\n",
    "        search_author = if_expanded_authors,\n",
    "        from_dt=ps.from_dt,\n",
    "        to_dt=ps.to_dt,\n",
    "        fields_of_study = ps.fields_of_study,\n",
    "        )\n",
    "    ps.explored_nodes['author'].extend(expanded_author_ids) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786257f7",
   "metadata": {},
   "source": [
    "### Graph Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffe3842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from collections import Counter\n",
    "\n",
    "g4 = copy.deepcopy(ps.pg.graph)\n",
    "print(len(ps.nodes_json), len(ps.edges_json), len(g4.nodes), len(g4.edges))\n",
    "\n",
    "# check node types\n",
    "node_types = [g4.nodes[nid].get('nodeType') for nid in g4.nodes]\n",
    "node_types_cnt = Counter(node_types)\n",
    "# 按计数降序排序\n",
    "sorted_node_counts = node_types_cnt.most_common()\n",
    "print(sorted_node_counts)\n",
    "\n",
    "# check node types\n",
    "edge_types = [d.get('relationshipType') for u, v, d in g4.edges(data=True)]\n",
    "edge_types_cnt = Counter(edge_types)\n",
    "# 按计数降序排序\n",
    "sorted_egdes_counts = edge_types_cnt.most_common()\n",
    "print(sorted_egdes_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c63d4d",
   "metadata": {},
   "source": [
    "### Filtering & Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8db2860",
   "metadata": {},
   "source": [
    "Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ee91bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_stat4 = []\n",
    "for n in g4.nodes:\n",
    "    if g4.nodes[n].get('nodeType') == 'Author':\n",
    "        out_edges_info = g4.out_edges(n, data=True)\n",
    "        write_cnt = sum([1 for u, v, data in out_edges_info if data.get('relationshipType') == 'WRITES'])\n",
    "        author_stat4.append((n, write_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97f1a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_writes4 = sorted(author_stat4, key=lambda item: item[1], reverse=True)\n",
    "for item in sorted_by_writes4[0:40]:\n",
    "    aid = item[0]\n",
    "    a_name = g4.nodes[aid].get('name')\n",
    "    hIndex = g4.nodes[aid].get('hIndex')\n",
    "    in_seed = True if aid in seed_author_ids else False\n",
    "    global_paper_cnt = g4.nodes[aid].get('paperCount')\n",
    "    global_citation_cnt = g4.nodes[aid].get('citationCount')\n",
    "    print({\"author_id\":aid, \"author_name\":a_name, \"write_cnt\":item[1], \"is_seed\":in_seed,\n",
    "           \"hIndex\":hIndex, \"global_paper_cnt\":global_paper_cnt, \"global_citation_cnt\":global_citation_cnt, })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833cdedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# why there is duplicated names in S2 authors?\n",
    "for nid, data in g4.nodes(data=True):\n",
    "    if data.get('nodeType')=='Author' and data.get('name') == 'Wanxiang Che':\n",
    "        print(nid, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67811846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from apis.s2_api import SemanticScholarKit\n",
    "tmp_author_ids = ['2059027765', '2283920108', '2256319']\n",
    "s2 = SemanticScholarKit()\n",
    "authors_info = await s2.async_search_author_by_ids(author_ids=tmp_author_ids, with_abstract=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112696b8",
   "metadata": {},
   "source": [
    "Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f9a824",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_stat4 = []\n",
    "for n in g4.nodes:\n",
    "    if g4.nodes[n].get('nodeType') == 'Paper':\n",
    "        in_edges_info = g4.in_edges(n, data=True)\n",
    "        cite_cnt = sum([1 for u, v, data in in_edges_info if data.get('relationshipType') == 'CITES'])\n",
    "        paper_stat4.append((n, cite_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ccb2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_seed_paper_cnt = len(seed_paper_dois)\n",
    "tot_paper_cnt = len([nid for nid in g4.nodes if g4.nodes[nid].get('nodeType')=='Paper'])\n",
    "print(tot_seed_paper_cnt, tot_paper_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96944cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sorted_by_cite4 = sorted(paper_stat4, key=lambda item: item[1], reverse=True)\n",
    "print(sorted_by_cite4[0:30])\n",
    "\n",
    "for item in sorted_by_cite4[0:30]:\n",
    "    n = item[0]\n",
    "    cite_cnt = item[1]\n",
    "    # paper infos\n",
    "    title = g4.nodes[n].get('title')\n",
    "    in_seed = True if item[0] in seed_paper_dois else False\n",
    "    overall_cite_cnt = g4.nodes[n].get('citationCount')\n",
    "    influential_cite_cnt = g4.nodes[n].get('influentialCitationCount')\n",
    "    # author infors\n",
    "    hindex_lst = []\n",
    "    for u in g4.predecessors(n):\n",
    "        if g4.nodes[u].get('nodeType') == 'Author':\n",
    "            hIndex = g4.nodes[u].get('hIndex')\n",
    "            if hIndex:\n",
    "                hindex_lst.append(hIndex)\n",
    "            paperCount = g4.nodes[u].get('paperCount')\n",
    "            citationCount = g4.nodes[u].get('citationCount')\n",
    "    h_index = np.average(hindex_lst)\n",
    "\n",
    "    paper_info = {\"doi\":n, \"title\":title, \"if_seed\": in_seed,\n",
    "                  \"local_refs\":cite_cnt, \"global_refs\":overall_cite_cnt, \"inf_cite_cnt\":influential_cite_cnt,\n",
    "                  \"h_index\": h_index}\n",
    "    print(paper_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1333ad",
   "metadata": {},
   "source": [
    "### Graph Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe63c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from graph.graph_viz import GraphViz\n",
    "viz4 = GraphViz(g4, 'paper graph after author expansion')\n",
    "viz4.preprocessing()\n",
    "viz4.visulization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5459d6",
   "metadata": {},
   "source": [
    "### Similarity Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe61925",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_threshold = 0.7\n",
    "expanded_k_papers = 20\n",
    "all_paper_dois = [node['id'] for node in ps.nodes_json if node['labels'] == ['Paper']]\n",
    "non_seed_paper_dois = [node['id'] for node in ps.nodes_json if node['labels'] == ['Paper'] and node['id'] not in seed_paper_dois]\n",
    "paper_nodes_json = [node for node in ps.nodes_json \n",
    "                    if node['labels'] == ['Paper'] and \n",
    "                    node['properties'].get('title') is not None and node['properties'].get('abstract') is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80503813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate paper nodes similarity\n",
    "semantic_similar_pool = await ps.cal_embed_and_similarity(\n",
    "    paper_nodes_json=paper_nodes_json,\n",
    "    paper_dois_1=all_paper_dois, \n",
    "    paper_dois_2=all_paper_dois,\n",
    "    similarity_threshold=similarity_threshold,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8be805",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_similar_papers = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3430166",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(semantic_similar_pool) > 0:\n",
    "    candit_items = []\n",
    "    for item in semantic_similar_pool:\n",
    "        wt = item.get('properties', {}).get('weight')\n",
    "        if (wt > 0.7 and wt < 0.95) or (wt > 0.7 and wt < 0.95):\n",
    "            if item['startNodeId'] in seed_paper_dois and item['endNodeId'] not in seed_paper_dois:\n",
    "                candit_items.append((item['endNodeId'], wt))\n",
    "            elif item['startNodeId'] not in seed_paper_dois and item['endNodeId'] in seed_paper_dois:\n",
    "                candit_items.append((item['startNodeId'], wt))\n",
    "                \n",
    "sorted_items = sorted(candit_items, key=lambda item: item[1], reverse=True)\n",
    "\n",
    "# filter top k similarities\n",
    "similar_paper_dois = [x[0] for x in sorted_items[0:top_k_similar_papers]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e4d5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doi in similar_paper_dois:\n",
    "    # paper infos\n",
    "    title = g4.nodes[doi].get('title')\n",
    "    in_seed = True if doi in seed_paper_dois else False\n",
    "    overall_cite_cnt = g4.nodes[doi].get('citationCount')\n",
    "    influential_cite_cnt = g4.nodes[doi].get('influentialCitationCount')\n",
    "    # author infors\n",
    "    hindex_lst = []\n",
    "    for u in g4.predecessors(doi):\n",
    "        if g4.nodes[u].get('nodeType') == 'Author':\n",
    "            hIndex = g4.nodes[u].get('hIndex')\n",
    "            if hIndex:\n",
    "                hindex_lst.append(hIndex)\n",
    "            paperCount = g4.nodes[u].get('paperCount')\n",
    "            citationCount = g4.nodes[u].get('citationCount')\n",
    "    h_index = np.average(hindex_lst)\n",
    "\n",
    "    paper_info = {\"doi\":doi, \"title\":title, \"if_seed\": in_seed,\n",
    "                  \"global_refs\":overall_cite_cnt, \"inf_cite_cnt\":influential_cite_cnt,\n",
    "                  \"h_index\": h_index}\n",
    "    print(paper_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000922c8",
   "metadata": {},
   "source": [
    "## Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203ad994",
   "metadata": {},
   "source": [
    "### Add Similar to Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91cea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(semantic_similar_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4495241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.pg.add_graph_edges(semantic_similar_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd098d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps._add_items_to_graph(semantic_similar_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cfb4ff",
   "metadata": {},
   "source": [
    "### Graph Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a24102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from collections import Counter\n",
    "\n",
    "g5 = copy.deepcopy(ps.pg.graph)\n",
    "print(len(ps.nodes_json), len(ps.edges_json), len(g5.nodes), len(g5.edges))\n",
    "\n",
    "# check node types\n",
    "node_types = [g5.nodes[nid].get('nodeType') for nid in g5.nodes]\n",
    "node_types_cnt = Counter(node_types)\n",
    "# 按计数降序排序\n",
    "sorted_node_counts = node_types_cnt.most_common()\n",
    "print(sorted_node_counts)\n",
    "\n",
    "# check node types\n",
    "edge_types = [d.get('relationshipType') for u, v, d in g5.edges(data=True)]\n",
    "edge_types_cnt = Counter(edge_types)\n",
    "# 按计数降序排序\n",
    "sorted_egdes_counts = edge_types_cnt.most_common()\n",
    "print(sorted_egdes_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09a4746",
   "metadata": {},
   "source": [
    "Remove Isolated Nodes and Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eae53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from typing import List, Dict, Union, List, Set, Tuple, Hashable, Literal, Optional\n",
    "\n",
    "NodeType = Hashable # 节点类型通常是可哈希的\n",
    "\n",
    "def find_wcc_subgraphs(\n",
    "    graph,\n",
    "    target_nodes: Union[NodeType, List[NodeType], Set[NodeType], Tuple[NodeType]]\n",
    ") -> List[nx.MultiDiGraph]:\n",
    "    \"\"\"查找包含一个或多个指定节点的弱连通分量对应的子图。\n",
    "    Args:\n",
    "        graph: NetworkX MultiDiGraph 图对象。\n",
    "        target_nodes: 一个节点 ID，或一个包含节点 ID 的列表、集合或元组。\n",
    "    Returns:\n",
    "        一个包含所有找到的弱连通分量子图 (作为独立的 MultiDiGraph 副本) 的列表。\n",
    "        如果目标节点不在图中或找不到对应的连通分量，则返回空列表。\n",
    "        注意：如果多个目标节点在同一个连通分量中，该分量的子图只会被返回一次。\n",
    "    \"\"\"\n",
    "    # 1. 标准化输入为集合\n",
    "    if isinstance(target_nodes, (list, set, tuple)):\n",
    "        target_nodes_set = set(target_nodes)\n",
    "    else:\n",
    "        # 假设是单个节点 ID\n",
    "        target_nodes_set = {target_nodes}\n",
    "\n",
    "    # 2. 检查所有目标节点是否存在于图中\n",
    "    missing_nodes = target_nodes_set - set(graph.nodes())\n",
    "    if missing_nodes:\n",
    "        print(f\"警告：以下目标节点不在图中，将被忽略: {missing_nodes}\")\n",
    "        target_nodes_set -= missing_nodes # 移除不存在的节点\n",
    "\n",
    "    if not target_nodes_set:\n",
    "        print(\"错误：没有有效的目标节点可供查找。\")\n",
    "        return []\n",
    "\n",
    "    # 3. 查找并收集包含任何目标节点的弱连通分量\n",
    "    found_subgraphs = []\n",
    "    found_components_nodes = set() # 用于跟踪已添加的分量的节点集，避免重复\n",
    "\n",
    "    for component_nodes in nx.weakly_connected_components(graph):\n",
    "        component_set = set(component_nodes)\n",
    "        # 4. 检查当前分量是否包含任何目标节点 (使用集合交集)\n",
    "        if not target_nodes_set.isdisjoint(component_set): # 如果交集非空\n",
    "            # 检查这个分量是否已经添加过 (基于其节点集合)\n",
    "            # frozenset 是可哈希的，可以放入集合中\n",
    "            component_frozenset = frozenset(component_set)\n",
    "            if component_frozenset not in found_components_nodes:\n",
    "                # 5. 提取子图并添加到结果列表\n",
    "                subgraph = graph.subgraph(component_nodes).copy()\n",
    "                found_subgraphs.append(subgraph)\n",
    "                found_components_nodes.add(component_frozenset)\n",
    "\n",
    "                # Optional: 如果我们确定一个目标节点只能属于一个WCC,\n",
    "                # 可以在这里从 target_nodes_set 中移除 component_set 里的目标节点\n",
    "                # 以可能稍微提高后续迭代的效率，但这通常不是必需的\n",
    "                # target_nodes_set -= component_set\n",
    "\n",
    "    return found_subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29114584",
   "metadata": {},
   "outputs": [],
   "source": [
    "g6 = find_wcc_subgraphs(graph=g5, target_nodes=seed_paper_dois)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f479a719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from collections import Counter\n",
    "\n",
    "print(len(ps.nodes_json), len(ps.edges_json), len(g6.nodes), len(g6.edges))\n",
    "\n",
    "# check node types\n",
    "node_types = [g6.nodes[nid].get('nodeType') for nid in g6.nodes]\n",
    "node_types_cnt = Counter(node_types)\n",
    "# 按计数降序排序\n",
    "sorted_node_counts = node_types_cnt.most_common()\n",
    "print(sorted_node_counts)\n",
    "\n",
    "# check node types\n",
    "edge_types = [d.get('relationshipType') for u, v, d in g6.edges(data=True)]\n",
    "edge_types_cnt = Counter(edge_types)\n",
    "# 按计数降序排序\n",
    "sorted_egdes_counts = edge_types_cnt.most_common()\n",
    "print(sorted_egdes_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317f3e6a",
   "metadata": {},
   "source": [
    "Seed Paper Similar To"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e9601f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_paper_ids, after_paper_ids = [], []\n",
    "pre_sim_paper_ids, after_sim_paper_ids = [], []\n",
    "for nid in seed_paper_dois:\n",
    "    pre_nodes_ids = g6.predecessors(nid)\n",
    "    pre_paper_ids.extend([x for x in pre_nodes_ids if g6.nodes[x].get('nodeType') == 'Paper' and x not in seed_paper_dois]) \n",
    "    for pre_id in pre_paper_ids:\n",
    "        print(pre_id, nid)\n",
    "        edge_type = g6[pre_id][nid].get('relationshipType')\n",
    "        if edge_type == 'SIMILAR_TO':\n",
    "            pre_sim_paper_ids.append(pre_id)\n",
    "\n",
    "    after_nodes_ids = g6.successors(nid)\n",
    "    after_paper_ids.extend([x for x in after_nodes_ids if g6.nodes[x].get('nodeType') == 'Paper' and x not in seed_paper_dois]) \n",
    "    for after_id in after_paper_ids:\n",
    "        edge_type = g6[nid][after_id].get('relationshipType')\n",
    "        if edge_type == 'SIMILAR_TO':\n",
    "            after_sim_paper_ids.append(pre_id)\n",
    "\n",
    "print(len(pre_paper_ids), len(pre_sim_paper_ids), len(after_paper_ids), len(after_sim_paper_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04779da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in g6.predecessors('10.48550/arXiv.2412.10415'):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f34350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "g6['10.48550/arXiv.2403.02901']['10.48550/arXiv.2412.10415']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b320381c",
   "metadata": {},
   "source": [
    "### Still Graph Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e2180f",
   "metadata": {},
   "source": [
    "Get k-hop neighbor graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485fa498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from typing import Iterable, Set, Hashable # For type hinting\n",
    "\n",
    "def get_k_hop_neighbors(graph: nx.MultiDiGraph,\n",
    "                        start_nodes: Iterable[Hashable],\n",
    "                        k: int) -> Set[Hashable]:\n",
    "    \"\"\"\n",
    "    查找 MultiDiGraph 中一个或多个起始节点的 k-hop 邻居（忽略边的方向）。\n",
    "    通过为每个起始节点计算 ego_graph 并合并结果实现。\n",
    "\n",
    "    Args:\n",
    "        graph: NetworkX MultiDiGraph 对象。\n",
    "        start_nodes: 一个包含一个或多个起始节点的可迭代对象 (如 list, set)。\n",
    "        k: 跳数 (hops)。\n",
    "\n",
    "    Returns:\n",
    "        一个包含所有距离任一<0xE8><0xB5><0xB7>始节点 k 跳内的节点的集合（包括起始节点）。\n",
    "    \"\"\"\n",
    "    # 1. 创建一个无向图视图/副本 (只做一次)\n",
    "    #    对于仅查找节点，nx.Graph 通常足够且更快\n",
    "    undirected_graph = nx.Graph(graph)\n",
    "    # 或者 undirected_graph = graph.to_undirected() # 转为 MultiGraph\n",
    "\n",
    "    all_k_hop_neighbors = set()\n",
    "    valid_start_nodes_found = False\n",
    "\n",
    "    for start_node in start_nodes:\n",
    "        if start_node not in undirected_graph:\n",
    "            print(f\"警告: 起始节点 {start_node} 不在图中，将被忽略。\")\n",
    "            continue # 跳过不在图中的起始节点\n",
    "\n",
    "        valid_start_nodes_found = True\n",
    "        # 2. 为当前有效的起始节点计算 ego_graph\n",
    "        #    ego_graph 包含中心节点和 k-hop 内的所有节点\n",
    "        ego = nx.ego_graph(undirected_graph, start_node, radius=k)\n",
    "\n",
    "        # 3. 将当前 ego_graph 的节点合并到总集合中\n",
    "        all_k_hop_neighbors.update(ego.nodes())\n",
    "\n",
    "    if not valid_start_nodes_found and start_nodes:\n",
    "         print(\"警告: 所有提供的起始节点都不在图中。\")\n",
    "\n",
    "    return all_k_hop_neighbors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989fcd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_nodes = seed_paper_dois\n",
    "\n",
    "k = 1\n",
    "hop_1_neighbors = get_k_hop_neighbors(g6, start_nodes, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8c9f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "hop_2_neighbors = get_k_hop_neighbors(g6, start_nodes, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66934c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "hop_3_neighbors = get_k_hop_neighbors(g6, start_nodes, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a613a340",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "hop_4_neighbors = get_k_hop_neighbors(g6, start_nodes, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510f3be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "hop_5_neighbors = get_k_hop_neighbors(g6, start_nodes, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe1f293",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_view = nx.Graph(g6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c758a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_1_paper_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a15ee14",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in g.predecessors('10.1038/s42256-024-00832-8') if x in seed_paper_dois]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eccb2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "g6['10.48550/arXiv.2503.01424']['10.1038/s42256-024-00832-8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d074062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "def get_edge_data_for_paths(\n",
    "    graph: nx.MultiDiGraph,\n",
    "    paths: List[List[Any]]\n",
    ") -> List[List[Optional[Dict[str, Any]]]]:\n",
    "    \"\"\"\n",
    "    为给定的节点路径列表，从原始 MultiDiGraph 中提取对应的边数据。\n",
    "\n",
    "    对于路径中的每一步 (u, v)，它会尝试查找 u->v 或 v->u 的边，\n",
    "    并返回找到的第一个边的属性字典。\n",
    "\n",
    "    Args:\n",
    "        graph: 原始的 NetworkX MultiDiGraph 对象，包含边的属性数据。\n",
    "        paths: 一个列表，其中每个元素是表示一条路径的节点列表\n",
    "               (例如由 nx.all_simple_paths 找到)。\n",
    "\n",
    "    Returns:\n",
    "        一个列表，结构与 paths 对应。每个内部列表包含对应路径上\n",
    "        每条边的属性数据字典。如果在原始图中找不到对应步骤的边\n",
    "        (理论上不应发生，如果路径有效)，则该步骤的数据为 None。\n",
    "        如果 u 和 v 之间有多条边，默认返回找到的第一条边的数据。\n",
    "    \"\"\"\n",
    "    paths_info = []\n",
    "    if not graph.is_multigraph():\n",
    "        # 提示：虽然输入类型是 MultiDiGraph，做一个检查或转换可能更健壮\n",
    "        print(\"警告：输入图不是 MultiDiGraph，行为可能与预期不同。\")\n",
    "\n",
    "    for path in paths:\n",
    "        current_path_edge_data = []\n",
    "        # 遍历路径中的每对连续节点 (u, v)\n",
    "        for i in range(len(path) - 1):\n",
    "            u = path[i]\n",
    "            v = path[i+1]\n",
    "            edge_data = None\n",
    "\n",
    "            # 尝试查找 u -> v 的边\n",
    "            # graph.get_edge_data(u, v) 返回一个字典，key 是边的 key，value 是属性字典\n",
    "            # 如果不存在 u -> v 的边，返回 None\n",
    "            forward_edges_data = graph.get_edge_data(u, v)\n",
    "            if forward_edges_data:\n",
    "                # 获取找到的第一个前向边的数据 (任意 key)\n",
    "                # list(forward_edges_data.values())[0] 获取第一个key对应的值（属性字典）\n",
    "                edge_data = list(forward_edges_data.values())[0]\n",
    "                current_path_edge_data.append((u, v, edge_data))\n",
    "            else:\n",
    "                # 如果没有 u -> v，尝试查找 v -> u 的边\n",
    "                backward_edges_data = graph.get_edge_data(v, u)\n",
    "                if backward_edges_data:\n",
    "                    # 获取找到的第一个反向边的数据 (任意 key)\n",
    "                    edge_data = list(backward_edges_data.values())[0]\n",
    "                    current_path_edge_data.append((v, u, edge_data))\n",
    "                else:\n",
    "                    current_path_edge_data.append((None, None, None))\n",
    "\n",
    "            # 如果 edge_data 为 None，可能表示路径与原始图不一致或存在问题\n",
    "            if edge_data is None:\n",
    "                 print(f\"警告：在路径 {path} 中，未能在原始 MultiDiGraph 中找到节点对 ({u}, {v}) 或 ({v}, {u}) 之间的任何边。\")\n",
    "\n",
    "        # 将当前路径的所有边数据列表添加到总结果中\n",
    "        paths_info.append(current_path_edge_data)\n",
    "\n",
    "    return paths_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfce2c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1\n",
    "hop_1_paper_ids = []\n",
    "hop_1_paper_paths = []\n",
    "hop_1_paper_paths_info = []\n",
    "for id in hop_1_neighbors:\n",
    "    node_data = g6.nodes[id]\n",
    "    if node_data.get('nodeType') == 'Paper':\n",
    "        paths = []\n",
    "        for seed_doi in seed_paper_dois:\n",
    "            paths_generator = nx.all_simple_paths(\n",
    "                g_view,\n",
    "                source=id,\n",
    "                target=seed_doi,\n",
    "                cutoff=k\n",
    "            )\n",
    "            for path in paths_generator:\n",
    "                paths.append(path)\n",
    "        paths_info = get_edge_data_for_paths(g6, paths)\n",
    "\n",
    "        hop_1_paper_ids.append(id)\n",
    "        hop_1_paper_paths.append(paths)\n",
    "        hop_1_paper_paths_info.append(paths_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b938bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_1_paper_paths_info[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e5ca48",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_1_paper_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86cfc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "hop_3_paper_ids = []\n",
    "hop_3_paper_paths = []\n",
    "hop_3_paper_paths_info = []\n",
    "for id in hop_3_neighbors:\n",
    "    node_data = g6.nodes[id]\n",
    "    if node_data.get('nodeType') == 'Paper':\n",
    "        paths = []\n",
    "        for seed_doi in seed_paper_dois:\n",
    "            paths_generator = nx.all_simple_paths(\n",
    "                g_view,\n",
    "                source=id,\n",
    "                target=seed_doi,\n",
    "                cutoff=k\n",
    "            )\n",
    "            for path in paths_generator:\n",
    "                paths.append(path)\n",
    "        paths_info = get_edge_data_for_paths(g6, paths)\n",
    "\n",
    "        hop_3_paper_ids.append(id)\n",
    "        hop_3_paper_paths.append(paths)\n",
    "        hop_3_paper_paths_info.append(paths_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f377c706",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_3_paper_paths_info[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024a3833",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hop_2_paper_paths_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b371c5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 包含无效起始节点的示例\n",
    "start_nodes_with_invalid = [0, 99] # 99 不在图中\n",
    "k = 2\n",
    "k_hop_neighbors_invalid = get_k_hop_neighbors(graph: nx.MultiDiGraph,\n",
    "(G, start_nodes_with_invalid, k)\n",
    "print(f\"起始节点 {start_nodes_with_invalid} 的 {k}-hop 邻居 (Ego方法): {k_hop_neighbors_invalid}\")\n",
    "\n",
    "# 如果希望结果不包含起始节点本身\n",
    "k_hop_neighbors_excluding_starts = k_hop_neighbors - set(start_nodes)\n",
    "print(f\"起始节点 {start_nodes} 的 {k}-hop 邻居 (Ego方法, 不含自身): {k_hop_neighbors_excluding_starts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da3a460",
   "metadata": {},
   "outputs": [],
   "source": [
    "    undirected_view = nx.Graph(graph)\n",
    "\n",
    "    # 3. 使用 networkx.all_simple_paths 查找无向视图中的所有简单路径。\n",
    "    #    这个函数保证了路径中没有重复的节点（即无环）。\n",
    "    #    它返回一个生成器，这对于可能存在大量路径的情况更节省内存。\n",
    "    paths_generator = nx.all_simple_paths(\n",
    "        undirected_view,\n",
    "        source=source,\n",
    "        target=target,\n",
    "        cutoff=cutoff\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea3aee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0515660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f95e92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_all_undirected_simple_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0776632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_paper_dois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a122b21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g5 = ps.pg.graph\n",
    "start_node = '10.48550/arXiv.2302.00093'\n",
    "end_node = seed_paper_dois[0]\n",
    "\n",
    "print(f\"查找从节点 '{start_node}' 到节点 '{end_node}' 的所有简单路径 (忽略方向):\")\n",
    "\n",
    "# 3. 调用函数查找路径\n",
    "try:\n",
    "    all_paths_gen = find_all_undirected_simple_paths(g5, start_node, end_node, 5)\n",
    "\n",
    "    # 4. 遍历生成器并打印路径\n",
    "    found_paths_list = list(all_paths_gen) # 将生成器转换为列表以便计数和打印\n",
    "\n",
    "    if found_paths_list:\n",
    "        print(f\"共找到 {len(found_paths_list)} 条路径:\")\n",
    "        for i, path in enumerate(found_paths_list):\n",
    "            print(f\"  路径 {i+1}: {path}\")\n",
    "    else:\n",
    "        print(\"未找到任何路径。\")\n",
    "\n",
    "except nx.NodeNotFound as e:\n",
    "    print(f\"错误: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911d197d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4be414c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e019df",
   "metadata": {},
   "outputs": [],
   "source": [
    "await ps.construct_paper_graph(\n",
    "    search_citation = 'both',  # 'both',\n",
    "    search_author = True,\n",
    "    find_recommend = True,\n",
    "    if_related_topic = True,\n",
    "    if_expanded_citations  = 'reference',  #  'reference',\n",
    "    if_expanded_authors = True,\n",
    "    if_add_similarity = True,\n",
    "    similarity_threshold = 0.7,\n",
    "    expanded_k_papers = 20,\n",
    "    expanded_l_authors = 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8528b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ps.nodes_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28ad6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ps.edges_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30642b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = ps.pg.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4824d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(g.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aa4eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(g.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b36911a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check node types\n",
    "set([g.nodes[nid].get('nodeType') for nid in g.nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88de0b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats of node types\n",
    "node_types = [g.nodes[nid].get('nodeType') for nid in g.nodes]\n",
    "\n",
    "from collections import Counter\n",
    "counts = Counter(node_types)\n",
    "\n",
    "# 按计数降序排序\n",
    "sorted_counts = counts.most_common()\n",
    "sorted_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6f7903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats of edge types\n",
    "edge_types = [d.get('relationshipType') for u, v, d in g.edges(data=True)]\n",
    "print(set(edge_types))\n",
    "\n",
    "from collections import Counter\n",
    "counts = Counter(edge_types)\n",
    "\n",
    "# 按计数降序排序\n",
    "sorted_counts = counts.most_common()\n",
    "print(sorted_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ba695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed papers\n",
    "seed_paper_dois = [nid for nid in g.nodes \n",
    "                        if g.nodes[nid].get('nodeType')=='Paper' and\n",
    "                           g.nodes[nid].get('from_seed') == True]\n",
    "seed_paper_nodes = [g.nodes[nid] for nid in g.nodes \n",
    "                        if g.nodes[nid].get('nodeType')=='Paper' and\n",
    "                           g.nodes[nid].get('from_seed') == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87510ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(seed_paper_dois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9822600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expanded papers with citation chain\n",
    "# paper with cites but no citing, paper not in seed dois\n",
    "paper_w_ref_dois = []\n",
    "paper_w_ref_nodes = []\n",
    "\n",
    "for nid in g.nodes:\n",
    "    node = g.nodes[nid]\n",
    "    if node.get('nodeType')=='Paper' and nid not in seed_paper_dois:\n",
    "        out_edges_info = g.out_edges(nid, data=True)\n",
    "        cnt = 0\n",
    "        for u, v, data in out_edges_info:\n",
    "            if data.get('relationshipType') == 'CITES':\n",
    "               cnt += 1\n",
    "        if cnt > 0:\n",
    "            paper_w_ref_dois.append(nid)\n",
    "            paper_w_ref_nodes.append(node)\n",
    "\n",
    "print(paper_w_ref_dois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc02382",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_paper_w_ref_dois = [x for x in paper_w_ref_dois if x not in seed_paper_dois]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6bb94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dois = []\n",
    "for doi in expanded_paper_w_ref_dois:\n",
    "    out_edges_info = g.out_edges(doi, data=True)\n",
    "    ref_cnt = sum([1 for u, v, data in out_edges_info if data.get('relationshipType') == 'CITES'])\n",
    "    print(doi, ref_cnt)\n",
    "    if ref_cnt > 2:\n",
    "        filtered_dois.append(doi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39b93a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.out_edges('10.48550/arXiv.2408.16498', data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aa46b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = '10.48550/arXiv.2408.16498'\n",
    "for v in g.successors(n):\n",
    "    data = g[n][v]\n",
    "    if data.get('relationshipType') == 'CITES':\n",
    "        print(g.nodes[v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f45f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_dois)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff27070",
   "metadata": {},
   "source": [
    "Check cross refs  \n",
    "- most refered to\n",
    "- precessor of seed dois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1ea0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_stat = []\n",
    "for n in g.nodes:\n",
    "    if g.nodes[n].get('nodeType') == 'Paper':\n",
    "        in_edges_info = g.in_edges(n, data=True)\n",
    "        cite_cnt = sum([1 for u, v, data in in_edges_info if data.get('relationshipType') == 'CITES'])\n",
    "        sim_cnt = sum([1 for u, v, data in in_edges_info if data.get('relationshipType') == 'SIMILAR_TO'])\n",
    "        paper_stat.append((n, cite_cnt, sim_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85a5f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8f8e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_cite = sorted(paper_stat, key=lambda item: item[1], reverse=True)\n",
    "print(sorted_by_cite[0:20])\n",
    "\n",
    "for item in sorted_by_cite[0:20]:\n",
    "    n = item[0]\n",
    "    cite_cnt = item[1]\n",
    "    # paper infos\n",
    "    title = g.nodes[n].get('title')\n",
    "    overall_cite_cnt = g.nodes[n].get('citationCount')\n",
    "    influential_cite_cnt = g.nodes[n].get('influentialCitationCount')\n",
    "    # author infors\n",
    "    hindex_lst = []\n",
    "    for u in g.predecessors(n):\n",
    "        if g.nodes[u].get('nodeType') == 'Author':\n",
    "            hIndex = g.nodes[u].get('hIndex')\n",
    "            if hIndex:\n",
    "                hindex_lst.append(hIndex)\n",
    "            paperCount = g.nodes[u].get('paperCount')\n",
    "            citationCount = g.nodes[u].get('citationCount')\n",
    "    h_index = np.average(hindex_lst)\n",
    "\n",
    "    paper_info = {\"doi\":n, \"title\":title, \n",
    "                  \"local_refs\":cite_cnt, \"global_refs\":overall_cite_cnt, \"inf_cite_cnt\":influential_cite_cnt,\n",
    "                  \"h_index\": h_index}\n",
    "    print(paper_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc7b7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_sim = sorted(paper_stat, key=lambda item: item[2], reverse=True)\n",
    "print(sorted_by_sim[0:20])\n",
    "\n",
    "for item in sorted_by_sim[0:20]:\n",
    "    n = item[0]\n",
    "    sim_cnt = item[2]\n",
    "    title = g.nodes[n].get('title')\n",
    "    overall_cite_cnt = g.nodes[n].get('citationCount')\n",
    "    influential_cite_cnt = g.nodes[n].get('influentialCitationCount')\n",
    "    # author infors\n",
    "    hindex_lst = []\n",
    "    for u in g.predecessors(n):\n",
    "        if g.nodes[u].get('nodeType') == 'Author':\n",
    "            hIndex = g.nodes[u].get('hIndex')\n",
    "            if hIndex:\n",
    "                hindex_lst.append(hIndex)\n",
    "            paperCount = g.nodes[u].get('paperCount')\n",
    "            citationCount = g.nodes[u].get('citationCount')\n",
    "    h_index = np.average(hindex_lst)\n",
    "\n",
    "    paper_info = {\"doi\":n, \"title\":title, \n",
    "                  \"local_sims\":sim_cnt, \"global_refs\":overall_cite_cnt, \"inf_cite_cnt\":influential_cite_cnt,\n",
    "                  \"h_index\": h_index}\n",
    "    print(paper_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6982774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check key authors in graph\n",
    "author_stat = []\n",
    "for n in g.nodes:\n",
    "    if g.nodes[n].get('nodeType') == 'Author':\n",
    "        out_edges_info = g.out_edges(n, data=True)\n",
    "        writes_cnt = sum([1 for u, v, data in out_edges_info if data.get('relationshipType') == 'WRITES'])\n",
    "        author_stat.append((n, writes_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0b2a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_writes = sorted(author_stat, key=lambda item: item[1], reverse=True)\n",
    "print(sorted_by_writes[0:20])\n",
    "\n",
    "for item in sorted_by_writes[0:20]:\n",
    "    n = item[0]\n",
    "    print(g.nodes[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e838ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.explored_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ea649a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in graph[0].graph.nodes:\n",
    "    item = graph[0].graph.nodes[id]\n",
    "    if item.get('nodeType') is None:\n",
    "        print(id, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14049e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(nodes_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e42ad93",
   "metadata": {},
   "outputs": [],
   "source": [
    "set([d['relationshipType'] for u, v, d in graph[0].graph.edges(data=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a2c951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node types and edges types to keep\n",
    "filtered_node_labels = ['Paper', 'Topic', 'Author']\n",
    "filtered_edges_labels = ['CITES', 'DISCUSS', 'WRITES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52f4213",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = graph[0].graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339de557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of node IDs to iterate over\n",
    "node_ids_to_check = list(G.nodes) # <--- Create a static list here\n",
    "\n",
    "# filter node types\n",
    "for id in node_ids_to_check: # <-- Iterate over the list\n",
    "    # Check if the node still exists (important if edges might remove nodes indirectly, though less likely here)\n",
    "    if id in G:\n",
    "        item = G.nodes[id]\n",
    "        node_type = item.get('nodeType')\n",
    "        if node_type not in filtered_node_labels:\n",
    "            G.remove_node(id) # Modify the original graph G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf9baea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of edge tuples (u, v, data) to iterate over\n",
    "edge_list_copy = list(G.edges(data=True)) # <--- Create a static list here\n",
    "\n",
    "# filter edge types\n",
    "for u, v, d in edge_list_copy: # <-- Iterate over the copy\n",
    "    edge_type = d.get('relationshipType') # Use .get() for safety if attr might be missing\n",
    "    if edge_type not in filtered_edges_labels:\n",
    "         # Check if edge still exists (might have been removed if graph allows parallel edges and one was removed)\n",
    "         if G.has_edge(u, v):\n",
    "            G.remove_edge(u, v) # Modify the original graph G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64c7ec79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([1,2,3]) - set([1, 2,3,4, 5,6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c8ef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "G.remove_edge(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e861433",
   "metadata": {},
   "outputs": [],
   "source": [
    "set([graph[0].graph.nodes[x]['nodeType'] for x in graph[0].graph.nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dac349",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = False\n",
    "if a:\n",
    "    print(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25d68d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1501a5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_nodes_from([(4, {\"color\": \"red\"}), (5, {\"color\": \"green\"})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d767059",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e50252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_nodes_from([(4, {\"color\": \"blue\"})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1e8da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c418ac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_nodes_from([(4, {\"name\": \"No.4\"})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c017868",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1110a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jiezi4ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
