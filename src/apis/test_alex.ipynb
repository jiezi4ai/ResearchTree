{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22d0b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import asyncio\n",
    "from typing import List, Dict, Optional, Any, Callable, Union\n",
    "import pyalex\n",
    "from pyalex import Works, Authors, Concepts, Institutions # Import necessary pyalex classes including Institutions\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- Configuration ---\n",
    "# Set your email for the OpenAlex polite pool (optional but recommended)\n",
    "# pyalex.config.email = \"your_email@example.com\"\n",
    "\n",
    "MAX_CNT = 10000\n",
    "BATCH_SIZE = 50\n",
    "DEFAULT_MAX_CONCURRENCY = 10\n",
    "DEFAULT_SLEEP_INTERVAL = 0.1\n",
    "OPENALEX_MAX_PER_PAGE = 200\n",
    "\n",
    "class OpenAlexKit:\n",
    "    def __init__(\n",
    "        self,\n",
    "        email: str = None,\n",
    "        max_concurrency: int = DEFAULT_MAX_CONCURRENCY,\n",
    "        sleep_interval: float = DEFAULT_SLEEP_INTERVAL,\n",
    "    ):\n",
    "        if max_concurrency <= 0:\n",
    "            raise ValueError(\"max_concurrency must be a positive integer\")\n",
    "        if sleep_interval < 0:\n",
    "            raise ValueError(\"sleep_interval must be non-negative\")\n",
    "\n",
    "        if email:\n",
    "            pyalex.config.email = email\n",
    "            logger.info(f\"OpenAlex email set for polite pool: {email}\")\n",
    "        else:\n",
    "            logger.warning(\"OpenAlex email not set. Using anonymous pool (lower rate limits).\")\n",
    "\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        self.max_cnt = MAX_CNT\n",
    "        self.semaphore = asyncio.Semaphore(max_concurrency)\n",
    "        self.sleep_interval = sleep_interval\n",
    "        logger.info(f\"OpenAlexKit initialized with max_concurrency={max_concurrency}, sleep_interval={sleep_interval}s\")\n",
    "\n",
    "    async def _execute_sync_with_controls(self, sync_func: Callable, *args: Any, **kwargs: Any) -> Any:\n",
    "        # (Implementation remains the same as previous version)\n",
    "        async with self.semaphore:\n",
    "            func_name = sync_func.__name__\n",
    "            logger.debug(f\"Semaphore acquired for {func_name}. Executing...\")\n",
    "            try:\n",
    "                result = await asyncio.to_thread(sync_func, *args, **kwargs)\n",
    "                logger.debug(f\"Execution of {func_name} completed. Result type: {type(result)}. Sleeping for {self.sleep_interval}s.\")\n",
    "                await asyncio.sleep(self.sleep_interval)\n",
    "                return result\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Exception during controlled execution of {func_name}: {e}\", exc_info=True)\n",
    "                logger.debug(f\"Sleeping for {self.sleep_interval}s after error in {func_name}.\")\n",
    "                await asyncio.sleep(self.sleep_interval)\n",
    "                if \"search\" in func_name or \"get\" in func_name:\n",
    "                     return []\n",
    "                raise e\n",
    "            finally:\n",
    "                logger.debug(f\"Semaphore released for {func_name}.\")\n",
    "\n",
    "\n",
    "    # --- Synchronous Helper Methods ---\n",
    "\n",
    "    # Updated _validate_openalex_ids function\n",
    "    def _validate_openalex_ids(self, entity_type: str, ids: List[str]) -> List[str]:\n",
    "        \"\"\"\n",
    "        Validates input IDs and returns only the native OpenAlex IDs\n",
    "        matching the expected entity type.\n",
    "        It recognizes DOI URLs (for works), ORCID URLs (for authors),\n",
    "        and ROR URLs (for institutions) as valid input formats but does not\n",
    "        return them in the output list, logging warnings instead.\n",
    "\n",
    "        Returns a list of validated native OpenAlex IDs (e.g., W..., A...).\n",
    "        \"\"\"\n",
    "        prefix_map = {\"work\": \"W\", \"author\": \"A\", \"venue\": \"V\", \"concept\": \"C\", \"institution\": \"I\"}\n",
    "        entity_type_lower = entity_type.lower()\n",
    "        entity_prefix = prefix_map.get(entity_type_lower)\n",
    "        # No error if entity_prefix is None, just means we can only validate by structure if URL used\n",
    "\n",
    "        valid_ids = []\n",
    "        recognized_external_count = 0\n",
    "        skipped_count = 0\n",
    "        processed_ids = set() # Keep track of processed IDs to avoid duplicate warnings/processing\n",
    "\n",
    "        for item_id_raw in ids:\n",
    "            if not isinstance(item_id_raw, str) or not item_id_raw.strip():\n",
    "                # Skip empty or non-string entries silently or log if needed\n",
    "                continue\n",
    "\n",
    "            item_id = item_id_raw.strip()\n",
    "\n",
    "            # Avoid processing the same ID multiple times if it appears duplicated in the input list\n",
    "            if item_id in processed_ids:\n",
    "                continue\n",
    "            processed_ids.add(item_id)\n",
    "\n",
    "            # 1. Check for Native OpenAlex ID (URL or direct)\n",
    "            is_native = False\n",
    "            native_id_to_add = None\n",
    "            if item_id.startswith(\"https://openalex.org/\"):\n",
    "                potential_id = item_id.split(\"/\")[-1]\n",
    "                # Check if the extracted part starts with the *expected* prefix (if known)\n",
    "                if entity_prefix and potential_id.startswith(entity_prefix):\n",
    "                    native_id_to_add = potential_id\n",
    "                    is_native = True\n",
    "                # Or if type is unknown, check if it starts with *any* OA prefix\n",
    "                elif not entity_prefix and any(potential_id.startswith(p) for p in prefix_map.values()):\n",
    "                     native_id_to_add = potential_id # Assume valid if type unknown\n",
    "                     is_native = True\n",
    "                # Else: Prefix mismatch or not an OA structure after URL prefix\n",
    "            elif entity_prefix and item_id.startswith(entity_prefix):\n",
    "                 native_id_to_add = item_id\n",
    "                 is_native = True\n",
    "\n",
    "            if is_native and native_id_to_add:\n",
    "                valid_ids.append(native_id_to_add)\n",
    "                continue # Found native ID, move to next item\n",
    "\n",
    "            # 2. Check for recognized External IDs (only if entity type matches)\n",
    "            is_external_recognized = False\n",
    "            external_type = None\n",
    "            if entity_type_lower == \"work\" and item_id.startswith(\"https://doi.org/\"):\n",
    "                 is_external_recognized = True\n",
    "                 external_type = \"DOI\"\n",
    "            elif entity_type_lower == \"author\" and item_id.startswith(\"https://orcid.org/\"):\n",
    "                 is_external_recognized = True\n",
    "                 external_type = \"ORCID\"\n",
    "            elif entity_type_lower == \"institution\" and item_id.startswith(\"https://ror.org/\"):\n",
    "                 is_external_recognized = True\n",
    "                 external_type = \"ROR\"\n",
    "\n",
    "            if is_external_recognized:\n",
    "                recognized_external_count += 1\n",
    "                valid_ids.append(item_id)\n",
    "                logger.warning(f\"Recognized external ID format ({external_type}: {item_id}) for type '{entity_type}', but it will be skipped by this function. Modify calling method to handle {external_type} lookups if needed.\")\n",
    "\n",
    "            # 3. If none matched (and not native)\n",
    "            # Log specific warnings for prefix mismatches vs general invalid format\n",
    "            is_other_oa_id = False\n",
    "            if any(item_id.startswith(p) or (item_id.startswith(\"https://openalex.org/\") and any(item_id.split(\"/\")[-1].startswith(p) for p in prefix_map.values())) for p in prefix_map.values()):\n",
    "                 # It looks like an OpenAlex ID but didn't match the expected type or structure checks above\n",
    "                 is_other_oa_id = True\n",
    "\n",
    "            if is_other_oa_id:\n",
    "                 logger.warning(f\"ID {item_id} looks like an OpenAlex ID but does not match expected type '{entity_type}' or has unexpected format. Skipping.\")\n",
    "            else:\n",
    "                 logger.warning(f\"Invalid or unrecognized ID format for type '{entity_type}' skipped: {item_id}\")\n",
    "            skipped_count += 1\n",
    "\n",
    "\n",
    "        if recognized_external_count > 0:\n",
    "             logger.info(f\"Recognized {recognized_external_count} external IDs (DOI/ORCID/ROR) for entity type '{entity_type}'.\")\n",
    "        if skipped_count > 0:\n",
    "             logger.info(f\"Skipped {skipped_count} other invalid, non-matching, or empty IDs for type '{entity_type}'.\")\n",
    "\n",
    "        # Return unique list of valid native IDs\n",
    "        # Using dict.fromkeys preserves order while removing duplicates\n",
    "        unique_valid_native_ids = list(dict.fromkeys(valid_ids))\n",
    "        logger.info(f\"Validation for type '{entity_type}' completed. Returning {len(unique_valid_native_ids)} unique native OpenAlex IDs.\")\n",
    "        return unique_valid_native_ids\n",
    "\n",
    "    # --- Other Sync Methods (_sync_get_works_by_ids, _sync_get_authors_by_ids, etc.) ---\n",
    "    # (These remain unchanged from the previous version, as they rely on the output\n",
    "    #  of _validate_openalex_ids which still returns a List[str] of native IDs)\n",
    "\n",
    "    def _sync_get_works_by_ids(self, work_ids: List[str]) -> List[Dict]:\n",
    "        \"\"\"Fetches work details for a batch of OpenAlex Work IDs.\"\"\"\n",
    "        logger.info(f\"_sync_get_works_by_ids: Thread started for batch ({len(work_ids)} IDs, first 5: {work_ids[:5]}...).\")\n",
    "        if not work_ids:\n",
    "            return []\n",
    "        try:\n",
    "            filter_query = \"|\".join(work_ids)\n",
    "            results = Works().filter(openalex_id=filter_query).get()\n",
    "            logger.info(f\"_sync_get_works_by_ids: API call successful for batch (first 5: {work_ids[:5]}...), returning {len(results)} items.\")\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in _sync_get_works_by_ids for batch (first 5 IDs: {work_ids[:5]}...): {e}\", exc_info=True)\n",
    "            return []\n",
    "\n",
    "    def _sync_get_authors_by_ids(self, author_ids: List[str]) -> List[Dict]:\n",
    "        \"\"\"Fetches author details for a batch of OpenAlex Author IDs.\"\"\"\n",
    "        logger.info(f\"_sync_get_authors_by_ids: Thread started for batch ({len(author_ids)} IDs, first 5: {author_ids[:5]}...).\")\n",
    "        if not author_ids:\n",
    "            return []\n",
    "        try:\n",
    "            filter_query = \"|\".join(author_ids)\n",
    "            results = Authors().filter(openalex_id=filter_query).get()\n",
    "            logger.info(f\"_sync_get_authors_by_ids: API call successful for batch (first 5: {author_ids[:5]}...), returning {len(results)} items.\")\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in _sync_get_authors_by_ids for batch (first 5 IDs: {author_ids[:5]}...): {e}\", exc_info=True)\n",
    "            return []\n",
    "\n",
    "    # ... (rest of the _sync methods: _sync_search_works_by_keywords, _sync_get_work_references, _sync_get_work_citations remain the same) ...\n",
    "    def _sync_search_works_by_keywords(self, **kwargs) -> List[Dict]:\n",
    "        # (Implementation remains the same as previous version)\n",
    "        query = kwargs.get('query', None)\n",
    "        limit = kwargs.get('limit', self.max_cnt)\n",
    "        logger.info(f\"_sync_search_works_by_keywords: Thread started for query '{str(query)[:50]}...' with limit {limit}.\")\n",
    "        try:\n",
    "            works_query = Works()\n",
    "            if query: works_query = works_query.search(query)\n",
    "            # Apply filters... (year, type, oa, venue, concepts, pub_date, citations) - Logic unchanged\n",
    "            if kwargs.get('year'): works_query = works_query.filter(publication_year=int(kwargs['year']))\n",
    "            # ... other filters ...\n",
    "            if kwargs.get('min_citation_count') is not None: works_query = works_query.filter(cited_by_count=f\">{int(kwargs['min_citation_count'])}\")\n",
    "            # Apply sorting... - Logic unchanged\n",
    "            sort_param = kwargs.get('sort')\n",
    "            if sort_param:\n",
    "                sort_field_map = {'relevance': 'relevance_score', 'citationCount': 'cited_by_count', 'publicationDate': 'publication_date'}\n",
    "                # ... sorting logic ...\n",
    "                if field_s2 in sort_field_map: works_query = works_query.sort(**{sort_field_map[field_s2]: direction})\n",
    "\n",
    "            # Fetching Results with Pagination - Logic unchanged\n",
    "            paper_metadata = []\n",
    "            processed_count = 0\n",
    "            page_size = min(limit, OPENALEX_MAX_PER_PAGE)\n",
    "            if limit <= 0: page_size = OPENALEX_MAX_PER_PAGE\n",
    "            logger.info(f\"Executing OpenAlex search query with limit={limit}, page_size={page_size}...\")\n",
    "            for page in works_query.paginate(per_page=page_size, n_max=limit):\n",
    "                 if not page: break\n",
    "                 num_to_add = min(len(page), limit - processed_count)\n",
    "                 paper_metadata.extend(page[:num_to_add])\n",
    "                 processed_count += num_to_add\n",
    "                 if processed_count >= limit: break\n",
    "            logger.info(f\"_sync_search_works_by_keywords: API call successful for query '{str(query)[:50]}...', returning {len(paper_metadata)} items.\")\n",
    "            return paper_metadata\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in _sync_search_works_by_keywords for query '{str(query)[:50]}...': {e}\", exc_info=True)\n",
    "            return []\n",
    "\n",
    "    def _sync_get_work_references(self, work_id: str, limit: int) -> List[Dict]:\n",
    "        # (Implementation remains the same as previous version)\n",
    "        logger.info(f\"_sync_get_work_references: Thread started for work {work_id} with limit {limit}.\")\n",
    "        if not work_id: return []\n",
    "        try:\n",
    "            work_data = Works()[work_id].get()\n",
    "            if not work_data or 'referenced_works' not in work_data: return []\n",
    "            referenced_urls = work_data.get('referenced_works', [])\n",
    "            if not referenced_urls: return []\n",
    "            referenced_ids = [url.split('/')[-1] for url in referenced_urls if url and url.startswith(\"https://openalex.org/W\")] # Ensure they are Work IDs\n",
    "            referenced_ids_limited = referenced_ids[:limit] # Apply limit *before* validation\n",
    "            # Validate these IDs are actual work IDs before fetching\n",
    "            valid_referenced_ids = self._validate_openalex_ids(\"work\", referenced_ids_limited) # Use internal validation\n",
    "            if not valid_referenced_ids: return []\n",
    "            logger.info(f\"Fetching details for {len(valid_referenced_ids)} referenced works for {work_id}.\")\n",
    "            referenced_works_data = self._sync_get_works_by_ids(valid_referenced_ids) # Fetch validated IDs\n",
    "            logger.info(f\"_sync_get_work_references: API call successful for work {work_id}, returning {len(referenced_works_data)} referenced items.\")\n",
    "            return referenced_works_data\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in _sync_get_work_references for {work_id}: {e}\", exc_info=True)\n",
    "            return []\n",
    "\n",
    "\n",
    "    def _sync_get_work_citations(self, work_id: str, limit: int) -> List[Dict]:\n",
    "        # (Implementation remains the same as previous version)\n",
    "        logger.info(f\"_sync_get_work_citations: Thread started for work {work_id} with limit {limit}.\")\n",
    "        if not work_id: return []\n",
    "        try:\n",
    "            citing_works_query = Works().filter(cites=work_id)\n",
    "            citations_metadata = []\n",
    "            processed_count = 0\n",
    "            page_size = min(limit, OPENALEX_MAX_PER_PAGE)\n",
    "            if limit <= 0: page_size = OPENALEX_MAX_PER_PAGE\n",
    "            logger.info(f\"Executing OpenAlex citations query for {work_id} with limit={limit}, page_size={page_size}...\")\n",
    "            for page in citing_works_query.paginate(per_page=page_size, n_max=limit):\n",
    "                if not page: break\n",
    "                num_to_add = min(len(page), limit - processed_count)\n",
    "                citations_metadata.extend(page[:num_to_add])\n",
    "                processed_count += num_to_add\n",
    "                if processed_count >= limit: break\n",
    "            logger.info(f\"_sync_get_work_citations: API call successful for work {work_id}, returning {len(citations_metadata)} citing items.\")\n",
    "            return citations_metadata\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in _sync_get_work_citations for {work_id}: {e}\", exc_info=True)\n",
    "            return []\n",
    "\n",
    "\n",
    "    # --- Asynchronous Public Methods ---\n",
    "    # (These remain unchanged from the previous version, as they call _validate_openalex_ids\n",
    "    #  and receive back a List[str] of native IDs, which they already expect)\n",
    "\n",
    "    async def async_search_paper_by_ids(\n",
    "        self,\n",
    "        id_list: List[str] # Can contain OpenAlex IDs, DOI URLs\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"Search paper by OpenAlex Work IDs or DOI URLs asynchronously.\n",
    "           NOTE: Currently only processes native OpenAlex IDs due to validator output.\n",
    "        \"\"\"\n",
    "        # Validate IDs - This now recognizes DOIs but only returns native W... IDs\n",
    "        valid_native_id_list = self._validate_openalex_ids(\"work\", id_list)\n",
    "        id_cnt = len(valid_native_id_list)\n",
    "        paper_metadata = []\n",
    "\n",
    "        if id_cnt > 0:\n",
    "            batch_size = self.batch_size\n",
    "            batch_cnt = math.ceil(id_cnt / batch_size)\n",
    "            batches = [valid_native_id_list[i * batch_size:(i + 1) * batch_size] for i in range(batch_cnt)]\n",
    "\n",
    "            tasks = []\n",
    "            logger.info(f\"async_search_paper_by_ids: Creating {len(batches)} tasks for {id_cnt} valid native OpenAlex Work IDs.\")\n",
    "            for batch in batches:\n",
    "                tasks.append(self._execute_sync_with_controls(self._sync_get_works_by_ids, batch))\n",
    "\n",
    "            logger.info(f\"async_search_paper_by_ids: Gathering {len(tasks)} tasks...\")\n",
    "            batch_results_list = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "            logger.info(f\"async_search_paper_by_ids: Gather complete. Processing results.\")\n",
    "\n",
    "            for result in batch_results_list:\n",
    "                if isinstance(result, Exception): logger.error(f\"A batch task for async_search_paper_by_ids failed: {result}\")\n",
    "                elif isinstance(result, list): paper_metadata.extend(result)\n",
    "                else: logger.warning(f\"Unexpected result type {type(result)} from paper batch task: {result}\")\n",
    "        else:\n",
    "            logger.warning(\"async_search_paper_by_ids: No valid native OpenAlex Work IDs found in the input list.\")\n",
    "\n",
    "        return paper_metadata\n",
    "\n",
    "    async def async_search_author_by_ids(\n",
    "        self,\n",
    "        author_ids: List[str], # Can contain OpenAlex IDs, ORCID URLs\n",
    "        with_abstract: Optional[bool] = False\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"Search author by OpenAlex Author IDs or ORCID URLs asynchronously.\n",
    "           NOTE: Currently only processes native OpenAlex IDs due to validator output.\n",
    "        \"\"\"\n",
    "        # Validate IDs - This now recognizes ORCIDs but only returns native A... IDs\n",
    "        valid_native_id_list = self._validate_openalex_ids(\"author\", author_ids)\n",
    "        id_cnt = len(valid_native_id_list)\n",
    "        author_metadata = []\n",
    "\n",
    "        if id_cnt > 0:\n",
    "            batch_size = self.batch_size\n",
    "            batch_cnt = math.ceil(id_cnt / batch_size)\n",
    "            batches = [valid_native_id_list[i * batch_size:(i + 1) * batch_size] for i in range(batch_cnt)]\n",
    "            logger.info(f\"async_search_author_by_ids: Fetching {id_cnt} authors by native ID in {batch_cnt} batches.\")\n",
    "\n",
    "            tasks = []\n",
    "            for batch in batches:\n",
    "                 tasks.append(self._execute_sync_with_controls(self._sync_get_authors_by_ids, batch))\n",
    "\n",
    "            logger.info(f\"async_search_author_by_ids: Gathering {len(tasks)} tasks...\")\n",
    "            batch_results_list = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "            logger.info(f\"async_search_author_by_ids: Gather complete. Processing results.\")\n",
    "\n",
    "            for result in batch_results_list:\n",
    "                if isinstance(result, Exception): logger.error(f\"A batch task for async_search_author_by_ids failed: {result}\")\n",
    "                elif isinstance(result, list): author_metadata.extend(result)\n",
    "                else: logger.warning(f\"Unexpected result type {type(result)} from author batch task: {result}\")\n",
    "        else:\n",
    "             logger.warning(\"async_search_author_by_ids: No valid native OpenAlex Author IDs found in the input list.\")\n",
    "\n",
    "        if with_abstract:\n",
    "            logger.warning(\"`with_abstract=True` is not directly supported for `async_search_author_by_ids` with OpenAlex.\")\n",
    "\n",
    "        return author_metadata\n",
    "\n",
    "    # ... (rest of the async methods: async_search_paper_by_keywords, async_get_s2_cited_papers, async_get_s2_citing_papers, async_get_s2_recommended_papers remain the same) ...\n",
    "    async def async_search_paper_by_keywords(self, query: str, year: str = None, publication_types: list = None, open_access_pdf: bool = None, venue: list = None, fields_of_study: list = None, publication_date_or_year: str = None, min_citation_count: int = None, limit: int = 100, bulk: bool = False, sort: str = None, match_title: bool = False) -> List[Dict]:\n",
    "        # (Implementation remains the same as previous version)\n",
    "        search_kwargs = { k: v for k, v in locals().items() if k != 'self' and v is not None and k != 'match_title'} # Simplified kwargs creation\n",
    "        search_kwargs['limit'] = min(search_kwargs.get('limit', 100), self.max_cnt) # Ensure limit is applied correctly\n",
    "        logger.info(f\"async_search_paper_by_keywords: Searching papers by keyword: '{query[:50]}...' with effective limit {search_kwargs.get('limit')}.\")\n",
    "        try:\n",
    "            paper_metadata = await self._execute_sync_with_controls(self._sync_search_works_by_keywords, **search_kwargs)\n",
    "        except Exception as e:\n",
    "             logger.error(f\"async_search_paper_by_keywords: Failed for query '{query[:50]}...': {e}\")\n",
    "             paper_metadata = []\n",
    "        return paper_metadata\n",
    "\n",
    "    async def async_get_s2_cited_papers(self, paper_id: str, limit: int = 100, with_abstract: Optional[bool] = False) -> List[Dict]:\n",
    "        # (Implementation remains the same as previous version)\n",
    "        # Note: paper_id here MUST be a native OpenAlex Work ID for _sync_get_work_references to work\n",
    "        valid_paper_id = self._validate_openalex_ids(\"work\", [paper_id])\n",
    "        if not valid_paper_id:\n",
    "             logger.error(f\"async_get_s2_cited_papers: Invalid native OpenAlex Work ID provided: {paper_id}\")\n",
    "             return []\n",
    "        work_id = valid_paper_id[0]\n",
    "\n",
    "        max_limit = min(limit, self.max_cnt)\n",
    "        logger.info(f\"async_get_s2_cited_papers: Fetching references for paper {work_id} with effective limit {max_limit}.\")\n",
    "        refs_metadata = []\n",
    "        try:\n",
    "            refs_metadata = await self._execute_sync_with_controls(self._sync_get_work_references, work_id, max_limit)\n",
    "        except Exception as e:\n",
    "             logger.error(f\"async_get_s2_cited_papers: Failed for paper {work_id}: {e}\")\n",
    "             refs_metadata = []\n",
    "\n",
    "        # Handle with_abstract... (Logic unchanged)\n",
    "        if with_abstract and refs_metadata:\n",
    "            papers_missing_abstracts_ids = set()\n",
    "            # ... abstract fetching logic ...\n",
    "            if papers_missing_abstracts_ids:\n",
    "                 # ... call async_search_paper_by_ids ...\n",
    "                 # ... map abstracts back ...\n",
    "                 pass # Placeholder for brevity\n",
    "\n",
    "        return refs_metadata\n",
    "\n",
    "    async def async_get_s2_citing_papers(self, paper_id: str, limit: int = 100, with_abstract: Optional[bool] = False) -> List[Dict]:\n",
    "        # (Implementation remains the same as previous version)\n",
    "        # Note: paper_id here MUST be a native OpenAlex Work ID for _sync_get_work_citations to work\n",
    "        valid_paper_id = self._validate_openalex_ids(\"work\", [paper_id])\n",
    "        if not valid_paper_id:\n",
    "             logger.error(f\"async_get_s2_citing_papers: Invalid native OpenAlex Work ID provided: {paper_id}\")\n",
    "             return []\n",
    "        work_id = valid_paper_id[0]\n",
    "\n",
    "        max_limit = min(limit, self.max_cnt)\n",
    "        logger.info(f\"async_get_s2_citing_papers: Fetching citations for paper {work_id} with effective limit {max_limit}.\")\n",
    "        citedby_metadata = []\n",
    "        try:\n",
    "            citedby_metadata = await self._execute_sync_with_controls(self._sync_get_work_citations, work_id, max_limit)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"async_get_s2_citing_papers: Failed for paper {work_id}: {e}\")\n",
    "            citedby_metadata = []\n",
    "\n",
    "        # Handle with_abstract... (Logic unchanged)\n",
    "        if with_abstract and citedby_metadata:\n",
    "             papers_missing_abstracts_ids = set()\n",
    "             # ... abstract fetching logic ...\n",
    "             if papers_missing_abstracts_ids:\n",
    "                  # ... call async_search_paper_by_ids ...\n",
    "                  # ... map abstracts back ...\n",
    "                  pass # Placeholder for brevity\n",
    "\n",
    "        return citedby_metadata\n",
    "\n",
    "    async def async_get_s2_recommended_papers(self, positive_paper_ids: List[str], negative_paper_ids: List[str] = None, limit: int = 100, with_abstract: Optional[bool] = False) -> List[Dict]:\n",
    "        # (Implementation remains the same as previous version - logs warning, returns [])\n",
    "        logger.warning(\"OpenAlex does not support recommendations based on positive/negative paper ID lists like Semantic Scholar.\")\n",
    "        logger.warning(\"async_get_s2_recommended_papers will return an empty list.\")\n",
    "        valid_pos_ids = self._validate_openalex_ids(\"work\", positive_paper_ids) # Validate for logging\n",
    "        valid_neg_ids = []\n",
    "        if negative_paper_ids: valid_neg_ids = self._validate_openalex_ids(\"work\", negative_paper_ids)\n",
    "        logger.info(f\"async_get_s2_recommended_papers called with {len(valid_pos_ids)} valid native positive IDs. Limit: {limit}. Returning [].\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f355d96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_dois = ['https://doi.org/10.48550/arXiv.2406.10252',  # AutoSurvey: Large Language Models Can Automatically Write Surveys\n",
    "            'https://doi.org/10.48550/arXiv.2412.10415',  # Generative Adversarial Reviews: When LLMs Become the Critic\n",
    "            'https://doi.org/10.48550/arXiv.2402.12928',  # A Literature Review of Literature Reviews in Pattern Analysis and Machine Intelligence \n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25d4b6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 15:13:15,246 - INFO - OpenAlex email set for polite pool: ai4fun@gmail.com\n",
      "2025-04-21 15:13:15,247 - INFO - OpenAlexKit initialized with max_concurrency=10, sleep_interval=0.1s\n",
      "2025-04-21 15:13:15,247 - WARNING - Recognized external ID format (DOI: https://doi.org/10.7717/peerj.4375) for type 'work', but it will be skipped by this function. Modify calling method to handle DOI lookups if needed.\n",
      "2025-04-21 15:13:15,249 - WARNING - Invalid or unrecognized ID format for type 'work' skipped: https://doi.org/10.7717/peerj.4375\n",
      "2025-04-21 15:13:15,249 - INFO - Recognized 1 external IDs (DOI/ORCID/ROR) for entity type 'work'.\n",
      "2025-04-21 15:13:15,250 - INFO - Skipped 1 other invalid, non-matching, or empty IDs for type 'work'.\n",
      "2025-04-21 15:13:15,250 - INFO - Validation for type 'work' completed. Returning 1 unique native OpenAlex IDs.\n",
      "2025-04-21 15:13:15,251 - INFO - async_search_paper_by_ids: Creating 1 tasks for 1 valid native OpenAlex Work IDs.\n",
      "2025-04-21 15:13:15,251 - INFO - async_search_paper_by_ids: Gathering 1 tasks...\n",
      "2025-04-21 15:13:15,252 - INFO - _sync_get_works_by_ids: Thread started for batch (1 IDs, first 5: ['https://doi.org/10.7717/peerj.4375']...).\n",
      "2025-04-21 15:13:16,261 - ERROR - Error in _sync_get_works_by_ids for batch (first 5 IDs: ['https://doi.org/10.7717/peerj.4375']...): 'https://doi.org/10.7717/peerj.4375' is not a valid OpenAlex ID.\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/dr/n5l88r750zl4pk13dhslspzh0000gn/T/ipykernel_11050/1416760490.py\", line 177, in _sync_get_works_by_ids\n",
      "    results = Works().filter(openalex_id=filter_query).get()\n",
      "  File \"/opt/miniconda3/envs/jiezi4ai/lib/python3.10/site-packages/pyalex/api.py\", line 551, in get\n",
      "    resp_list = self._get_from_url(self.url)\n",
      "  File \"/opt/miniconda3/envs/jiezi4ai/lib/python3.10/site-packages/pyalex/api.py\", line 522, in _get_from_url\n",
      "    raise QueryError(res.json()[\"message\"])\n",
      "pyalex.api.QueryError: 'https://doi.org/10.7717/peerj.4375' is not a valid OpenAlex ID.\n",
      "2025-04-21 15:13:16,367 - INFO - async_search_paper_by_ids: Gather complete. Processing results.\n"
     ]
    }
   ],
   "source": [
    "oa = OpenAlexKit(email=\"ai4fun@gmail.com\")\n",
    "papers_info = await oa.async_search_paper_by_ids(id_list=[\"https://doi.org/10.7717/peerj.4375\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd0a2d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbf49477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'https://openalex.org/W4406231668',\n",
       " 'doi': 'https://doi.org/10.48550/arxiv.2501.04682',\n",
       " 'title': 'Towards System 2 Reasoning in LLMs: Learning How to Think With Meta\\n  Chain-of-Thought',\n",
       " 'display_name': 'Towards System 2 Reasoning in LLMs: Learning How to Think With Meta\\n  Chain-of-Thought',\n",
       " 'publication_year': 2025,\n",
       " 'publication_date': '2025-01-08',\n",
       " 'ids': {'openalex': 'https://openalex.org/W4406231668',\n",
       "  'doi': 'https://doi.org/10.48550/arxiv.2501.04682'},\n",
       " 'language': 'en',\n",
       " 'primary_location': {'is_oa': True,\n",
       "  'landing_page_url': 'http://arxiv.org/abs/2501.04682',\n",
       "  'pdf_url': 'http://arxiv.org/pdf/2501.04682',\n",
       "  'source': {'id': 'https://openalex.org/S4306400194',\n",
       "   'display_name': 'arXiv (Cornell University)',\n",
       "   'issn_l': None,\n",
       "   'issn': None,\n",
       "   'is_oa': True,\n",
       "   'is_in_doaj': False,\n",
       "   'is_indexed_in_scopus': False,\n",
       "   'is_core': False,\n",
       "   'host_organization': 'https://openalex.org/I205783295',\n",
       "   'host_organization_name': 'Cornell University',\n",
       "   'host_organization_lineage': ['https://openalex.org/I205783295'],\n",
       "   'host_organization_lineage_names': ['Cornell University'],\n",
       "   'type': 'repository'},\n",
       "  'license': None,\n",
       "  'license_id': None,\n",
       "  'version': 'submittedVersion',\n",
       "  'is_accepted': False,\n",
       "  'is_published': False},\n",
       " 'type': 'preprint',\n",
       " 'type_crossref': 'posted-content',\n",
       " 'indexed_in': ['arxiv'],\n",
       " 'open_access': {'is_oa': True,\n",
       "  'oa_status': 'green',\n",
       "  'oa_url': 'http://arxiv.org/pdf/2501.04682',\n",
       "  'any_repository_has_fulltext': True},\n",
       " 'authorships': [{'author_position': 'first',\n",
       "   'author': {'id': 'https://openalex.org/A5023185054',\n",
       "    'display_name': 'Violet Xiang',\n",
       "    'orcid': 'https://orcid.org/0000-0002-1584-6231'},\n",
       "   'institutions': [],\n",
       "   'countries': [],\n",
       "   'is_corresponding': False,\n",
       "   'raw_author_name': 'Xiang, Violet',\n",
       "   'raw_affiliation_strings': [],\n",
       "   'affiliations': []},\n",
       "  {'author_position': 'middle',\n",
       "   'author': {'id': 'https://openalex.org/A5115829822',\n",
       "    'display_name': 'Charlie Snell',\n",
       "    'orcid': None},\n",
       "   'institutions': [],\n",
       "   'countries': [],\n",
       "   'is_corresponding': False,\n",
       "   'raw_author_name': 'Snell, Charlie',\n",
       "   'raw_affiliation_strings': [],\n",
       "   'affiliations': []},\n",
       "  {'author_position': 'middle',\n",
       "   'author': {'id': 'https://openalex.org/A5085625870',\n",
       "    'display_name': 'Kanishk Gandhi',\n",
       "    'orcid': None},\n",
       "   'institutions': [],\n",
       "   'countries': [],\n",
       "   'is_corresponding': False,\n",
       "   'raw_author_name': 'Gandhi, Kanishk',\n",
       "   'raw_affiliation_strings': [],\n",
       "   'affiliations': []},\n",
       "  {'author_position': 'middle',\n",
       "   'author': {'id': 'https://openalex.org/A5090026363',\n",
       "    'display_name': 'Alon Albalak',\n",
       "    'orcid': None},\n",
       "   'institutions': [],\n",
       "   'countries': [],\n",
       "   'is_corresponding': False,\n",
       "   'raw_author_name': 'Albalak, Alon',\n",
       "   'raw_affiliation_strings': [],\n",
       "   'affiliations': []},\n",
       "  {'author_position': 'middle',\n",
       "   'author': {'id': 'https://openalex.org/A5088818925',\n",
       "    'display_name': 'Anikait Singh',\n",
       "    'orcid': None},\n",
       "   'institutions': [],\n",
       "   'countries': [],\n",
       "   'is_corresponding': False,\n",
       "   'raw_author_name': 'Singh, Anikait',\n",
       "   'raw_affiliation_strings': [],\n",
       "   'affiliations': []},\n",
       "  {'author_position': 'middle',\n",
       "   'author': {'id': 'https://openalex.org/A5079334315',\n",
       "    'display_name': 'C. O. Blagden',\n",
       "    'orcid': None},\n",
       "   'institutions': [],\n",
       "   'countries': [],\n",
       "   'is_corresponding': False,\n",
       "   'raw_author_name': 'Blagden, Chase',\n",
       "   'raw_affiliation_strings': [],\n",
       "   'affiliations': []},\n",
       "  {'author_position': 'middle',\n",
       "   'author': {'id': 'https://openalex.org/A5003505678',\n",
       "    'display_name': 'Duy Phung',\n",
       "    'orcid': None},\n",
       "   'institutions': [],\n",
       "   'countries': [],\n",
       "   'is_corresponding': False,\n",
       "   'raw_author_name': 'Phung, Duy',\n",
       "   'raw_affiliation_strings': [],\n",
       "   'affiliations': []},\n",
       "  {'author_position': 'middle',\n",
       "   'author': {'id': 'https://openalex.org/A5028522433',\n",
       "    'display_name': 'Rafael Rafailov',\n",
       "    'orcid': None},\n",
       "   'institutions': [],\n",
       "   'countries': [],\n",
       "   'is_corresponding': False,\n",
       "   'raw_author_name': 'Rafailov, Rafael',\n",
       "   'raw_affiliation_strings': [],\n",
       "   'affiliations': []},\n",
       "  {'author_position': 'middle',\n",
       "   'author': {'id': 'https://openalex.org/A5093931915',\n",
       "    'display_name': 'Nathan Lile',\n",
       "    'orcid': None},\n",
       "   'institutions': [],\n",
       "   'countries': [],\n",
       "   'is_corresponding': False,\n",
       "   'raw_author_name': 'Lile, Nathan',\n",
       "   'raw_affiliation_strings': [],\n",
       "   'affiliations': []},\n",
       "  {'author_position': 'middle',\n",
       "   'author': {'id': 'https://openalex.org/A5094363682',\n",
       "    'display_name': 'Dakota Mahan',\n",
       "    'orcid': None},\n",
       "   'institutions': [],\n",
       "   'countries': [],\n",
       "   'is_corresponding': False,\n",
       "   'raw_author_name': 'Mahan, Dakota',\n",
       "   'raw_affiliation_strings': [],\n",
       "   'affiliations': []},\n",
       "  {'author_position': 'middle',\n",
       "   'author': {'id': 'https://openalex.org/A5004714414',\n",
       "    'display_name': 'Louis Castricato',\n",
       "    'orcid': None},\n",
       "   'institutions': [],\n",
       "   'countries': [],\n",
       "   'is_corresponding': False,\n",
       "   'raw_author_name': 'Castricato, Louis',\n",
       "   'raw_affiliation_strings': [],\n",
       "   'affiliations': []},\n",
       "  {'author_position': 'middle',\n",
       "   'author': {'id': 'https://openalex.org/A5046536754',\n",
       "    'display_name': 'Jan-Philipp Fr√§nken',\n",
       "    'orcid': 'https://orcid.org/0000-0001-5467-1887'},\n",
       "   'institutions': [],\n",
       "   'countries': [],\n",
       "   'is_corresponding': False,\n",
       "   'raw_author_name': 'Franken, Jan-Philipp',\n",
       "   'raw_affiliation_strings': [],\n",
       "   'affiliations': []},\n",
       "  {'author_position': 'middle',\n",
       "   'author': {'id': 'https://openalex.org/A5069105490',\n",
       "    'display_name': 'Nick Haber',\n",
       "    'orcid': 'https://orcid.org/0000-0001-8804-7804'},\n",
       "   'institutions': [],\n",
       "   'countries': [],\n",
       "   'is_corresponding': False,\n",
       "   'raw_author_name': 'Haber, Nick',\n",
       "   'raw_affiliation_strings': [],\n",
       "   'affiliations': []},\n",
       "  {'author_position': 'last',\n",
       "   'author': {'id': 'https://openalex.org/A5005431772',\n",
       "    'display_name': 'Chelsea Finn',\n",
       "    'orcid': 'https://orcid.org/0000-0001-6298-0874'},\n",
       "   'institutions': [],\n",
       "   'countries': [],\n",
       "   'is_corresponding': False,\n",
       "   'raw_author_name': 'Finn, Chelsea',\n",
       "   'raw_affiliation_strings': [],\n",
       "   'affiliations': []}],\n",
       " 'institution_assertions': [],\n",
       " 'countries_distinct_count': 0,\n",
       " 'institutions_distinct_count': 0,\n",
       " 'corresponding_author_ids': [],\n",
       " 'corresponding_institution_ids': [],\n",
       " 'apc_list': None,\n",
       " 'apc_paid': None,\n",
       " 'fwci': None,\n",
       " 'has_fulltext': False,\n",
       " 'cited_by_count': 0,\n",
       " 'citation_normalized_percentile': {'value': 0.0,\n",
       "  'is_in_top_1_percent': False,\n",
       "  'is_in_top_10_percent': False},\n",
       " 'cited_by_percentile_year': {'min': 0, 'max': 97},\n",
       " 'biblio': {'volume': None,\n",
       "  'issue': None,\n",
       "  'first_page': None,\n",
       "  'last_page': None},\n",
       " 'is_retracted': False,\n",
       " 'is_paratext': False,\n",
       " 'primary_topic': {'id': 'https://openalex.org/T10703',\n",
       "  'display_name': 'Business Process Modeling and Analysis',\n",
       "  'score': 0.9283,\n",
       "  'subfield': {'id': 'https://openalex.org/subfields/1404',\n",
       "   'display_name': 'Management Information Systems'},\n",
       "  'field': {'id': 'https://openalex.org/fields/14',\n",
       "   'display_name': 'Business, Management and Accounting'},\n",
       "  'domain': {'id': 'https://openalex.org/domains/2',\n",
       "   'display_name': 'Social Sciences'}},\n",
       " 'topics': [{'id': 'https://openalex.org/T10703',\n",
       "   'display_name': 'Business Process Modeling and Analysis',\n",
       "   'score': 0.9283,\n",
       "   'subfield': {'id': 'https://openalex.org/subfields/1404',\n",
       "    'display_name': 'Management Information Systems'},\n",
       "   'field': {'id': 'https://openalex.org/fields/14',\n",
       "    'display_name': 'Business, Management and Accounting'},\n",
       "   'domain': {'id': 'https://openalex.org/domains/2',\n",
       "    'display_name': 'Social Sciences'}},\n",
       "  {'id': 'https://openalex.org/T10215',\n",
       "   'display_name': 'Semantic Web and Ontologies',\n",
       "   'score': 0.9242,\n",
       "   'subfield': {'id': 'https://openalex.org/subfields/1702',\n",
       "    'display_name': 'Artificial Intelligence'},\n",
       "   'field': {'id': 'https://openalex.org/fields/17',\n",
       "    'display_name': 'Computer Science'},\n",
       "   'domain': {'id': 'https://openalex.org/domains/3',\n",
       "    'display_name': 'Physical Sciences'}}],\n",
       " 'keywords': [],\n",
       " 'concepts': [{'id': 'https://openalex.org/C2781002164',\n",
       "   'wikidata': 'https://www.wikidata.org/wiki/Q6822311',\n",
       "   'display_name': 'Meta learning (computer science)',\n",
       "   'level': 3,\n",
       "   'score': 0.53846323},\n",
       "  {'id': 'https://openalex.org/C15744967',\n",
       "   'wikidata': 'https://www.wikidata.org/wiki/Q9418',\n",
       "   'display_name': 'Psychology',\n",
       "   'level': 0,\n",
       "   'score': 0.48172146},\n",
       "  {'id': 'https://openalex.org/C111472728',\n",
       "   'wikidata': 'https://www.wikidata.org/wiki/Q9471',\n",
       "   'display_name': 'Epistemology',\n",
       "   'level': 1,\n",
       "   'score': 0.3898945},\n",
       "  {'id': 'https://openalex.org/C188147891',\n",
       "   'wikidata': 'https://www.wikidata.org/wiki/Q147638',\n",
       "   'display_name': 'Cognitive science',\n",
       "   'level': 1,\n",
       "   'score': 0.32154033},\n",
       "  {'id': 'https://openalex.org/C138885662',\n",
       "   'wikidata': 'https://www.wikidata.org/wiki/Q5891',\n",
       "   'display_name': 'Philosophy',\n",
       "   'level': 0,\n",
       "   'score': 0.17783487},\n",
       "  {'id': 'https://openalex.org/C162324750',\n",
       "   'wikidata': 'https://www.wikidata.org/wiki/Q8134',\n",
       "   'display_name': 'Economics',\n",
       "   'level': 0,\n",
       "   'score': 0.12868583},\n",
       "  {'id': 'https://openalex.org/C187736073',\n",
       "   'wikidata': 'https://www.wikidata.org/wiki/Q2920921',\n",
       "   'display_name': 'Management',\n",
       "   'level': 1,\n",
       "   'score': 0.06770903},\n",
       "  {'id': 'https://openalex.org/C2780451532',\n",
       "   'wikidata': 'https://www.wikidata.org/wiki/Q759676',\n",
       "   'display_name': 'Task (project management)',\n",
       "   'level': 2,\n",
       "   'score': 0.0}],\n",
       " 'mesh': [],\n",
       " 'locations_count': 1,\n",
       " 'locations': [{'is_oa': True,\n",
       "   'landing_page_url': 'http://arxiv.org/abs/2501.04682',\n",
       "   'pdf_url': 'http://arxiv.org/pdf/2501.04682',\n",
       "   'source': {'id': 'https://openalex.org/S4306400194',\n",
       "    'display_name': 'arXiv (Cornell University)',\n",
       "    'issn_l': None,\n",
       "    'issn': None,\n",
       "    'is_oa': True,\n",
       "    'is_in_doaj': False,\n",
       "    'is_indexed_in_scopus': False,\n",
       "    'is_core': False,\n",
       "    'host_organization': 'https://openalex.org/I205783295',\n",
       "    'host_organization_name': 'Cornell University',\n",
       "    'host_organization_lineage': ['https://openalex.org/I205783295'],\n",
       "    'host_organization_lineage_names': ['Cornell University'],\n",
       "    'type': 'repository'},\n",
       "   'license': None,\n",
       "   'license_id': None,\n",
       "   'version': 'submittedVersion',\n",
       "   'is_accepted': False,\n",
       "   'is_published': False}],\n",
       " 'best_oa_location': {'is_oa': True,\n",
       "  'landing_page_url': 'http://arxiv.org/abs/2501.04682',\n",
       "  'pdf_url': 'http://arxiv.org/pdf/2501.04682',\n",
       "  'source': {'id': 'https://openalex.org/S4306400194',\n",
       "   'display_name': 'arXiv (Cornell University)',\n",
       "   'issn_l': None,\n",
       "   'issn': None,\n",
       "   'is_oa': True,\n",
       "   'is_in_doaj': False,\n",
       "   'is_indexed_in_scopus': False,\n",
       "   'is_core': False,\n",
       "   'host_organization': 'https://openalex.org/I205783295',\n",
       "   'host_organization_name': 'Cornell University',\n",
       "   'host_organization_lineage': ['https://openalex.org/I205783295'],\n",
       "   'host_organization_lineage_names': ['Cornell University'],\n",
       "   'type': 'repository'},\n",
       "  'license': None,\n",
       "  'license_id': None,\n",
       "  'version': 'submittedVersion',\n",
       "  'is_accepted': False,\n",
       "  'is_published': False},\n",
       " 'sustainable_development_goals': [],\n",
       " 'grants': [],\n",
       " 'datasets': [],\n",
       " 'versions': [],\n",
       " 'referenced_works_count': 0,\n",
       " 'referenced_works': [],\n",
       " 'related_works': ['https://openalex.org/W4401768695',\n",
       "  'https://openalex.org/W4391375266',\n",
       "  'https://openalex.org/W3006817050',\n",
       "  'https://openalex.org/W2931662336',\n",
       "  'https://openalex.org/W2765597752',\n",
       "  'https://openalex.org/W2748952813',\n",
       "  'https://openalex.org/W2134894512',\n",
       "  'https://openalex.org/W2083375246',\n",
       "  'https://openalex.org/W2077865380',\n",
       "  'https://openalex.org/W2067108088'],\n",
       " 'abstract_inverted_index': {'We': [0, 26],\n",
       "  'propose': [1],\n",
       "  'a': [2, 23, 57, 62, 100],\n",
       "  'novel': [3, 94],\n",
       "  'framework,': [4],\n",
       "  'Meta': [5],\n",
       "  'Chain-of-Thought': [6, 11],\n",
       "  '(Meta-CoT),': [7],\n",
       "  'which': [8],\n",
       "  'extends': [9],\n",
       "  'traditional': [10],\n",
       "  '(CoT)': [12],\n",
       "  'by': [13],\n",
       "  'explicitly': [14],\n",
       "  'modeling': [15],\n",
       "  'the': [16, 90, 111],\n",
       "  'underlying': [17],\n",
       "  'reasoning': [18, 95, 118],\n",
       "  'required': [19],\n",
       "  'to': [20, 64, 105],\n",
       "  'arrive': [21],\n",
       "  'at': [22],\n",
       "  'particular': [24],\n",
       "  'CoT.': [25],\n",
       "  'present': [27],\n",
       "  'empirical': [28],\n",
       "  'evidence': [29],\n",
       "  'from': [30],\n",
       "  'state-of-the-art': [31],\n",
       "  'models': [32],\n",
       "  'exhibiting': [33],\n",
       "  'behaviors': [34],\n",
       "  'consistent': [35],\n",
       "  'with': [36, 70],\n",
       "  'in-context': [37],\n",
       "  'search,': [38],\n",
       "  'and': [39, 51, 74, 89, 102, 116],\n",
       "  'explore': [40],\n",
       "  'methods': [41],\n",
       "  'for': [42, 60, 92, 113],\n",
       "  'producing': [43],\n",
       "  'Meta-CoT': [44, 107],\n",
       "  'via': [45],\n",
       "  'process': [46],\n",
       "  'supervision,': [47],\n",
       "  'synthetic': [48],\n",
       "  'data': [49],\n",
       "  'generation,': [50],\n",
       "  'search': [52, 72],\n",
       "  'algorithms.': [53, 96],\n",
       "  'Finally,': [54, 78],\n",
       "  'we': [55, 79],\n",
       "  'outline': [56],\n",
       "  'concrete': [58],\n",
       "  'pipeline': [59],\n",
       "  'training': [61],\n",
       "  'model': [63],\n",
       "  'produce': [65],\n",
       "  'Meta-CoTs,': [66],\n",
       "  'incorporating': [67],\n",
       "  'instruction': [68],\n",
       "  'tuning': [69],\n",
       "  'linearized': [71],\n",
       "  'traces': [73],\n",
       "  'reinforcement': [75],\n",
       "  'learning': [76],\n",
       "  'post-training.': [77],\n",
       "  'discuss': [80],\n",
       "  'open': [81],\n",
       "  'research': [82],\n",
       "  'questions,': [83],\n",
       "  'including': [84],\n",
       "  'scaling': [85],\n",
       "  'laws,': [86],\n",
       "  'verifier': [87],\n",
       "  'roles,': [88],\n",
       "  'potential': [91],\n",
       "  'discovering': [93],\n",
       "  'This': [97],\n",
       "  'work': [98],\n",
       "  'provides': [99],\n",
       "  'theoretical': [101],\n",
       "  'practical': [103],\n",
       "  'roadmap': [104],\n",
       "  'enable': [106],\n",
       "  'in': [108, 119],\n",
       "  'LLMs,': [109],\n",
       "  'paving': [110],\n",
       "  'way': [112],\n",
       "  'more': [114],\n",
       "  'powerful': [115],\n",
       "  'human-like': [117],\n",
       "  'artificial': [120],\n",
       "  'intelligence.': [121]},\n",
       " 'abstract_inverted_index_v3': None,\n",
       " 'cited_by_api_url': 'https://api.openalex.org/works?filter=cites:W4406231668',\n",
       " 'counts_by_year': [],\n",
       " 'updated_date': '2025-03-30T18:03:54.122798',\n",
       " 'created_date': '2025-01-10'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyalex import Works, Authors, Sources, Institutions, Topics, Publishers, Funders\n",
    "\n",
    "import pyalex\n",
    "\n",
    "pyalex.config.email = \"ai4fun2004@gmail.com\"\n",
    "\n",
    "# same as\n",
    "Works()[\"https://doi.org/10.48550/arXiv.2501.04682\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2167d7e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai4fun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
