{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e2ffaa5",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f670ae1b",
   "metadata": {},
   "source": [
    "## Paper Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24acc952",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaeef614",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/jiezi4ai/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from paper_collect import PaperCollector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abd73eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_api_key = os.getenv('GEMINI_API_KEY_3')\n",
    "llm_model_name=\"gemini-2.0-flash\"\n",
    "embed_api_key = os.getenv('GEMINI_API_KEY_3')\n",
    "embed_model_name=\"models/text-embedding-004\"\n",
    "\n",
    "research_topic = \"llm literature review\"\n",
    "seed_dois = ['10.48550/arXiv.2406.10252',  # AutoSurvey: Large Language Models Can Automatically Write Surveys\n",
    "            '10.48550/arXiv.2412.10415',  # Generative Adversarial Reviews: When LLMs Become the Critic\n",
    "            '10.48550/arXiv.2402.12928',  # A Literature Review of Literature Reviews in Pattern Analysis and Machine Intelligence \n",
    "            ]\n",
    "seed_titles = ['PaperRobot: Incremental Draft Generation of Scientific Ideas',\n",
    "            'From Hypothesis to Publication: A Comprehensive Survey of AI-Driven Research Support Systems'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41739da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PaperCollector(   \n",
    "    research_topic = research_topic,   \n",
    "    seed_paper_titles = seed_titles, \n",
    "    seed_paper_dois = seed_dois,\n",
    "    llm_api_key = llm_api_key,\n",
    "    llm_model_name = llm_model_name,\n",
    "    embed_api_key = embed_api_key,\n",
    "    embed_model_name = embed_model_name,\n",
    "    from_dt = '2020-01-01',\n",
    "    to_dt = '2025-04-30',\n",
    "    fields_of_study = ['Computer Science'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705bb1bc",
   "metadata": {},
   "source": [
    "### Inital Search\n",
    "- initial search for seed paper metadata\n",
    "- basic search takes about 30-60 seconds "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb61e95",
   "metadata": {},
   "source": [
    "**Paper Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d26918ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 12:13:26,914 - INFO - SemanticScholarKit initialized with max_concurrency=10, sleep_interval=3.0s\n",
      "2025-04-11 12:13:26,915 - INFO - Fetching papers by 3 DOIs...\n",
      "2025-04-11 12:13:26,915 - INFO - Fetching papers by title: 'PaperRobot: Incremental Draft Generation of Scientific Ideas...'\n",
      "2025-04-11 12:13:26,916 - INFO - Fetching papers by title: 'From Hypothesis to Publication: A Comprehensive Survey of AI-Driven Research Support Systems...'\n",
      "2025-04-11 12:13:26,916 - INFO - Fetching papers by topic: 'llm literature review...'\n",
      "2025-04-11 12:13:26,917 - INFO - Running 4 initial query tasks concurrently...\n",
      "2025-04-11 12:13:26,917 - INFO - async_search_paper_by_ids: Creating 1 tasks for 3 IDs.\n",
      "2025-04-11 12:13:26,918 - INFO - async_search_paper_by_ids: Gathering 1 tasks...\n",
      "2025-04-11 12:13:26,918 - INFO - async_search_paper_by_keywords: Searching papers by keyword: 'PaperRobot: Incremental Draft Generation of Scient...' with effective limit 50.\n",
      "2025-04-11 12:13:26,919 - INFO - _sync_search_paper_by_keywords: Thread started for query 'PaperRobot: Incremental Draft Generation of Scient...' with limit 50.\n",
      "2025-04-11 12:13:26,919 - INFO - async_search_paper_by_keywords: Searching papers by keyword: 'From Hypothesis to Publication: A Comprehensive Su...' with effective limit 50.\n",
      "2025-04-11 12:13:26,921 - INFO - _sync_search_paper_by_keywords: Thread started for query 'From Hypothesis to Publication: A Comprehensive Su...' with limit 50.\n",
      "2025-04-11 12:13:26,921 - INFO - async_search_paper_by_keywords: Searching papers by keyword: 'llm literature review...' with effective limit 50.\n",
      "2025-04-11 12:13:26,923 - INFO - _sync_search_paper_by_keywords: Thread started for query 'llm literature review...' with limit 50.\n",
      "2025-04-11 12:13:26,924 - INFO - _sync_get_papers: Thread started for batch (3 IDs, first 5: ['10.48550/arXiv.2406.10252', '10.48550/arXiv.2412.10415', '10.48550/arXiv.2402.12928']...).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Initial Query for Seed Papers Information ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 12:13:27,906 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=PaperRobot:%20Incremental%20Draft%20Generation%20of%20Scientific%20Ideas&fields=abstract,authors,citationCount,citationStyles,corpusId,externalIds,fieldsOfStudy,influentialCitationCount,isOpenAccess,journal,openAccessPdf,paperId,publicationDate,publicationTypes,publicationVenue,referenceCount,s2FieldsOfStudy,title,url,venue,year&offset=0&limit=50 \"HTTP/1.1 429 \"\n",
      "2025-04-11 12:13:27,959 - INFO - HTTP Request: POST https://api.semanticscholar.org/graph/v1/paper/batch?fields=abstract,authors,citationCount,citationStyles,corpusId,externalIds,fieldsOfStudy,influentialCitationCount,isOpenAccess,journal,openAccessPdf,paperId,publicationDate,publicationTypes,publicationVenue,referenceCount,s2FieldsOfStudy,title,url,venue,year \"HTTP/1.1 200 OK\"\n",
      "2025-04-11 12:13:27,968 - INFO - _sync_get_papers: API call successful for batch (first 5: ['10.48550/arXiv.2406.10252', '10.48550/arXiv.2412.10415', '10.48550/arXiv.2402.12928']...), returning 3 items.\n",
      "2025-04-11 12:13:28,264 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=From%20Hypothesis%20to%20Publication:%20A%20Comprehensive%20Survey%20of%20AI-Driven%20Research%20Support%20Systems&fields=abstract,authors,citationCount,citationStyles,corpusId,externalIds,fieldsOfStudy,influentialCitationCount,isOpenAccess,journal,openAccessPdf,paperId,publicationDate,publicationTypes,publicationVenue,referenceCount,s2FieldsOfStudy,title,url,venue,year&offset=0&limit=50 \"HTTP/1.1 200 OK\"\n",
      "2025-04-11 12:13:28,964 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=llm%20literature%20review&fields=abstract,authors,citationCount,citationStyles,corpusId,externalIds,fieldsOfStudy,influentialCitationCount,isOpenAccess,journal,openAccessPdf,paperId,publicationDate,publicationTypes,publicationVenue,referenceCount,s2FieldsOfStudy,title,url,venue,year&offset=0&limit=50 \"HTTP/1.1 200 OK\"\n",
      "2025-04-11 12:13:29,145 - INFO - _sync_search_paper_by_keywords: API call successful for query 'From Hypothesis to Publication: A Comprehensive Su...', returning 3 items.\n",
      "2025-04-11 12:13:30,969 - INFO - async_search_paper_by_ids: Gather complete. Processing results.\n",
      "2025-04-11 12:13:32,244 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=llm%20literature%20review&fields=abstract,authors,citationCount,citationStyles,corpusId,externalIds,fieldsOfStudy,influentialCitationCount,isOpenAccess,journal,openAccessPdf,paperId,publicationDate,publicationTypes,publicationVenue,referenceCount,s2FieldsOfStudy,title,url,venue,year&offset=50&limit=50 \"HTTP/1.1 200 OK\"\n",
      "2025-04-11 12:13:34,085 - INFO - _sync_search_paper_by_keywords: API call successful for query 'llm literature review...', returning 50 items.\n",
      "2025-04-11 12:14:00,296 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=PaperRobot:%20Incremental%20Draft%20Generation%20of%20Scientific%20Ideas&fields=abstract,authors,citationCount,citationStyles,corpusId,externalIds,fieldsOfStudy,influentialCitationCount,isOpenAccess,journal,openAccessPdf,paperId,publicationDate,publicationTypes,publicationVenue,referenceCount,s2FieldsOfStudy,title,url,venue,year&offset=0&limit=50 \"HTTP/1.1 200 OK\"\n",
      "2025-04-11 12:14:00,298 - INFO - _sync_search_paper_by_keywords: API call successful for query 'PaperRobot: Incremental Draft Generation of Scient...', returning 1 items.\n",
      "2025-04-11 12:14:03,324 - INFO - Graph state after initial search tasks. Nodes: 377, Edges: 325\n"
     ]
    }
   ],
   "source": [
    "# --- INITIAL QUERY on SEED ---\n",
    "# initial query for seed papers basic information\n",
    "print(\"--- Running Initial Query for Seed Papers Information ---\")\n",
    "await ps.init_search(\n",
    "    ps.research_topic,\n",
    "    ps.seed_paper_titles,\n",
    "    ps.seed_paper_dois,\n",
    "    ps.search_limit,\n",
    "    ps.from_dt,\n",
    "    ps.to_dt\n",
    ")\n",
    "# get seed DOIs\n",
    "seed_paper_dois = [node['id'] for node in ps.nodes_json if node['labels'] == ['Paper'] and node['properties'].get('from_seed')==True]\n",
    "seed_author_ids = []\n",
    "for node in ps.nodes_json:\n",
    "    if node['labels'] == ['Paper'] and node['properties'].get('from_seed')==True and isinstance(node['properties'].get('authors'), list):\n",
    "        authors_id = [x['authorId'] for x in node['properties']['authors'] if x['authorId'] is not None] \n",
    "        seed_author_ids.extend(authors_id)\n",
    "seed_paper_json = [node for node in ps.nodes_json if node['labels'] == ['Paper'] and node['properties'].get('from_seed')==True]\n",
    "ps.explored_nodes['seed'].extend(seed_paper_dois) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fd06b8",
   "metadata": {},
   "source": [
    "**Graph Stats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c28ae7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377 325 377 325\n",
      "[('Author', 264), ('Paper', 56), ('Journal', 30), ('Venue', 27)]\n",
      "[('WRITES', 268), ('PRINTS_ON', 29), ('RELEASES_IN', 28)]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from collections import Counter\n",
    "\n",
    "g = copy.deepcopy(ps.pg.graph)\n",
    "print(len(ps.nodes_json), len(ps.edges_json), len(g.nodes), len(g.edges))\n",
    "\n",
    "# check node types\n",
    "node_types = [g.nodes[nid].get('nodeType') for nid in g.nodes]\n",
    "node_types_cnt = Counter(node_types)\n",
    "# 按计数降序排序\n",
    "sorted_node_counts = node_types_cnt.most_common()\n",
    "print(sorted_node_counts)\n",
    "\n",
    "# check node types\n",
    "edge_types = [d.get('relationshipType') for u, v, d in g.edges(data=True)]\n",
    "edge_types_cnt = Counter(edge_types)\n",
    "# 按计数降序排序\n",
    "sorted_egdes_counts = edge_types_cnt.most_common()\n",
    "print(sorted_egdes_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb9e8b4",
   "metadata": {},
   "source": [
    "**Graph Viz**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a1afdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns # Ensure seaborn is imported for preprocessing functions\n",
    "import matplotlib.pyplot as plt # Ensure matplotlib is imported for preprocessing functions\n",
    "from typing import List, Dict, Optional\n",
    "from collections import Counter # Ensure Counter is imported for preprocessing functions\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Your Preprocessing Functions (Ensure they are defined/imported)\n",
    "#    (Copied from your request for completeness, with minor corrections)\n",
    "# =============================================================================\n",
    "\n",
    "def add_node_label(G, node_key_ref):\n",
    "    # node_key_ref = {'Paper': 'title', 'Author': 'name', 'Affiliation': '', 'Journal': '', 'Venue': ''}\n",
    "    for nid, node_data in G.nodes(data=True):\n",
    "        node_type = node_data.get('nodeType')\n",
    "        label_key = node_key_ref.get(node_type)\n",
    "        # Ensure label_key is valid and the attribute exists\n",
    "        if label_key and label_key in node_data:\n",
    "            node_data['vizLabel'] = node_data.get(label_key, f\"ID: {nid}\") # Fallback label\n",
    "        elif 'nodeType' in node_data:\n",
    "            node_data['vizLabel'] = f\"{node_data['nodeType']} ID: {nid}\" # Fallback with type\n",
    "        else:\n",
    "            node_data['vizLabel'] = f\"ID: {nid}\" # Generic fallback\n",
    "\n",
    "\n",
    "def add_edges_label(G):\n",
    "    # Corrected: Use G.edges, not G.edgs\n",
    "    for u, v, key, edge_data in G.edges(data=True, keys=True): # Use keys=True for MultiDiGraph\n",
    "        u_label = G.nodes[u].get('vizLabel', f\"ID: {u}\")\n",
    "        v_label = G.nodes[v].get('vizLabel', f\"ID: {v}\")\n",
    "        rel_type = edge_data.get('relationshipType', 'UNKNOWN')\n",
    "        # Use key to distinguish parallel edges if necessary\n",
    "        edge_data['vizLabel'] = f\"{u_label} -> {v_label} ({rel_type}, key={key})\"\n",
    "\n",
    "\n",
    "def assign_node_size(\n",
    "        G,\n",
    "        sig_nid_lst: Optional[List[str]] = None,\n",
    "        min_node_size: Optional[int] = 10,\n",
    "        max_node_size: Optional[int] = 50,\n",
    "        ):\n",
    "    \"\"\"assign node size (Corrected Logic)\"\"\"\n",
    "    paper_cites_ref, author_writes_ref = {}, {}\n",
    "\n",
    "    # First pass: Calculate counts for all relevant nodes\n",
    "    for nid, node_data in G.nodes(data=True):\n",
    "        node_type = node_data.get('nodeType')\n",
    "        if node_type == 'Paper':\n",
    "            # Corrected: Use G.in_edges(nid, data=True)\n",
    "            in_edges_info = G.in_edges(nid, data=True)\n",
    "            # Corrected: Check the edge data directly\n",
    "            cites_cnt = sum(1 for u, v, data in in_edges_info if data.get('relationshipType') == 'CITES')\n",
    "            paper_cites_ref[nid] = cites_cnt\n",
    "        elif node_type == 'Author':\n",
    "             # Corrected: Use G.out_edges(nid, data=True)\n",
    "            out_edges_info = G.out_edges(nid, data=True)\n",
    "             # Corrected: Check the edge data directly\n",
    "            writes_cnt = sum(1 for u, v, data in out_edges_info if data.get('relationshipType') == 'WRITES')\n",
    "            author_writes_ref[nid] = writes_cnt\n",
    "\n",
    "    # Determine min/max counts *after* collecting all counts\n",
    "    max_cites_cnt = max(paper_cites_ref.values()) if paper_cites_ref else 0\n",
    "    min_cites_cnt = min(paper_cites_ref.values()) if paper_cites_ref else 0\n",
    "    max_writes_cnt = max(author_writes_ref.values()) if author_writes_ref else 0\n",
    "    min_writes_cnt = min(author_writes_ref.values()) if author_writes_ref else 0\n",
    "\n",
    "    # Avoid division by zero if all counts are the same\n",
    "    cites_range = max_cites_cnt - min_cites_cnt if max_cites_cnt > min_cites_cnt else 1\n",
    "    writes_range = max_writes_cnt - min_writes_cnt if max_writes_cnt > min_writes_cnt else 1\n",
    "\n",
    "    # Second pass: Assign sizes\n",
    "    for nid, node_data in G.nodes(data=True):\n",
    "        node_data['vizSize'] = min_node_size # Default size\n",
    "\n",
    "        # Override for significant nodes\n",
    "        if sig_nid_lst is not None and nid in sig_nid_lst:\n",
    "            node_data['vizSize'] = max_node_size\n",
    "            continue # Skip dynamic sizing if it's a significant node\n",
    "\n",
    "        # Apply dynamic sizing based on counts for non-significant nodes\n",
    "        node_type = node_data.get('nodeType')\n",
    "        if node_type == 'Paper' and nid in paper_cites_ref:\n",
    "            value = paper_cites_ref[nid]\n",
    "            node_size = min_node_size + ((max_node_size - min_node_size) * (value - min_cites_cnt)) / cites_range\n",
    "            node_data['vizSize'] = max(min_node_size, min(max_node_size, node_size)) # Clamp size\n",
    "        elif node_type == 'Author' and nid in author_writes_ref:\n",
    "            value = author_writes_ref[nid]\n",
    "            node_size = min_node_size + ((max_node_size - min_node_size) * (value - min_writes_cnt)) / writes_range\n",
    "            node_data['vizSize'] = max(min_node_size, min(max_node_size, node_size)) # Clamp size\n",
    "\n",
    "\n",
    "def assign_edge_weight(\n",
    "        G,\n",
    "        edge_type_weight_ref,\n",
    "        default_weight: Optional[float] = 0.1\n",
    "        ):\n",
    "    # edge_type_weight_ref = {'CITES':0.5, 'DISCUSS':0.4, 'WRITES':0.3, 'WORKS_IN':0.2, 'PRINTS_ON':0.1, 'RELEASES_IN':0.1}\n",
    "    # Corrected: Use G.edges\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        weight = data.get('weight')\n",
    "        if weight is None:\n",
    "            node_type = data.get('relationshipType')\n",
    "            weight = edge_type_weight_ref.get(node_type)\n",
    "            if weight is None:\n",
    "                 weight = default_weight\n",
    "            data['weight'] = weight # Assign calculated weight back\n",
    "        # Ensure vizWidth is always set based on the final weight\n",
    "        data['vizWidth'] = data['weight'] * 10 # Scale weight for better visibility if needed\n",
    "\n",
    "\n",
    "def assign_node_color(\n",
    "        G,\n",
    "        sig_nid_lst: Optional[List[str]] = None,\n",
    "        default_colormap_name: Optional[str] = 'tab20', # Seaborn color map like 'tab10', 'colorblind', 'deep', 'muted' are good choices\n",
    "        default_color_cnt: Optional[int] = 10 # Increased default count for tab20\n",
    "        ):\n",
    "    \"\"\"assign color to node\n",
    "    for significant node, add highlight border\n",
    "    \"\"\"\n",
    "    highlight_border_color = '#FFD700' # Gold/Yellow - stands out well\n",
    "    highlight_border_width = 4       # Significantly thicker border for highlighted nodes\n",
    "    normal_border_width = 1          # Normal border width for non-highlighted nodes\n",
    "    default_node_color = '#CCCCCC'   # Default color if type is missing or unmapped\n",
    "    default_border_color = '#888888' # Default border color\n",
    "\n",
    "    node_types_lst = [G.nodes[nid].get('nodeType') for nid in G.nodes]\n",
    "    node_types_cnt = Counter(node_types_lst)\n",
    "     # Get unique types, filtering out None if present, but handle None later\n",
    "    unique_node_types = sorted([t for t in node_types_cnt if t is not None])\n",
    "    unique_node_cnt = len(unique_node_types)\n",
    "\n",
    "    if unique_node_cnt == 0:\n",
    "        colors_hex = []\n",
    "    elif unique_node_cnt <= default_color_cnt:\n",
    "        colors_hex = sns.color_palette(default_colormap_name, n_colors=unique_node_cnt).as_hex()\n",
    "    else:\n",
    "        colors_hex = sns.color_palette(default_colormap_name, n_colors=default_color_cnt).as_hex()\n",
    "        colors_hex.extend(['#808080']*(unique_node_cnt - default_color_cnt))\n",
    "\n",
    "    # Create a mapping from node type to its assigned color\n",
    "    type_to_color = dict(zip(unique_node_types, colors_hex))\n",
    "\n",
    "    # Assign colors and border properties to nodes in the graph\n",
    "    for nid, node_data in G.nodes(data=True):\n",
    "        node_type = node_data.get('nodeType') # Use .get() for safety\n",
    "\n",
    "        # Determine base color\n",
    "        original_color = type_to_color.get(node_type, default_node_color) # Use default if type is None or not mapped\n",
    "        node_data['vizColor'] = original_color\n",
    "\n",
    "        # Determine border properties based on significance\n",
    "        if sig_nid_lst is not None and nid in sig_nid_lst:\n",
    "            node_data['vizBorderColor'] = highlight_border_color\n",
    "            node_data['vizBorderWidth'] = highlight_border_width\n",
    "        else:\n",
    "            # Subtle border using a slightly darker shade of the node color or a fixed grey\n",
    "            # node_data['vizBorderColor'] = original_color\n",
    "            node_data['vizBorderColor'] = default_border_color # Use a fixed subtle border color\n",
    "            node_data['vizBorderWidth'] = normal_border_width\n",
    "\n",
    "def assign_edge_color(\n",
    "        G,\n",
    "        default_colormap_name: Optional[str] = 'Pastel1', # Use a different palette for edges\n",
    "        default_color_cnt: Optional[int] = 9 # Pastel1 has 9 colors\n",
    "        ):\n",
    "    \"\"\"assign color to edge\"\"\"\n",
    "    default_edge_color = '#AAAAAA' # Default color for unmapped or None types\n",
    "\n",
    "    # Corrected: Use G.edges(data=True)\n",
    "    edge_types_lst = [d.get('relationshipType') for u, v, d in G.edges(data=True)]\n",
    "    edge_types_cnt = Counter(edge_types_lst)\n",
    "    # Filter out None, handle it later\n",
    "    unique_edge_types = sorted([t for t in edge_types_cnt if t is not None])\n",
    "    unique_edge_cnt = len(unique_edge_types)\n",
    "\n",
    "    if unique_edge_cnt == 0:\n",
    "        colors_hex = []\n",
    "    elif unique_edge_cnt <= default_color_cnt:\n",
    "         # Use the full palette if enough colors\n",
    "        colors_hex = sns.color_palette(default_colormap_name, n_colors=unique_edge_cnt).as_hex()\n",
    "    else:\n",
    "        # Use the available colors and add grey for the rest\n",
    "        colors_hex = sns.color_palette(default_colormap_name, n_colors=default_color_cnt).as_hex()\n",
    "        colors_hex.extend(['#D3D3D3']*(unique_edge_cnt - default_color_cnt)) # Light grey for extras\n",
    "\n",
    "    # Create a mapping from edge type to its assigned color\n",
    "    type_to_color = dict(zip(unique_edge_types, colors_hex))\n",
    "\n",
    "    # Assign colors to edges in the graph\n",
    "    # Corrected: Use G.edges(data=True)\n",
    "    for u, v, edge_data in G.edges(data=True):\n",
    "        edge_type = edge_data.get('relationshipType') # Use .get() for safety\n",
    "        edge_color = type_to_color.get(edge_type, default_edge_color) # Fallback to default\n",
    "        edge_data['vizColor'] = edge_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "884e0db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running preprocessing...\n",
      "Sample node data after preprocessing (Paper1): {'nodeType': 'Paper', 'title': 'Intro to Graphs', 'year': 2021, 'vizLabel': 'Intro to Graphs', 'vizSize': 35, 'vizColor': '#2ca02c', 'vizBorderColor': '#FFD700', 'vizBorderWidth': 4}\n",
      "Sample edge data after preprocessing (Author1 -> Paper1, WRITES): {'relationshipType': 'WRITES', 'weight': 0.8, 'vizLabel': 'Author1 -> Paper1 (WRITES, key=0)', 'vizWidth': 8.0, 'vizColor': '#e6f5c9'}\n",
      "Preprocessing complete.\n",
      "Generating Bokeh visualization...\n",
      "Layout calculated using spring_layout.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from bokeh.plotting import figure, show # Removed from_networkx import\n",
    "from bokeh.models import (Circle, MultiLine, EdgesAndLinkedNodes, NodesAndLinkedEdges,\n",
    "                          HoverTool, TapTool, BoxSelectTool,\n",
    "                          ColumnDataSource, StaticLayoutProvider, Div, CustomJS,\n",
    "                          GraphRenderer) # Added GraphRenderer import explicitly\n",
    "from bokeh.layouts import column, row\n",
    "from bokeh.palettes import Spectral4 # Example palette\n",
    "import pandas as pd\n",
    "from collections import Counter # Ensure Counter is imported for preprocessing functions\n",
    "import seaborn as sns # Ensure seaborn is imported for preprocessing functions\n",
    "import matplotlib.pyplot as plt # Ensure matplotlib is imported for preprocessing functions\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Your Preprocessing Functions (Keep them exactly as you provided)\n",
    "#    ... (add_node_label, add_edges_label, assign_node_size, ...)\n",
    "# =============================================================================\n",
    "# (Your preprocessing functions go here - unchanged from your original code)\n",
    "\n",
    "def add_node_label(G, node_key_ref):\n",
    "    # node_key_ref = {'Paper': 'title', 'Author': 'name', 'Affiliation': '', 'Journal': '', 'Venue': ''}\n",
    "    for nid, node_data in G.nodes(data=True):\n",
    "        node_type = node_data.get('nodeType')\n",
    "        label_key = node_key_ref.get(node_type)\n",
    "        # Ensure label_key is valid and the attribute exists\n",
    "        if label_key and label_key in node_data:\n",
    "            node_data['vizLabel'] = node_data.get(label_key, f\"ID: {nid}\") # Fallback label\n",
    "        elif 'nodeType' in node_data:\n",
    "            node_data['vizLabel'] = f\"{node_data['nodeType']} ID: {nid}\" # Fallback with type\n",
    "        else:\n",
    "            node_data['vizLabel'] = f\"ID: {nid}\" # Generic fallback\n",
    "\n",
    "def add_edges_label(G):\n",
    "    # Corrected: Use G.edges, not G.edgs\n",
    "    for u, v, key, edge_data in G.edges(data=True, keys=True): # Use keys=True for MultiDiGraph\n",
    "        rel_type = edge_data.get('relationshipType', 'UNKNOWN')\n",
    "        # Use key to distinguish parallel edges if necessary\n",
    "        edge_data['vizLabel'] = f\"{u} -> {v} ({rel_type}, key={key})\"\n",
    "\n",
    "def assign_node_size(\n",
    "        G,\n",
    "        sig_nid_lst: Optional[List[str]] = None,\n",
    "        min_node_size: Optional[int] = 10,\n",
    "        max_node_size: Optional[int] = 50,\n",
    "        ):\n",
    "    \"\"\"assign node size (Corrected Logic)\"\"\"\n",
    "    paper_cites_ref, author_writes_ref = {}, {}\n",
    "\n",
    "    # First pass: Calculate counts for all relevant nodes\n",
    "    for nid, node_data in G.nodes(data=True):\n",
    "        node_type = node_data.get('nodeType')\n",
    "        if node_type == 'Paper':\n",
    "            # Corrected: Use G.in_edges(nid, data=True)\n",
    "            in_edges_info = G.in_edges(nid, data=True)\n",
    "            # Corrected: Check the edge data directly\n",
    "            cites_cnt = sum(1 for u, v, data in in_edges_info if data.get('relationshipType') == 'CITES')\n",
    "            paper_cites_ref[nid] = cites_cnt\n",
    "        elif node_type == 'Author':\n",
    "            # Corrected: Use G.out_edges(nid, data=True)\n",
    "            out_edges_info = G.out_edges(nid, data=True)\n",
    "            # Corrected: Check the edge data directly\n",
    "            writes_cnt = sum(1 for u, v, data in out_edges_info if data.get('relationshipType') == 'WRITES')\n",
    "            author_writes_ref[nid] = writes_cnt\n",
    "\n",
    "    # Determine min/max counts *after* collecting all counts\n",
    "    max_cites_cnt = max(paper_cites_ref.values()) if paper_cites_ref else 0\n",
    "    min_cites_cnt = min(paper_cites_ref.values()) if paper_cites_ref else 0\n",
    "    max_writes_cnt = max(author_writes_ref.values()) if author_writes_ref else 0\n",
    "    min_writes_cnt = min(author_writes_ref.values()) if author_writes_ref else 0\n",
    "\n",
    "    # Avoid division by zero if all counts are the same\n",
    "    cites_range = max_cites_cnt - min_cites_cnt if max_cites_cnt > min_cites_cnt else 1\n",
    "    writes_range = max_writes_cnt - min_writes_cnt if max_writes_cnt > min_writes_cnt else 1\n",
    "\n",
    "    # Second pass: Assign sizes\n",
    "    for nid, node_data in G.nodes(data=True):\n",
    "        node_data['vizSize'] = min_node_size # Default size\n",
    "\n",
    "        # Override for significant nodes\n",
    "        if sig_nid_lst is not None and nid in sig_nid_lst:\n",
    "            node_data['vizSize'] = max_node_size\n",
    "            continue # Skip dynamic sizing if it's a significant node\n",
    "\n",
    "        # Apply dynamic sizing based on counts for non-significant nodes\n",
    "        node_type = node_data.get('nodeType')\n",
    "        if node_type == 'Paper' and nid in paper_cites_ref:\n",
    "            value = paper_cites_ref[nid]\n",
    "            # Ensure value is numeric before calculation\n",
    "            if isinstance(value, (int, float)):\n",
    "                node_size = min_node_size + ((max_node_size - min_node_size) * (value - min_cites_cnt)) / cites_range\n",
    "                node_data['vizSize'] = max(min_node_size, min(max_node_size, node_size)) # Clamp size\n",
    "        elif node_type == 'Author' and nid in author_writes_ref:\n",
    "            value = author_writes_ref[nid]\n",
    "             # Ensure value is numeric before calculation\n",
    "            if isinstance(value, (int, float)):\n",
    "                node_size = min_node_size + ((max_node_size - min_node_size) * (value - min_writes_cnt)) / writes_range\n",
    "                node_data['vizSize'] = max(min_node_size, min(max_node_size, node_size)) # Clamp size\n",
    "\n",
    "\n",
    "def assign_edge_weight(\n",
    "        G,\n",
    "        edge_type_weight_ref,\n",
    "        default_weight: Optional[float] = 0.1\n",
    "        ):\n",
    "    # edge_type_weight_ref = {'CITES':0.5, 'DISCUSS':0.4, 'WRITES':0.3, 'WORKS_IN':0.2, 'PRINTS_ON':0.1, 'RELEASES_IN':0.1}\n",
    "    # Iterate through edges using keys for MultiDiGraph\n",
    "    for u, v, k, data in G.edges(data=True, keys=True):\n",
    "        weight = data.get('weight')\n",
    "        if weight is None:\n",
    "            edge_type = data.get('relationshipType') # Changed variable name for clarity\n",
    "            weight = edge_type_weight_ref.get(edge_type)\n",
    "            if weight is None:\n",
    "                weight = default_weight\n",
    "            data['weight'] = weight # Assign calculated weight back\n",
    "\n",
    "        # Ensure vizWidth is always set based on the final weight\n",
    "        # Convert weight to float before multiplication\n",
    "        try:\n",
    "           data['vizWidth'] = float(data['weight']) * 10 # Scale weight for better visibility\n",
    "        except (ValueError, TypeError):\n",
    "           data['vizWidth'] = float(default_weight) * 10 # Fallback width\n",
    "\n",
    "\n",
    "def assign_node_color(\n",
    "        G,\n",
    "        sig_nid_lst: Optional[List[str]] = None,\n",
    "        default_colormap_name: Optional[str] = 'tab20', # Seaborn color map like 'tab10', 'colorblind', 'deep', 'muted' are good choices\n",
    "        default_color_cnt: Optional[int] = 10 # Increased default count for tab20\n",
    "        ):\n",
    "    \"\"\"assign color to node\n",
    "    for significant node, add highlight border\n",
    "    \"\"\"\n",
    "    highlight_border_color = '#FFD700' # Gold/Yellow - stands out well\n",
    "    highlight_border_width = 4        # Significantly thicker border for highlighted nodes\n",
    "    normal_border_width = 1         # Normal border width for non-highlighted nodes\n",
    "    default_node_color = '#CCCCCC'    # Default color if type is missing or unmapped\n",
    "    default_border_color = '#888888' # Default border color\n",
    "\n",
    "    node_types_lst = [G.nodes[nid].get('nodeType') for nid in G.nodes]\n",
    "    node_types_cnt = Counter(node_types_lst)\n",
    "     # Get unique types, filtering out None if present, but handle None later\n",
    "    unique_node_types = sorted([t for t in node_types_cnt if t is not None])\n",
    "    unique_node_cnt = len(unique_node_types)\n",
    "\n",
    "    if unique_node_cnt == 0:\n",
    "        colors_hex = []\n",
    "    elif unique_node_cnt <= default_color_cnt:\n",
    "        colors_hex = sns.color_palette(default_colormap_name, n_colors=unique_node_cnt).as_hex()\n",
    "    else:\n",
    "        colors_hex = sns.color_palette(default_colormap_name, n_colors=default_color_cnt).as_hex()\n",
    "        colors_hex.extend(['#808080']*(unique_node_cnt - default_color_cnt))\n",
    "\n",
    "    # Create a mapping from node type to its assigned color\n",
    "    type_to_color = dict(zip(unique_node_types, colors_hex))\n",
    "\n",
    "    # Assign colors and border properties to nodes in the graph\n",
    "    for nid, node_data in G.nodes(data=True):\n",
    "        node_type = node_data.get('nodeType') # Use .get() for safety\n",
    "\n",
    "        # Determine base color\n",
    "        original_color = type_to_color.get(node_type, default_node_color) # Use default if type is None or not mapped\n",
    "        node_data['vizColor'] = original_color\n",
    "\n",
    "        # Determine border properties based on significance\n",
    "        if sig_nid_lst is not None and nid in sig_nid_lst:\n",
    "            node_data['vizBorderColor'] = highlight_border_color\n",
    "            node_data['vizBorderWidth'] = highlight_border_width\n",
    "        else:\n",
    "            # Subtle border using a slightly darker shade of the node color or a fixed grey\n",
    "            # node_data['vizBorderColor'] = original_color\n",
    "            node_data['vizBorderColor'] = default_border_color # Use a fixed subtle border color\n",
    "            node_data['vizBorderWidth'] = normal_border_width\n",
    "\n",
    "def assign_edge_color(\n",
    "        G,\n",
    "        default_colormap_name: Optional[str] = 'Pastel1', # Use a different palette for edges\n",
    "        default_color_cnt: Optional[int] = 9 # Pastel1 has 9 colors\n",
    "        ):\n",
    "    \"\"\"assign color to edge\"\"\"\n",
    "    default_edge_color = '#AAAAAA' # Default color for unmapped or None types\n",
    "\n",
    "    # Use G.edges(data=True, keys=True) for MultiDiGraph\n",
    "    edge_types_lst = [d.get('relationshipType') for u, v, k, d in G.edges(data=True, keys=True)]\n",
    "    edge_types_cnt = Counter(edge_types_lst)\n",
    "    # Filter out None, handle it later\n",
    "    unique_edge_types = sorted([t for t in edge_types_cnt if t is not None])\n",
    "    unique_edge_cnt = len(unique_edge_types)\n",
    "\n",
    "    if unique_edge_cnt == 0:\n",
    "        colors_hex = []\n",
    "    elif unique_edge_cnt <= default_color_cnt:\n",
    "        # Use the full palette if enough colors\n",
    "        colors_hex = sns.color_palette(default_colormap_name, n_colors=unique_edge_cnt).as_hex()\n",
    "    else:\n",
    "        # Use the available colors and add grey for the rest\n",
    "        colors_hex = sns.color_palette(default_colormap_name, n_colors=default_color_cnt).as_hex()\n",
    "        colors_hex.extend(['#D3D3D3']*(unique_edge_cnt - default_color_cnt)) # Light grey for extras\n",
    "\n",
    "    # Create a mapping from edge type to its assigned color\n",
    "    type_to_color = dict(zip(unique_edge_types, colors_hex))\n",
    "\n",
    "    # Assign colors to edges in the graph\n",
    "    # Use G.edges(data=True, keys=True) for MultiDiGraph\n",
    "    for u, v, k, edge_data in G.edges(data=True, keys=True):\n",
    "        edge_type = edge_data.get('relationshipType') # Use .get() for safety\n",
    "        edge_color = type_to_color.get(edge_type, default_edge_color) # Fallback to default\n",
    "        edge_data['vizColor'] = edge_color\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Bokeh Visualization Function (REVISED)\n",
    "# =============================================================================\n",
    "\n",
    "def visualize_graph_bokeh(G, title=\"Interactive Network Graph\"):\n",
    "    \"\"\"\n",
    "    Visualizes a preprocessed NetworkX MultiDiGraph using Bokeh by manually\n",
    "    configuring the GraphRenderer.\n",
    "\n",
    "    Args:\n",
    "        G (nx.MultiDiGraph): The graph with 'viz*' attributes already added.\n",
    "        title (str): The title for the Bokeh plot.\n",
    "    \"\"\"\n",
    "    # --- 1. Calculate Layout ---\n",
    "    try:\n",
    "        pos = nx.spring_layout(G, k=0.5, iterations=50, seed=42)\n",
    "        print(\"Layout calculated using spring_layout.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Spring layout failed ({e}), trying Kamada-Kawai layout.\")\n",
    "        try:\n",
    "            pos = nx.kamada_kawai_layout(G)\n",
    "            print(\"Layout calculated using kamada_kawai_layout.\")\n",
    "        except Exception as e2:\n",
    "            print(f\"Kamada-Kawai layout also failed ({e2}), using random layout.\")\n",
    "            pos = nx.random_layout(G, seed=42)\n",
    "            print(\"Layout calculated using random_layout.\")\n",
    "\n",
    "    # Create a layout provider using the calculated positions\n",
    "    graph_layout = StaticLayoutProvider(graph_layout=pos)\n",
    "\n",
    "    # --- 2. Prepare Data Sources (Ensure all viz* and attr_* are included) ---\n",
    "    node_ids = list(G.nodes())\n",
    "    node_data = dict(\n",
    "        index=node_ids, # Bokeh uses 'index' for node IDs in GraphRenderer\n",
    "        # x and y positions are handled by the layout_provider, not needed in source\n",
    "        vizSize=[G.nodes[nid].get('vizSize', 10) for nid in node_ids],\n",
    "        vizColor=[G.nodes[nid].get('vizColor', '#CCCCCC') for nid in node_ids],\n",
    "        vizBorderColor=[G.nodes[nid].get('vizBorderColor', '#888888') for nid in node_ids],\n",
    "        vizBorderWidth=[G.nodes[nid].get('vizBorderWidth', 1) for nid in node_ids],\n",
    "        vizLabel=[G.nodes[nid].get('vizLabel', str(nid)) for nid in node_ids]\n",
    "    )\n",
    "    # Add ALL other node attributes for the click callback\n",
    "    all_node_attrs = {}\n",
    "    if G.nodes:\n",
    "        # Collect all unique attribute keys from all nodes\n",
    "        all_keys = set()\n",
    "        for nid in G.nodes():\n",
    "           all_keys.update(G.nodes[nid].keys())\n",
    "\n",
    "        for key in all_keys:\n",
    "            if key not in ['vizSize', 'vizColor', 'vizBorderColor', 'vizBorderWidth', 'vizLabel']:\n",
    "                all_node_attrs[f\"attr_{key}\"] = [G.nodes[nid].get(key, 'N/A') for nid in node_ids]\n",
    "\n",
    "    node_data.update(all_node_attrs)\n",
    "    node_source = ColumnDataSource(data=node_data)\n",
    "\n",
    "    # Extract edge attributes for ColumnDataSource\n",
    "    # Ensure start/end nodes match the node_ids ('index' in node_source)\n",
    "    start_nodes = [u for u, v, k in G.edges(keys=True)]\n",
    "    end_nodes = [v for u, v, k in G.edges(keys=True)]\n",
    "    edge_data = dict(\n",
    "        start=start_nodes, # Bokeh uses 'start' and 'end' for edge connections\n",
    "        end=end_nodes,\n",
    "        vizWidth=[data.get('vizWidth', 1) for u, v, k, data in G.edges(data=True, keys=True)],\n",
    "        vizColor=[data.get('vizColor', '#AAAAAA') for u, v, k, data in G.edges(data=True, keys=True)],\n",
    "        vizLabel=[data.get('vizLabel', '') for u, v, k, data in G.edges(data=True, keys=True)]\n",
    "    )\n",
    "     # Add ALL other edge attributes for the click callback\n",
    "    all_edge_attrs = {}\n",
    "    if G.edges:\n",
    "        # Collect all unique attribute keys from all edges\n",
    "        all_keys = set()\n",
    "        for u, v, k, data in G.edges(data=True, keys=True):\n",
    "            all_keys.update(data.keys())\n",
    "\n",
    "        for key in all_keys:\n",
    "            if key not in ['vizWidth', 'vizColor', 'vizLabel']:\n",
    "                # Ensure edge data access uses keys for MultiDiGraph\n",
    "                all_edge_attrs[f\"attr_{key}\"] = [G.get_edge_data(u, v, k).get(key, 'N/A')\n",
    "                                                  for u, v, k in G.edges(keys=True)]\n",
    "\n",
    "    edge_data.update(all_edge_attrs)\n",
    "    edge_source = ColumnDataSource(data=edge_data)\n",
    "\n",
    "\n",
    "    # --- 3. Create Bokeh Plot ---\n",
    "    plot = figure(title=title,\n",
    "                  x_range=(-1.1, 1.1), y_range=(-1.1, 1.1),\n",
    "                  tools=\"pan,wheel_zoom,box_zoom,reset,save\", # Basic tools + TapTool added later\n",
    "                  width=800, height=600,\n",
    "                  x_axis_location=None, y_axis_location=None)\n",
    "    plot.grid.grid_line_color = None\n",
    "\n",
    "    # --- 4. Manually Create and Configure GraphRenderer ---\n",
    "    graph_renderer = GraphRenderer()\n",
    "\n",
    "    # Assign layout provider\n",
    "    graph_renderer.layout_provider = graph_layout\n",
    "\n",
    "    # Configure Node Renderer\n",
    "    graph_renderer.node_renderer.data_source = node_source # Use the prepared source\n",
    "    graph_renderer.node_renderer.glyph = Circle(\n",
    "        radius='vizSize', # Use 'radius' instead of 'size' for Circle\n",
    "        fill_color='vizColor',\n",
    "        line_color='vizBorderColor',\n",
    "        line_width='vizBorderWidth',\n",
    "        fill_alpha=0.8,\n",
    "        line_alpha=1.0\n",
    "    )\n",
    "    graph_renderer.node_renderer.selection_glyph = Circle(\n",
    "        radius='vizSize', fill_color='vizColor', line_color='red', line_width=3, fill_alpha=0.9, line_alpha=1.0)\n",
    "    graph_renderer.node_renderer.hover_glyph = Circle(\n",
    "        radius='vizSize', fill_color='vizColor', line_color='orange', line_width=3, fill_alpha=0.9, line_alpha=1.0)\n",
    "\n",
    "    # Configure Edge Renderer\n",
    "    graph_renderer.edge_renderer.data_source = edge_source # Use the prepared source\n",
    "    graph_renderer.edge_renderer.glyph = MultiLine(\n",
    "        line_color='vizColor',\n",
    "        line_width='vizWidth',\n",
    "        line_alpha=0.6\n",
    "    )\n",
    "    graph_renderer.edge_renderer.selection_glyph = MultiLine(\n",
    "        line_color='red', line_width='vizWidth', line_alpha=1.0)\n",
    "    graph_renderer.edge_renderer.hover_glyph = MultiLine(\n",
    "        line_color='orange', line_width='vizWidth', line_alpha=1.0)\n",
    "\n",
    "    # --- 5. Configure Interaction Policies ---\n",
    "    # These define how selections and hovers affect linked elements\n",
    "    graph_renderer.selection_policy = NodesAndLinkedEdges() # Clicking node selects node + its edges\n",
    "    graph_renderer.inspection_policy = EdgesAndLinkedNodes() # Hovering edge highlights edge + connected nodes\n",
    "\n",
    "    # --- 6. Add Renderer to Plot ---\n",
    "    plot.renderers.append(graph_renderer)\n",
    "\n",
    "    # --- 7. Configure HoverTool (Ensure it only targets specific renderers) ---\n",
    "    node_hover_tooltips = [\n",
    "        (\"Label\", \"@vizLabel\"),\n",
    "        (\"Node ID\", \"@index\"), # Use 'index' which is the node ID column\n",
    "        (\"Type\", \"@attr_nodeType\"), # Example showing an original attribute\n",
    "    ]\n",
    "    # Filter out tooltips for attributes that might not exist in all nodes\n",
    "    node_hover_tooltips = [(label, field) for label, field in node_hover_tooltips if field in node_source.data]\n",
    "\n",
    "    node_hover = HoverTool(tooltips=node_hover_tooltips,\n",
    "                           renderers=[graph_renderer.node_renderer]) # *** Crucial: Target only nodes ***\n",
    "\n",
    "    edge_hover_tooltips = [\n",
    "        (\"Label\", \"@vizLabel\"),\n",
    "        (\"Type\", \"@attr_relationshipType\"), # Example\n",
    "        (\"Weight\", \"@attr_weight\"),         # Example\n",
    "    ]\n",
    "    # Filter out tooltips for attributes that might not exist in all edges\n",
    "    edge_hover_tooltips = [(label, field) for label, field in edge_hover_tooltips if field in edge_source.data]\n",
    "\n",
    "    edge_hover = HoverTool(tooltips=edge_hover_tooltips,\n",
    "                           renderers=[graph_renderer.edge_renderer]) # *** Crucial: Target only edges ***\n",
    "\n",
    "    # Add ONLY these specific hover tools\n",
    "    plot.add_tools(node_hover, edge_hover)\n",
    "\n",
    "    # --- 8. Configure TapTool and Info Display ---\n",
    "    info_div = Div(text=\"Click on a node or edge to see its details.\", width=780, height=100, styles={'overflow-y': 'auto'}) # Added height and scroll\n",
    "\n",
    "    # JavaScript callback - unchanged, but ensure args point to the correct sources\n",
    "    callback_code = \"\"\"\n",
    "        const node_indices = node_source.selected.indices;\n",
    "        const edge_indices = edge_source.selected.indices;\n",
    "        let html = \"<b>Selected Element Details:</b><br><hr>\";\n",
    "\n",
    "        // Helper function to safely get data and format N/A or null\n",
    "        function getData(source, key, index) {\n",
    "            if (source.data[key] && index < source.data[key].length) {\n",
    "                const value = source.data[key][index];\n",
    "                return (value === null || value === undefined) ? 'N/A' : value;\n",
    "            }\n",
    "            return 'N/A';\n",
    "        }\n",
    "\n",
    "        if (node_indices.length > 0) {\n",
    "            const index = node_indices[0]; // Show info for the first selected node\n",
    "            html += \"<b>Type:</b> Node<br>\";\n",
    "            html += \"<b>ID:</b> \" + getData(node_source, 'index', index) + \"<br>\";\n",
    "            // Iterate through keys, prioritize vizLabel, then show attr_ fields\n",
    "            if ('vizLabel' in node_source.data) {\n",
    "                 html += \"<b>Label:</b> \" + getData(node_source, 'vizLabel', index) + \"<br>\";\n",
    "            }\n",
    "            for (const key in node_source.data) {\n",
    "                if (key.startsWith('attr_')) {\n",
    "                    const attr_name = key.substring(5); // Remove 'attr_' prefix\n",
    "                    // Avoid duplicating label if it came from an attr_ field used for vizLabel\n",
    "                    if (key !== 'attr_vizLabel') {\n",
    "                         html += \"<b>\" + attr_name + \":</b> \" + getData(node_source, key, index) + \"<br>\";\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "\n",
    "        } else if (edge_indices.length > 0) {\n",
    "            const index = edge_indices[0]; // Show info for the first selected edge\n",
    "            html += \"<b>Type:</b> Edge<br>\";\n",
    "            html += \"<b>From:</b> \" + getData(edge_source, 'start', index) + \"<br>\";\n",
    "            html += \"<b>To:</b> \" + getData(edge_source, 'end', index) + \"<br>\";\n",
    "             // Iterate through keys, prioritize vizLabel, then show attr_ fields\n",
    "            if ('vizLabel' in edge_source.data) {\n",
    "                 html += \"<b>Label:</b> \" + getData(edge_source, 'vizLabel', index) + \"<br>\";\n",
    "            }\n",
    "            for (const key in edge_source.data) {\n",
    "                 if (key.startsWith('attr_')) {\n",
    "                    const attr_name = key.substring(5); // Remove 'attr_' prefix\n",
    "                    // Avoid duplicating label if it came from an attr_ field used for vizLabel\n",
    "                    if (key !== 'attr_vizLabel') {\n",
    "                        html += \"<b>\" + attr_name + \":</b> \" + getData(edge_source, key, index) + \"<br>\";\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "\n",
    "        } else {\n",
    "            html = \"Click on a node or edge to see its details.\";\n",
    "        }\n",
    "\n",
    "        info_div.text = html;\n",
    "    \"\"\"\n",
    "\n",
    "    tap_callback = CustomJS(args=dict(node_source=graph_renderer.node_renderer.data_source, # Use renderer's source\n",
    "                                      edge_source=graph_renderer.edge_renderer.data_source, # Use renderer's source\n",
    "                                      info_div=info_div),\n",
    "                            code=callback_code)\n",
    "\n",
    "    # Add TapTool, ensuring it triggers the callback for clicks on nodes/edges\n",
    "    tap_tool = TapTool(renderers=[graph_renderer.node_renderer, graph_renderer.edge_renderer],\n",
    "                       callback=tap_callback)\n",
    "    plot.add_tools(tap_tool)\n",
    "\n",
    "\n",
    "    # --- 9. Layout and Show ---\n",
    "    layout = column(info_div, plot)\n",
    "    show(layout)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Example Usage (Keep as is)\n",
    "# =============================================================================\n",
    "if __name__ == '__main__':\n",
    "    # --- Create a Sample MultiDiGraph ---\n",
    "    G = nx.MultiDiGraph()\n",
    "\n",
    "    # Add nodes with types and attributes\n",
    "    G.add_node(\"Paper1\", nodeType='Paper', title='Intro to Graphs', year=2021) # Removed vizLabel here, let preprocessing handle it\n",
    "    G.add_node(\"Paper2\", nodeType='Paper', title='Advanced Networks', year=2022)\n",
    "    G.add_node(\"Paper3\", nodeType='Paper', title='Visualization Techniques', year=2023)\n",
    "    G.add_node(\"Author1\", nodeType='Author', name='Alice', affiliation='Inst A')\n",
    "    G.add_node(\"Author2\", nodeType='Author', name='Bob', affiliation='Inst B')\n",
    "    G.add_node(\"Venue1\", nodeType='Venue', name='Conf X')\n",
    "    G.add_node(\"Journal1\", nodeType='Journal', name='Journal Y')\n",
    "    G.add_node(\"MissingTypeNode\") # Node without 'nodeType'\n",
    "\n",
    "    # Add edges with types and attributes\n",
    "    G.add_edge(\"Author1\", \"Paper1\", relationshipType='WRITES', weight=0.8) # Removed vizLabel here\n",
    "    G.add_edge(\"Author1\", \"Paper2\", relationshipType='WRITES', weight=0.9)\n",
    "    G.add_edge(\"Author2\", \"Paper1\", relationshipType='WRITES', weight=0.7)\n",
    "    G.add_edge(\"Author2\", \"Paper3\", relationshipType='WRITES', weight=0.8)\n",
    "    G.add_edge(\"Paper2\", \"Paper1\", relationshipType='CITES', weight=0.5) # P1 cited once\n",
    "    G.add_edge(\"Paper3\", \"Paper1\", relationshipType='CITES', weight=0.6) # P1 cited twice\n",
    "    G.add_edge(\"Paper3\", \"Paper2\", relationshipType='CITES', weight=0.4) # P2 cited once\n",
    "    G.add_edge(\"Paper1\", \"Venue1\", relationshipType='RELEASES_IN', weight=0.2)\n",
    "    G.add_edge(\"Paper2\", \"Journal1\", relationshipType='PRINTS_ON', weight=0.3)\n",
    "    G.add_edge(\"Paper3\", \"Venue1\", relationshipType='RELEASES_IN', weight=0.2)\n",
    "    # Add an edge without a relationshipType\n",
    "    G.add_edge(\"Author1\", \"Author2\") # Let preprocessing handle label\n",
    "    # Add a parallel edge\n",
    "    G.add_edge(\"Author1\", \"Paper1\", key=\"review\", relationshipType='REVIEWS', weight=0.1) # Let preprocessing handle label\n",
    "\n",
    "    # --- Run Preprocessing ---\n",
    "    print(\"Running preprocessing...\")\n",
    "    # Define how to get labels from node attributes based on nodeType\n",
    "    node_key_ref = {'Paper': 'title', 'Author': 'name', 'Venue': 'name', 'Journal': 'name'}\n",
    "    # Define base weights for edge types (used if edge has no 'weight' attribute)\n",
    "    edge_type_weight_ref = {'CITES':0.5, 'DISCUSS':0.4, 'WRITES':0.3, 'WORKS_IN':0.2, 'PRINTS_ON':0.1, 'RELEASES_IN':0.1, 'REVIEWS': 0.05}\n",
    "    # Define which nodes should be highlighted (larger size, different border)\n",
    "    significant_nodes = [\"Paper1\"]\n",
    "\n",
    "    # Apply preprocessing functions to add 'viz*' attributes\n",
    "    add_node_label(G, node_key_ref)\n",
    "    add_edges_label(G) # Ensure this adds 'vizLabel' to edges\n",
    "    assign_node_size(G, sig_nid_lst=significant_nodes, min_node_size=10, max_node_size=35) # Adjusted max size\n",
    "    assign_edge_weight(G, edge_type_weight_ref, default_weight=0.05) # Adds 'weight' and 'vizWidth'\n",
    "    assign_node_color(G, sig_nid_lst=significant_nodes, default_colormap_name='tab10') # Adds 'vizColor', 'vizBorderColor', 'vizBorderWidth'\n",
    "    assign_edge_color(G, default_colormap_name='Pastel2') # Adds 'vizColor'\n",
    "\n",
    "    # Add a small check for viz attributes after preprocessing\n",
    "    print(\"Sample node data after preprocessing (Paper1):\", G.nodes[\"Paper1\"])\n",
    "    print(\"Sample edge data after preprocessing (Author1 -> Paper1, WRITES):\", G.get_edge_data(\"Author1\", \"Paper1\")[0]) # Access first edge if parallel\n",
    "\n",
    "\n",
    "    print(\"Preprocessing complete.\")\n",
    "\n",
    "    # --- Visualize ---\n",
    "    print(\"Generating Bokeh visualization...\")\n",
    "    visualize_graph_bokeh(G, title=\"Interactive Publication Network\")\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7469a190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from bokeh.plotting import figure, show, from_networkx\n",
    "from bokeh.models import (Circle, MultiLine, EdgesAndLinkedNodes, NodesAndLinkedEdges,\n",
    "                          HoverTool, TapTool, BoxSelectTool,\n",
    "                          ColumnDataSource, StaticLayoutProvider, Div, CustomJS)\n",
    "from bokeh.layouts import column, row\n",
    "from bokeh.palettes import Spectral4 # Example palette\n",
    "import pandas as pd\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Bokeh Visualization Function\n",
    "# =============================================================================\n",
    "\n",
    "def visualize_graph_bokeh(G, title=\"Interactive Network Graph\"):\n",
    "    \"\"\"\n",
    "    Visualizes a preprocessed NetworkX MultiDiGraph using Bokeh.\n",
    "\n",
    "    Args:\n",
    "        G (nx.MultiDiGraph): The graph with 'viz*' attributes already added.\n",
    "        title (str): The title for the Bokeh plot.\n",
    "    \"\"\"\n",
    "    # --- 1. Calculate Layout ---\n",
    "    # spring_layout is often good for general graphs. Adjust k for spacing.\n",
    "    # kamada_kawai_layout is another good option, often slower but potentially better layout.\n",
    "    try:\n",
    "        # Use spring_layout, may need more iterations for large graphs\n",
    "        pos = nx.spring_layout(G, k=0.5, iterations=50, seed=42)\n",
    "        print(\"Layout calculated using spring_layout.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Spring layout failed ({e}), trying Kamada-Kawai layout.\")\n",
    "        try:\n",
    "            pos = nx.kamada_kawai_layout(G)\n",
    "            print(\"Layout calculated using kamada_kawai_layout.\")\n",
    "        except Exception as e2:\n",
    "            print(f\"Kamada-Kawai layout also failed ({e2}), using random layout.\")\n",
    "            pos = nx.random_layout(G, seed=42)\n",
    "            print(\"Layout calculated using random_layout.\")\n",
    "\n",
    "\n",
    "    # --- 2. Prepare Data Sources ---\n",
    "    # Extract node attributes into a dictionary for ColumnDataSource\n",
    "    node_ids = list(G.nodes())\n",
    "    node_data = dict(\n",
    "        index=node_ids,\n",
    "        x=[pos[nid][0] for nid in node_ids],\n",
    "        y=[pos[nid][1] for nid in node_ids],\n",
    "        vizSize=[G.nodes[nid].get('vizSize', 10) for nid in node_ids],\n",
    "        vizColor=[G.nodes[nid].get('vizColor', '#CCCCCC') for nid in node_ids],\n",
    "        vizBorderColor=[G.nodes[nid].get('vizBorderColor', '#888888') for nid in node_ids],\n",
    "        vizBorderWidth=[G.nodes[nid].get('vizBorderWidth', 1) for nid in node_ids],\n",
    "        vizLabel=[G.nodes[nid].get('vizLabel', str(nid)) for nid in node_ids]\n",
    "    )\n",
    "    # Add ALL other node attributes for the click callback\n",
    "    all_node_attrs = {}\n",
    "    if G.nodes:\n",
    "        first_node_data = next(iter(G.nodes(data=True)))[1]\n",
    "        for key in first_node_data.keys():\n",
    "            # Add attribute if it's not already handled explicitly\n",
    "            if key not in ['vizSize', 'vizColor', 'vizBorderColor', 'vizBorderWidth', 'vizLabel']:\n",
    "                 # Prefix to avoid name clashes and easily identify in JS\n",
    "                all_node_attrs[f\"attr_{key}\"] = [G.nodes[nid].get(key, 'N/A') for nid in node_ids]\n",
    "\n",
    "    node_data.update(all_node_attrs)\n",
    "    node_source = ColumnDataSource(data=node_data)\n",
    "\n",
    "    # Extract edge attributes for ColumnDataSource\n",
    "    start_nodes = [u for u, v, k in G.edges(keys=True)]\n",
    "    end_nodes = [v for u, v, k in G.edges(keys=True)]\n",
    "    edge_data = dict(\n",
    "        start=start_nodes,\n",
    "        end=end_nodes,\n",
    "        vizWidth=[data.get('vizWidth', 1) for u, v, data in G.edges(data=True)],\n",
    "        vizColor=[data.get('vizColor', '#AAAAAA') for u, v, data in G.edges(data=True)],\n",
    "        vizLabel=[data.get('vizLabel', '') for u, v, data in G.edges(data=True)]\n",
    "    )\n",
    "    # Add ALL other edge attributes for the click callback\n",
    "    all_edge_attrs = {}\n",
    "    if G.edges:\n",
    "        # Need to handle potential key differences if edges have varied attributes\n",
    "        # Let's gather all unique keys first\n",
    "        all_keys = set()\n",
    "        for u, v, data in G.edges(data=True):\n",
    "            all_keys.update(data.keys())\n",
    "\n",
    "        for key in all_keys:\n",
    "             if key not in ['vizWidth', 'vizColor', 'vizLabel']:\n",
    "                  # Prefix to avoid name clashes\n",
    "                 all_edge_attrs[f\"attr_{key}\"] = [G.get_edge_data(u, v, k).get(key, 'N/A')\n",
    "                                                  for u, v, k in G.edges(keys=True)] # Iterate with keys\n",
    "\n",
    "    edge_data.update(all_edge_attrs)\n",
    "    edge_source = ColumnDataSource(data=edge_data)\n",
    "\n",
    "    # --- 3. Create Bokeh Plot ---\n",
    "    plot = figure(title=title,\n",
    "                  x_range=(-1.1, 1.1), y_range=(-1.1, 1.1), # Adjust range based on layout\n",
    "                  tools=\"pan,wheel_zoom,box_zoom,reset,save\", # Basic interaction tools\n",
    "                  width=800, height=600, # Adjust size as needed\n",
    "                  x_axis_location=None, y_axis_location=None) # Hide axes\n",
    "    plot.grid.grid_line_color = None # Hide grid lines\n",
    "\n",
    "    # --- 4. Setup GraphRenderer ---\n",
    "    graph_renderer = from_networkx(G, pos, scale=1, center=(0, 0)) # Use from_networkx for convenience\n",
    "\n",
    "    # Update renderer data sources AFTER creation by from_networkx\n",
    "    graph_renderer.node_renderer.data_source.data = dict(node_source.data)\n",
    "    graph_renderer.edge_renderer.data_source.data = dict(edge_source.data)\n",
    "\n",
    "    # --- 5. Configure Node Glyphs ---\n",
    "    graph_renderer.node_renderer.glyph = Circle(\n",
    "        radius='vizSize',\n",
    "        fill_color='vizColor',\n",
    "        line_color='vizBorderColor',\n",
    "        line_width='vizBorderWidth',\n",
    "        fill_alpha=0.8, # Slight transparency\n",
    "        line_alpha=1.0\n",
    "    )\n",
    "    # Set selection and non-selection appearance for nodes\n",
    "    graph_renderer.node_renderer.selection_glyph = Circle(\n",
    "        radius='vizSize', fill_color='vizColor', line_color='red', line_width=3)\n",
    "    graph_renderer.node_renderer.hover_glyph = Circle(\n",
    "        radius='vizSize', fill_color='vizColor', line_color='orange', line_width=3)\n",
    "\n",
    "    # --- 6. Configure Edge Glyphs ---\n",
    "    graph_renderer.edge_renderer.glyph = MultiLine(\n",
    "        line_color='vizColor',\n",
    "        line_width='vizWidth',\n",
    "        line_alpha=0.6 # Make edges slightly transparent\n",
    "    )\n",
    "    # Set selection and non-selection appearance for edges\n",
    "    graph_renderer.edge_renderer.selection_glyph = MultiLine(\n",
    "        line_color='red', line_width='vizWidth', line_alpha=1.0)\n",
    "    graph_renderer.edge_renderer.hover_glyph = MultiLine(\n",
    "        line_color='orange', line_width='vizWidth', line_alpha=1.0)\n",
    "\n",
    "\n",
    "    # --- 7. Add Renderer to Plot ---\n",
    "    plot.renderers.append(graph_renderer)\n",
    "\n",
    "    # --- 8. Configure HoverTool ---\n",
    "    # Tooltip for Nodes\n",
    "    node_hover_tooltips = [\n",
    "        (\"Label\", \"@vizLabel\"),\n",
    "        (\"Node ID\", \"@index\"),\n",
    "        # (\"Type\", \"@attr_nodeType\"), # Example if 'attr_nodeType' exists\n",
    "    ]\n",
    "    node_hover = HoverTool(tooltips=node_hover_tooltips, renderers=[graph_renderer.node_renderer])\n",
    "\n",
    "    # Tooltip for Edges\n",
    "    edge_hover_tooltips = [\n",
    "        (\"Label\", \"@vizLabel\"),\n",
    "        # (\"Type\", \"@attr_relationshipType\"), # Example if 'attr_relationshipType' exists\n",
    "        # (\"Weight\", \"@attr_weight\"),        # Example if 'attr_weight' exists\n",
    "    ]\n",
    "    edge_hover = HoverTool(tooltips=edge_hover_tooltips, renderers=[graph_renderer.edge_renderer])\n",
    "\n",
    "    plot.add_tools(node_hover, edge_hover)\n",
    "\n",
    "    # --- 9. Configure TapTool and Info Display ---\n",
    "    # Add a Div to display information on click\n",
    "    info_div = Div(text=\"Click on a node or edge to see its details.\", width=780)\n",
    "\n",
    "    # JavaScript callback for TapTool (handles both nodes and edges)\n",
    "    # This JS code accesses the selected data from the sources and updates the Div\n",
    "    # It iterates through keys starting with 'attr_' to show all original attributes\n",
    "    callback_code = \"\"\"\n",
    "        const node_indices = node_source.selected.indices;\n",
    "        const edge_indices = edge_source.selected.indices;\n",
    "        let html = \"<b>Selected Element Details:</b><br><hr>\";\n",
    "\n",
    "        if (node_indices.length > 0) {\n",
    "            const index = node_indices[0]; // Show info for the first selected node\n",
    "            html += \"<b>Type:</b> Node<br>\";\n",
    "            html += \"<b>ID:</b> \" + node_source.data['index'][index] + \"<br>\";\n",
    "            for (const key in node_source.data) {\n",
    "                // Display vizLabel separately if needed, or rely on attr_ fields\n",
    "                // if (key === 'vizLabel') {\n",
    "                //     html += \"<b>Label:</b> \" + node_source.data[key][index] + \"<br>\";\n",
    "                // }\n",
    "                if (key.startsWith('attr_')) {\n",
    "                    const attr_name = key.substring(5); // Remove 'attr_' prefix\n",
    "                    html += \"<b>\" + attr_name + \":</b> \" + node_source.data[key][index] + \"<br>\";\n",
    "                }\n",
    "            }\n",
    "\n",
    "        } else if (edge_indices.length > 0) {\n",
    "            const index = edge_indices[0]; // Show info for the first selected edge\n",
    "            html += \"<b>Type:</b> Edge<br>\";\n",
    "            html += \"<b>From:</b> \" + edge_source.data['start'][index] + \"<br>\";\n",
    "            html += \"<b>To:</b> \" + edge_source.data['end'][index] + \"<br>\";\n",
    "             for (const key in edge_source.data) {\n",
    "                // if (key === 'vizLabel') {\n",
    "                //     html += \"<b>Label:</b> \" + edge_source.data[key][index] + \"<br>\";\n",
    "                // }\n",
    "                 if (key.startsWith('attr_')) {\n",
    "                    const attr_name = key.substring(5); // Remove 'attr_' prefix\n",
    "                    html += \"<b>\" + attr_name + \":</b> \" + edge_source.data[key][index] + \"<br>\";\n",
    "                }\n",
    "            }\n",
    "\n",
    "        } else {\n",
    "            html = \"Click on a node or edge to see its details.\";\n",
    "        }\n",
    "\n",
    "        info_div.text = html;\n",
    "    \"\"\"\n",
    "\n",
    "    # Attach the callback to changes in selected indices of BOTH sources\n",
    "    tap_callback = CustomJS(args=dict(node_source=graph_renderer.node_renderer.data_source,\n",
    "                                      edge_source=graph_renderer.edge_renderer.data_source,\n",
    "                                      info_div=info_div),\n",
    "                            code=callback_code)\n",
    "\n",
    "    # Add TapTool to the plot\n",
    "    tap_tool = TapTool(renderers=[graph_renderer.node_renderer, graph_renderer.edge_renderer],\n",
    "                       callback=tap_callback) # Using callback directly on TapTool\n",
    "    plot.add_tools(tap_tool)\n",
    "\n",
    "    # Configure interaction policies (optional but recommended)\n",
    "    graph_renderer.selection_policy = NodesAndLinkedEdges() # Select node and its edges\n",
    "    graph_renderer.inspection_policy = EdgesAndLinkedNodes() # Hover edge and its nodes\n",
    "\n",
    "    # --- 10. Layout and Show ---\n",
    "    layout = column(info_div, plot) # Arrange Div above the plot\n",
    "    show(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "008d0a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_key_ref = {'Paper': 'title', 'Author': 'name', 'Affiliation': 'name', 'Journal': 'name', 'Venue': 'name'}\n",
    "add_node_label(g, node_key_ref)\n",
    "\n",
    "add_edges_label(g)\n",
    "\n",
    "assign_node_size(g)\n",
    "\n",
    "edge_type_weight_ref = {'CITES':0.5, 'DISCUSS':0.4, 'WRITES':0.3, 'WORKS_IN':0.2, 'PRINTS_ON':0.1, 'RELEASES_IN':0.1}\n",
    "assign_edge_weight(g, edge_type_weight_ref)\n",
    "\n",
    "assign_node_color(g)\n",
    "\n",
    "assign_edge_color(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c8ab8de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layout calculated using spring_layout.\n"
     ]
    }
   ],
   "source": [
    "visualize_graph_bokeh(g, title=\"Interactive Network Graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df28f699",
   "metadata": {},
   "source": [
    "### Basic Search\n",
    "- basic search for the following information based on user input:\n",
    "    - search_citation: enable search along citation chain\n",
    "        - 'reference': papers cited by seeds\n",
    "        - 'citing': papers cites seeds\n",
    "        - 'both': all of the above\n",
    "    - search_author: search on seed papers authors\n",
    "        - would get authors information and other publications from the authors\n",
    "    - find_recommend: get recommended papers based on seed papers\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3586ee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MORE INFORMATION on SEED ---\n",
    "print(\"--- Getting More Information Related to Seed Papers ---\")\n",
    "# basic search for seed papers\n",
    "# may include seed paper authors, seed paper citation chain, recommendations based on seed papers \n",
    "await ps.collect(\n",
    "    seed_paper_dois=seed_paper_dois,\n",
    "    seed_author_ids=seed_author_ids,\n",
    "    search_citation = search_citation,\n",
    "    search_author = search_author,\n",
    "    find_recommend = find_recommend,\n",
    "    recommend_limit = ps.recommend_limit,\n",
    "    citation_limit = ps.citation_limit,\n",
    "    from_dt = ps.from_dt,\n",
    "    to_dt = ps.to_dt,\n",
    "    fields_of_study = ps.fields_of_study,\n",
    "    )\n",
    "if search_citation in ['reference', 'both']:\n",
    "    ps.explored_nodes['reference'].extend(seed_paper_dois) \n",
    "if search_citation in ['citing', 'both']:\n",
    "    ps.explored_nodes['citing'].extend(seed_paper_dois) \n",
    "if search_author:\n",
    "    ps.explored_nodes['author'].extend(seed_author_ids) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e019df",
   "metadata": {},
   "outputs": [],
   "source": [
    "await ps.construct_paper_graph(\n",
    "    search_citation = 'both',  # 'both',\n",
    "    search_author = True,\n",
    "    find_recommend = True,\n",
    "    if_related_topic = True,\n",
    "    if_expanded_citations  = 'reference',  #  'reference',\n",
    "    if_expanded_authors = True,\n",
    "    if_add_similarity = True,\n",
    "    similarity_threshold = 0.7,\n",
    "    expanded_k_papers = 20,\n",
    "    expanded_l_authors = 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1913e721",
   "metadata": {},
   "source": [
    "## Basic Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8528b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ps.nodes_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28ad6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ps.edges_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30642b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = ps.pg.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4824d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(g.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aa4eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(g.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b36911a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check node types\n",
    "set([g.nodes[nid].get('nodeType') for nid in g.nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88de0b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats of node types\n",
    "node_types = [g.nodes[nid].get('nodeType') for nid in g.nodes]\n",
    "\n",
    "from collections import Counter\n",
    "counts = Counter(node_types)\n",
    "\n",
    "# 按计数降序排序\n",
    "sorted_counts = counts.most_common()\n",
    "sorted_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6f7903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats of edge types\n",
    "edge_types = [d.get('relationshipType') for u, v, d in g.edges(data=True)]\n",
    "print(set(edge_types))\n",
    "\n",
    "from collections import Counter\n",
    "counts = Counter(edge_types)\n",
    "\n",
    "# 按计数降序排序\n",
    "sorted_counts = counts.most_common()\n",
    "print(sorted_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1431f5fe",
   "metadata": {},
   "source": [
    "## Key Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ba695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed papers\n",
    "seed_paper_dois = [nid for nid in g.nodes \n",
    "                        if g.nodes[nid].get('nodeType')=='Paper' and\n",
    "                           g.nodes[nid].get('from_seed') == True]\n",
    "seed_paper_nodes = [g.nodes[nid] for nid in g.nodes \n",
    "                        if g.nodes[nid].get('nodeType')=='Paper' and\n",
    "                           g.nodes[nid].get('from_seed') == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87510ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(seed_paper_dois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9822600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expanded papers with citation chain\n",
    "# paper with cites but no citing, paper not in seed dois\n",
    "paper_w_ref_dois = []\n",
    "paper_w_ref_nodes = []\n",
    "\n",
    "for nid in g.nodes:\n",
    "    node = g.nodes[nid]\n",
    "    if node.get('nodeType')=='Paper' and nid not in seed_paper_dois:\n",
    "        out_edges_info = g.out_edges(nid, data=True)\n",
    "        cnt = 0\n",
    "        for u, v, data in out_edges_info:\n",
    "            if data.get('relationshipType') == 'CITES':\n",
    "               cnt += 1\n",
    "        if cnt > 0:\n",
    "            paper_w_ref_dois.append(nid)\n",
    "            paper_w_ref_nodes.append(node)\n",
    "\n",
    "print(paper_w_ref_dois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc02382",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_paper_w_ref_dois = [x for x in paper_w_ref_dois if x not in seed_paper_dois]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6bb94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dois = []\n",
    "for doi in expanded_paper_w_ref_dois:\n",
    "    out_edges_info = g.out_edges(doi, data=True)\n",
    "    ref_cnt = sum([1 for u, v, data in out_edges_info if data.get('relationshipType') == 'CITES'])\n",
    "    print(doi, ref_cnt)\n",
    "    if ref_cnt > 2:\n",
    "        filtered_dois.append(doi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39b93a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.out_edges('10.48550/arXiv.2408.16498', data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aa46b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = '10.48550/arXiv.2408.16498'\n",
    "for v in g.successors(n):\n",
    "    data = g[n][v]\n",
    "    if data.get('relationshipType') == 'CITES':\n",
    "        print(g.nodes[v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f45f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_dois)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff27070",
   "metadata": {},
   "source": [
    "Check cross refs  \n",
    "- most refered to\n",
    "- precessor of seed dois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1ea0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_stat = []\n",
    "for n in g.nodes:\n",
    "    if g.nodes[n].get('nodeType') == 'Paper':\n",
    "        in_edges_info = g.in_edges(n, data=True)\n",
    "        cite_cnt = sum([1 for u, v, data in in_edges_info if data.get('relationshipType') == 'CITES'])\n",
    "        sim_cnt = sum([1 for u, v, data in in_edges_info if data.get('relationshipType') == 'SIMILAR_TO'])\n",
    "        paper_stat.append((n, cite_cnt, sim_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85a5f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8f8e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_cite = sorted(paper_stat, key=lambda item: item[1], reverse=True)\n",
    "print(sorted_by_cite[0:20])\n",
    "\n",
    "for item in sorted_by_cite[0:20]:\n",
    "    n = item[0]\n",
    "    cite_cnt = item[1]\n",
    "    # paper infos\n",
    "    title = g.nodes[n].get('title')\n",
    "    overall_cite_cnt = g.nodes[n].get('citationCount')\n",
    "    influential_cite_cnt = g.nodes[n].get('influentialCitationCount')\n",
    "    # author infors\n",
    "    hindex_lst = []\n",
    "    for u in g.predecessors(n):\n",
    "        if g.nodes[u].get('nodeType') == 'Author':\n",
    "            hIndex = g.nodes[u].get('hIndex')\n",
    "            if hIndex:\n",
    "                hindex_lst.append(hIndex)\n",
    "            paperCount = g.nodes[u].get('paperCount')\n",
    "            citationCount = g.nodes[u].get('citationCount')\n",
    "    h_index = np.average(hindex_lst)\n",
    "\n",
    "    paper_info = {\"doi\":n, \"title\":title, \n",
    "                  \"local_refs\":cite_cnt, \"global_refs\":overall_cite_cnt, \"inf_cite_cnt\":influential_cite_cnt,\n",
    "                  \"h_index\": h_index}\n",
    "    print(paper_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc7b7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_sim = sorted(paper_stat, key=lambda item: item[2], reverse=True)\n",
    "print(sorted_by_sim[0:20])\n",
    "\n",
    "for item in sorted_by_sim[0:20]:\n",
    "    n = item[0]\n",
    "    sim_cnt = item[2]\n",
    "    title = g.nodes[n].get('title')\n",
    "    overall_cite_cnt = g.nodes[n].get('citationCount')\n",
    "    influential_cite_cnt = g.nodes[n].get('influentialCitationCount')\n",
    "    # author infors\n",
    "    hindex_lst = []\n",
    "    for u in g.predecessors(n):\n",
    "        if g.nodes[u].get('nodeType') == 'Author':\n",
    "            hIndex = g.nodes[u].get('hIndex')\n",
    "            if hIndex:\n",
    "                hindex_lst.append(hIndex)\n",
    "            paperCount = g.nodes[u].get('paperCount')\n",
    "            citationCount = g.nodes[u].get('citationCount')\n",
    "    h_index = np.average(hindex_lst)\n",
    "\n",
    "    paper_info = {\"doi\":n, \"title\":title, \n",
    "                  \"local_sims\":sim_cnt, \"global_refs\":overall_cite_cnt, \"inf_cite_cnt\":influential_cite_cnt,\n",
    "                  \"h_index\": h_index}\n",
    "    print(paper_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6982774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check key authors in graph\n",
    "author_stat = []\n",
    "for n in g.nodes:\n",
    "    if g.nodes[n].get('nodeType') == 'Author':\n",
    "        out_edges_info = g.out_edges(n, data=True)\n",
    "        writes_cnt = sum([1 for u, v, data in out_edges_info if data.get('relationshipType') == 'WRITES'])\n",
    "        author_stat.append((n, writes_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0b2a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_writes = sorted(author_stat, key=lambda item: item[1], reverse=True)\n",
    "print(sorted_by_writes[0:20])\n",
    "\n",
    "for item in sorted_by_writes[0:20]:\n",
    "    n = item[0]\n",
    "    print(g.nodes[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e838ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.explored_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ea649a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in graph[0].graph.nodes:\n",
    "    item = graph[0].graph.nodes[id]\n",
    "    if item.get('nodeType') is None:\n",
    "        print(id, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14049e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(nodes_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e42ad93",
   "metadata": {},
   "outputs": [],
   "source": [
    "set([d['relationshipType'] for u, v, d in graph[0].graph.edges(data=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a2c951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node types and edges types to keep\n",
    "filtered_node_labels = ['Paper', 'Topic', 'Author']\n",
    "filtered_edges_labels = ['CITES', 'DISCUSS', 'WRITES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52f4213",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = graph[0].graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339de557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of node IDs to iterate over\n",
    "node_ids_to_check = list(G.nodes) # <--- Create a static list here\n",
    "\n",
    "# filter node types\n",
    "for id in node_ids_to_check: # <-- Iterate over the list\n",
    "    # Check if the node still exists (important if edges might remove nodes indirectly, though less likely here)\n",
    "    if id in G:\n",
    "        item = G.nodes[id]\n",
    "        node_type = item.get('nodeType')\n",
    "        if node_type not in filtered_node_labels:\n",
    "            G.remove_node(id) # Modify the original graph G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf9baea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of edge tuples (u, v, data) to iterate over\n",
    "edge_list_copy = list(G.edges(data=True)) # <--- Create a static list here\n",
    "\n",
    "# filter edge types\n",
    "for u, v, d in edge_list_copy: # <-- Iterate over the copy\n",
    "    edge_type = d.get('relationshipType') # Use .get() for safety if attr might be missing\n",
    "    if edge_type not in filtered_edges_labels:\n",
    "         # Check if edge still exists (might have been removed if graph allows parallel edges and one was removed)\n",
    "         if G.has_edge(u, v):\n",
    "            G.remove_edge(u, v) # Modify the original graph G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c8ef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "G.remove_edge(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e861433",
   "metadata": {},
   "outputs": [],
   "source": [
    "set([graph[0].graph.nodes[x]['nodeType'] for x in graph[0].graph.nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dac349",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = False\n",
    "if a:\n",
    "    print(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25d68d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1501a5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_nodes_from([(4, {\"color\": \"red\"}), (5, {\"color\": \"green\"})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d767059",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e50252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_nodes_from([(4, {\"color\": \"blue\"})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1e8da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c418ac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_nodes_from([(4, {\"name\": \"No.4\"})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c017868",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1110a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jiezi4ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
