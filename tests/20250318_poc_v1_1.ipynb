{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Tree PoC 20250318"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_topic = \"llm literature review\"\n",
    "seed_dois = ['10.48550/arXiv.2406.10252',  # AutoSurvey: Large Language Models Can Automatically Write Surveys\n",
    "             '10.48550/arXiv.2412.10415',  # Generative Adversarial Reviews: When LLMs Become the Critic\n",
    "             '10.48550/arXiv.2402.12928',  # A Literature Review of Literature Reviews in Pattern Analysis and Machine Intelligence \n",
    "             ]\n",
    "seed_titles = ['PaperRobot: Incremental Draft Generation of Scientific Ideas',\n",
    "               'From Hypothesis to Publication: A Comprehensive Survey of AI-Driven Research Support Systems'\n",
    "               ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jiezi/Code/GitHub/ResearchTree\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "print(parent_dir)\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import toml\n",
    "\n",
    "config_file = \"config.toml\"\n",
    "try:\n",
    "    with open(config_file, 'r', encoding='utf-8') as toml_file:\n",
    "        config_param = toml.load(toml_file)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Config file '{config_file}' not found. Please ensure it exists.\")\n",
    "    config_param = {} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_api_key = config_param.get('models', {}).get('llm', {}).get('api_key')\n",
    "llm_model_name = config_param.get('models', {}).get('llm', {}).get('model_name')\n",
    "embed_api_key = config_param.get('models', {}).get('embed', {}).get('api_key')\n",
    "embed_model_name = config_param.get('models', {}).get('embed', {}).get('model_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph.paper_trace import PaperExploration\n",
    "# paperbot = PaperExploration(\n",
    "#     seed_paper_dois=seed_dois[0],\n",
    "#     llm_api_key = llm_api_key,\n",
    "#     llm_model_name = llm_model_name,\n",
    "#     embed_api_key = embed_api_key,\n",
    "#     embed_model_name = embed_model_name\n",
    "#     )\n",
    "paperbot = PaperExploration(\n",
    "    research_topic=research_topic, \n",
    "    seed_paper_dois=seed_dois, \n",
    "    seed_paper_titles=seed_titles,\n",
    "    llm_api_key = llm_api_key,\n",
    "    llm_model_name = llm_model_name,\n",
    "    embed_api_key = embed_api_key,\n",
    "    embed_model_name = embed_model_name    \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get initial papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 11:31:59,741 - INFO - HTTP Request: POST https://api.semanticscholar.org/graph/v1/paper/batch?fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear \"HTTP/1.1 429 \"\n",
      "2025-03-24 11:32:31,146 - INFO - HTTP Request: POST https://api.semanticscholar.org/graph/v1/paper/batch?fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear \"HTTP/1.1 429 \"\n",
      "2025-03-24 11:33:02,709 - INFO - HTTP Request: POST https://api.semanticscholar.org/graph/v1/paper/batch?fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear \"HTTP/1.1 429 \"\n",
      "2025-03-24 11:33:34,319 - INFO - HTTP Request: POST https://api.semanticscholar.org/graph/v1/paper/batch?fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear \"HTTP/1.1 200 OK\"\n",
      "2025-03-24 11:33:53,112 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=PaperRobot%3A+Incremental+Draft+Generation+of+Scientific+Ideas&fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=50 \"HTTP/1.1 200 OK\"\n",
      "2025-03-24 11:33:59,446 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=From+Hypothesis+to+Publication%3A+A+Comprehensive+Survey+of+AI-Driven+Research+Support+Systems&fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=50 \"HTTP/1.1 429 \"\n",
      "2025-03-24 11:34:31,101 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=From+Hypothesis+to+Publication%3A+A+Comprehensive+Survey+of+AI-Driven+Research+Support+Systems&fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=50 \"HTTP/1.1 429 \"\n",
      "2025-03-24 11:35:02,769 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=From+Hypothesis+to+Publication%3A+A+Comprehensive+Survey+of+AI-Driven+Research+Support+Systems&fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=50 \"HTTP/1.1 200 OK\"\n",
      "2025-03-24 11:35:09,204 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=llm+literature+review&fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=50 \"HTTP/1.1 429 \"\n",
      "2025-03-24 11:35:40,826 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=llm+literature+review&fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=50 \"HTTP/1.1 429 \"\n",
      "2025-03-24 11:36:12,291 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=llm+literature+review&fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=50 \"HTTP/1.1 429 \"\n",
      "2025-03-24 11:36:43,563 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=llm+literature+review&fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=50 \"HTTP/1.1 429 \"\n",
      "2025-03-24 11:37:17,120 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=llm+literature+review&fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=50 \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "paperbot.initial_paper_query(limit=50, from_dt='2023-01-01', to_dt='2025-03-24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_paper = [x for x in paperbot.nodes_json if x['labels'] == [\"Paper\"] and 'Seed' in x['properties']['source']]\n",
    "init_paper_dois = [x['id'] for x in init_paper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10.48550/arXiv.2406.10252',\n",
       " '10.48550/arXiv.2412.10415',\n",
       " '10.48550/arXiv.2402.12928',\n",
       " '10.48550/arXiv.2503.01424']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_paper_dois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370 311\n"
     ]
    }
   ],
   "source": [
    "print(len(paperbot.nodes_json), len(paperbot.edges_json))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Citation Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 11:37:24,931 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/10.48550/arXiv.2406.10252/references?fields=contexts%2Cintents%2CcontextsWithIntent%2CisInfluential%2Cabstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=100 \"HTTP/1.1 200 OK\"\n",
      "2025-03-24 11:37:37,196 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/10.48550/arXiv.2406.10252/citations?fields=contexts%2Cintents%2CcontextsWithIntent%2CisInfluential%2Cabstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=100 \"HTTP/1.1 200 OK\"\n",
      "2025-03-24 11:37:49,386 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/10.48550/arXiv.2412.10415/references?fields=contexts%2Cintents%2CcontextsWithIntent%2CisInfluential%2Cabstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=100 \"HTTP/1.1 200 OK\"\n",
      "2025-03-24 11:38:01,681 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/10.48550/arXiv.2412.10415/citations?fields=contexts%2Cintents%2CcontextsWithIntent%2CisInfluential%2Cabstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=100 \"HTTP/1.1 200 OK\"\n",
      "2025-03-24 11:38:13,710 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/10.48550/arXiv.2402.12928/references?fields=contexts%2Cintents%2CcontextsWithIntent%2CisInfluential%2Cabstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=100 \"HTTP/1.1 200 OK\"\n",
      "2025-03-24 11:38:26,146 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/10.48550/arXiv.2402.12928/citations?fields=contexts%2Cintents%2CcontextsWithIntent%2CisInfluential%2Cabstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=100 \"HTTP/1.1 200 OK\"\n",
      "2025-03-24 11:38:37,616 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/10.48550/arXiv.2503.01424/references?fields=contexts%2Cintents%2CcontextsWithIntent%2CisInfluential%2Cabstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=100 \"HTTP/1.1 404 Not Found\"\n",
      "2025-03-24 11:38:37,618 - ERROR - Error when getting papers cited by 10.48550/arXiv.2503.01424: Paper with id 10.48550/arXiv.2503.01424 not found\n",
      "2025-03-24 11:38:48,944 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/10.48550/arXiv.2503.01424/citations?fields=contexts%2Cintents%2CcontextsWithIntent%2CisInfluential%2Cabstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=100 \"HTTP/1.1 404 Not Found\"\n",
      "2025-03-24 11:38:48,946 - ERROR - Error when getting papers citing 10.48550/arXiv.2503.01424: Paper with id 10.48550/arXiv.2503.01424 not found\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for paper_doi in init_paper_dois:\n",
    "    paperbot.get_cited_papers(paper_doi) \n",
    "    time.sleep(5)\n",
    "    paperbot.get_citing_papers(paper_doi) \n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1971 2070\n"
     ]
    }
   ],
   "source": [
    "print(len(paperbot.nodes_json), len(paperbot.edges_json))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Recommended Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 11:39:03,324 - INFO - HTTP Request: POST https://api.semanticscholar.org/recommendations/v1/papers/?fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&limit=100 \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "paperbot.get_recommend_papers(paper_dois=init_paper_dois, from_dt='2022-01-01', to_dt='2025-03-13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2513 2563\n"
     ]
    }
   ],
   "source": [
    "print(len(paperbot.nodes_json), len(paperbot.edges_json))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Papers from Related Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains, init_paper_info = [], []\n",
    "for item in init_paper:\n",
    "    title = item.get('properties',{}).get('title')\n",
    "    abstract = item.get('properties',{}).get('abstract')\n",
    "    domain = item.get('properties',{}).get('fieldsOfStudy')\n",
    "    info = f\"<paper> TITLE: {title}\\nABSTRACT: {abstract} </paper>\"\n",
    "    init_paper_info.append(info)\n",
    "    domains.extend(domain)\n",
    "\n",
    "from collections import Counter\n",
    "domain = Counter(domains).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 11:39:09,277 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-03-24 11:39:11,634 - INFO - AFC remote call 1 is done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'field_of_study': ['Artificial Intelligence', 'Natural Language Processing', 'Information Science', 'Meta-Research'], 'keywords_and_topics': ['large language models', 'literature reviews', 'peer review', 'AI-driven research support systems', 'generative AI'], 'tags': ['AutoSurvey', 'Generative Agent Reviewers (GAR)', 'PRISMA standards', 'bibliometric indicators', 'hypothesis formulation', 'manuscript publication'], 'queries': ['LLM automated literature review', 'AI peer review simulation', 'AI research support systems', 'evaluation of AI-generated reviews']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 11:39:12,800 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=LLM+automated+literature+review&fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=100 \"HTTP/1.1 429 \"\n",
      "2025-03-24 11:39:48,284 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=LLM+automated+literature+review&fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=100 \"HTTP/1.1 200 OK\"\n",
      "2025-03-24 11:39:56,851 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=AI+peer+review+simulation&fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=100 \"HTTP/1.1 200 OK\"\n",
      "2025-03-24 11:40:04,338 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=AI+research+support+systems&fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=100 \"HTTP/1.1 429 \"\n",
      "2025-03-24 11:40:37,342 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=AI+research+support+systems&fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=100 \"HTTP/1.1 200 OK\"\n",
      "2025-03-24 11:40:44,763 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=evaluation+of+AI-generated+reviews&fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=100 \"HTTP/1.1 429 \"\n",
      "2025-03-24 11:41:16,201 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=evaluation+of+AI-generated+reviews&fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=100 \"HTTP/1.1 429 \"\n",
      "2025-03-24 11:41:49,034 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=evaluation+of+AI-generated+reviews&fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=100 \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "paperbot.get_related_papers(domain, input_text=\"\\n\".join(init_paper_info), from_dt='2022-01-01', to_dt='2025-03-13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_nodes_json = [x for x in paperbot.nodes_json if x['labels'] == [\"Paper\"] ]\n",
    "await paperbot.add_semantic_relationship(paper_nodes_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4257 100721\n"
     ]
    }
   ],
   "source": [
    "print(len(paperbot.nodes_json), len(paperbot.edges_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "filename = \"paper_nodes_json.jsonl\"\n",
    "\n",
    "with open(filename, 'w') as f:\n",
    "    for item in paperbot.nodes_json:\n",
    "        json.dump(item, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "filename = \"paper_edges_json.jsonl\"\n",
    "\n",
    "with open(filename, 'w') as f:\n",
    "    for item in paperbot.edges_json:\n",
    "        json.dump(item, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['type', 'id', 'labels', 'properties', 'source', 'sourceDesc'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperbot.nodes_json[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CitedPaper', 'CitedPaper']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperbot.nodes_json[0]['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['s2PaperId', 'externalIds', 'corpusId', 'publicationVenue', 's2Url', 'title', 'abstract', 'venue', 'year', 'referenceCount', 'citationCount', 'influentialCitationCount', 'isOpenAccess', 'openAccessPdf', 'fieldsOfStudy', 's2FieldsOfStudy', 'publicationTypes', 'publicationDate', 'journal', 'citationStyles', 'authors', 'version', 'arxivUrl', 'arxivId', 'DOI', 'id', 'source', 'sourceDesc'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperbot.nodes_json[0]['properties'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Seed']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperbot.nodes_json[0]['properties']['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy \n",
    "\n",
    "def remove_key_values(input_dict, keys_to_delete):\n",
    "    \"\"\"delete key-value in dict\"\"\"\n",
    "    opt_dct = copy.deepcopy(input_dict)\n",
    "    for key in keys_to_delete:\n",
    "        if key in opt_dct:  # 检查键是否存在，避免 KeyError\n",
    "            del opt_dct[key]\n",
    "    return opt_dct # 为了方便链式调用，返回修改后的字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in paperbot.nodes_json:\n",
    "    source = item.get('source')\n",
    "    source_desc = item.get('sourceDesc')\n",
    "    if (isinstance(source, list) and len(source) > 0) or (isinstance(source_desc, list) and len(source_desc) > 0):\n",
    "        if isinstance(item['properties']['source'], list):\n",
    "            item['properties']['source'].extend(source)\n",
    "        else:\n",
    "            item['properties']['source'] = source\n",
    "        if isinstance(item['properties']['sourceDesc'], list):\n",
    "            item['properties']['sourceDesc'].extend(source_desc)\n",
    "        else:\n",
    "            item['properties']['sourceDesc'] = source_desc\n",
    "    item = remove_key_values(item, ['source', 'sourceDesc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Author', 'Journal', 'Paper', 'Venue'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([x['labels'][0] for x in paperbot.nodes_json])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4257, 4085)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x['id'] for x in paperbot.nodes_json]), len(set([x['id'] for x in paperbot.nodes_json]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in paperbot.nodes_json:\n",
    "    if item['labels'] == ['Venue']:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in paperbot.nodes_json:\n",
    "    item['ref_cnt'] = len(set(item['properties']['source']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_data_lambda = sorted(paperbot.nodes_json, key=lambda item: item['ref_cnt'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'node', 'id': '10.48550/arXiv.2402.12928', 'labels': ['Paper'], 'properties': {'s2PaperId': '69b53faee7ce5c007e4d3e3ea532818ed8d0645d', 'externalIds': {'DBLP': 'journals/corr/abs-2402-12928', 'ArXiv': '2402.12928', 'DOI': '10.48550/arXiv.2402.12928', 'CorpusId': 267760070}, 'corpusId': 267760070, 'publicationVenue': {'id': '1901e811-ee72-4b20-8f7e-de08cd395a10', 'name': 'arXiv.org', 'alternate_names': ['ArXiv'], 'issn': '2331-8422', 'url': 'https://arxiv.org', 'source': ['Seed'], 'sourceDesc': ['Original seed papers']}, 's2Url': 'https://www.semanticscholar.org/paper/69b53faee7ce5c007e4d3e3ea532818ed8d0645d', 'title': 'A Literature Review of Literature Reviews in Pattern Analysis and Machine Intelligence', 'abstract': 'The rapid advancements in Pattern Analysis and Machine Intelligence (PAMI) have led to an overwhelming expansion of scientific knowledge, spawning numerous literature reviews aimed at collecting and synthesizing fragmented information. This paper presents a thorough analysis of these literature reviews within the PAMI field, and tries to address three core research questions: (1) What are the prevalent structural and statistical characteristics of PAMI literature reviews? (2) What strategies can researchers employ to efficiently navigate the growing corpus of reviews? (3) What are the advantages and limitations of AI-generated reviews compared to human-authored ones? To address the first research question, we begin with a narrative overview to highlight common preferences in composing PAMI reviews, followed by a statistical analysis to quantitatively uncover patterns in these preferences. Our findings reveal several key insights. First, fewer than 20% of PAMI reviews currently comply with PRISMA standards, although this proportion is gradually increasing. Second, there is a moderate positive correlation between the quality of references and the scholarly impact of reviews, emphasizing the importance of reference selection. To further assist researchers in efficiently managing the rapidly growing number of literature reviews, we introduce four novel, real-time, article-level bibliometric indicators that facilitate the screening of numerous reviews. Finally, our comparative analysis reveals that AI-generated reviews currently fall short of human-authored ones in accurately evaluating the academic significance of newly published articles and integrating rich visual elements, which limits their practical utility. Overall, this study provides a deeper understanding of PAMI literature reviews by uncovering key trends, evaluating current practices, and highlighting areas for future improvement.', 'venue': 'arXiv.org', 'year': 2024, 'referenceCount': 163, 'citationCount': 0, 'influentialCitationCount': 0, 'isOpenAccess': True, 'openAccessPdf': 'https://arxiv.org/pdf/2402.12928', 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle', 'Review'], 'publicationDate': '2024-02-20', 'journal': {'name': 'ArXiv', 'volume': 'abs/2402.12928'}, 'citationStyles': {'bibtex': '@Article{Zhao2024ALR,\\n author = {Penghai Zhao and Xin Zhang and Ming-Ming Cheng and Jian Yang and Xiang Li},\\n booktitle = {arXiv.org},\\n journal = {ArXiv},\\n title = {A Literature Review of Literature Reviews in Pattern Analysis and Machine Intelligence},\\n volume = {abs/2402.12928},\\n year = {2024}\\n}\\n'}, 'authors': [{'authorId': '2284827556', 'name': 'Penghai Zhao', 'source': ['Seed', 'CitingPaper', 'LLMQuery'], 'sourceDesc': ['Original seed papers', 'citing 10.48550/arXiv.2406.10252', 'evaluation of AI-generated reviews']}, {'authorId': '2268132119', 'name': 'Xin Zhang', 'source': ['Seed', 'CitingPaper', 'LLMQuery'], 'sourceDesc': ['Original seed papers', 'citing 10.48550/arXiv.2406.10252', 'evaluation of AI-generated reviews']}, {'authorId': '2275569993', 'name': 'Ming-Ming Cheng', 'source': ['Seed', 'CitingPaper', 'LLMQuery'], 'sourceDesc': ['Original seed papers', 'citing 10.48550/arXiv.2406.10252', 'evaluation of AI-generated reviews']}, {'authorId': '2284825678', 'name': 'Jian Yang', 'source': ['Seed', 'CitingPaper', 'LLMQuery'], 'sourceDesc': ['Original seed papers', 'citing 10.48550/arXiv.2406.10252', 'evaluation of AI-generated reviews']}, {'authorId': '2284824283', 'name': 'Xiang Li', 'source': ['Seed', 'CitingPaper', 'LLMQuery'], 'sourceDesc': ['Original seed papers', 'citing 10.48550/arXiv.2406.10252', 'evaluation of AI-generated reviews']}], 'version': '', 'arxivUrl': 'https://arxiv.org/abs/2402.12928', 'arxivId': '2402.12928', 'DOI': '10.48550/arXiv.2402.12928', 'id': '10.48550/arXiv.2402.12928', 'source': ['Seed', 'CitingPaper', 'LLMQuery'], 'sourceDesc': ['Original seed papers', 'citing 10.48550/arXiv.2406.10252', 'evaluation of AI-generated reviews']}, 'source': ['CitingPaper', 'LLMQuery'], 'sourceDesc': ['citing 10.48550/arXiv.2406.10252', 'evaluation of AI-generated reviews'], 'ref_cnt': 3}\n",
      "A Literature Review of Literature Reviews in Pattern Analysis and Machine Intelligence 3\n",
      "{'type': 'node', 'id': '10.48550/arXiv.2503.01424', 'labels': ['Paper'], 'properties': {'s2PaperId': 'cdb34c0092a767848ca1de6fa7e3a6b822585fa4', 'externalIds': {'ArXiv': '2503.01424', 'CorpusId': 276775839}, 'corpusId': 276775839, 'publicationVenue': None, 's2Url': 'https://www.semanticscholar.org/paper/cdb34c0092a767848ca1de6fa7e3a6b822585fa4', 'title': 'From Hypothesis to Publication: A Comprehensive Survey of AI-Driven Research Support Systems', 'abstract': 'Research is a fundamental process driving the advancement of human civilization, yet it demands substantial time and effort from researchers. In recent years, the rapid development of artificial intelligence (AI) technologies has inspired researchers to explore how AI can accelerate and enhance research. To monitor relevant advancements, this paper presents a systematic review of the progress in this domain. Specifically, we organize the relevant studies into three main categories: hypothesis formulation, hypothesis validation, and manuscript publication. Hypothesis formulation involves knowledge synthesis and hypothesis generation. Hypothesis validation includes the verification of scientific claims, theorem proving, and experiment validation. Manuscript publication encompasses manuscript writing and the peer review process. Furthermore, we identify and discuss the current challenges faced in these areas, as well as potential future directions for research. Finally, we also offer a comprehensive overview of existing benchmarks and tools across various domains that support the integration of AI into the research process. We hope this paper serves as an introduction for beginners and fosters future research. Resources have been made publicly available at https://github.com/zkzhou126/AI-for-Research.', 'venue': '', 'year': 2025, 'referenceCount': 252, 'citationCount': 0, 'influentialCitationCount': 0, 'isOpenAccess': True, 'openAccessPdf': 'https://arxiv.org/pdf/2503.01424', 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}], 'publicationTypes': ['Review'], 'publicationDate': '2025-03-03', 'journal': None, 'citationStyles': {'bibtex': '@Inproceedings{Zhou2025FromHT,\\n author = {Zekun Zhou and Xiaocheng Feng and Lei Huang and Xiachong Feng and Ziyun Song and Ruihan Chen and Liang Zhao and Weitao Ma and Yuxuan Gu and Baoxin Wang and Dayong Wu and Guoping Hu and Ting Liu and Bing Qin},\\n title = {From Hypothesis to Publication: A Comprehensive Survey of AI-Driven Research Support Systems},\\n year = {2025}\\n}\\n'}, 'authors': [{'authorId': '2328342585', 'name': 'Zekun Zhou', 'source': ['Seed', 'CitingPaper', 'RecommendedPaper'], 'sourceDesc': ['Original seed papers', 'citing 10.48550/arXiv.2406.10252', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424']}, {'authorId': '2674998', 'name': 'Xiaocheng Feng', 'source': ['Seed', 'CitingPaper', 'RecommendedPaper'], 'sourceDesc': ['Original seed papers', 'citing 10.48550/arXiv.2406.10252', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424']}, {'authorId': '2265930173', 'name': 'Lei Huang', 'source': ['Seed', 'CitingPaper', 'RecommendedPaper'], 'sourceDesc': ['Original seed papers', 'citing 10.48550/arXiv.2406.10252', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424']}, {'authorId': '51056442', 'name': 'Xiachong Feng', 'source': ['Seed', 'CitingPaper', 'RecommendedPaper'], 'sourceDesc': ['Original seed papers', 'citing 10.48550/arXiv.2406.10252', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424']}, {'authorId': '2349068478', 'name': 'Ziyun Song', 'source': ['Seed', 'CitingPaper', 'RecommendedPaper'], 'sourceDesc': ['Original seed papers', 'citing 10.48550/arXiv.2406.10252', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424']}, {'authorId': '2337225259', 'name': 'Ruihan Chen', 'source': ['Seed', 'CitingPaper', 'RecommendedPaper'], 'sourceDesc': ['Original seed papers', 'citing 10.48550/arXiv.2406.10252', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424']}, {'authorId': '2216503559', 'name': 'Liang Zhao', 'source': ['Seed', 'CitingPaper', 'RecommendedPaper'], 'sourceDesc': ['Original seed papers', 'citing 10.48550/arXiv.2406.10252', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424']}, {'authorId': '2265878959', 'name': 'Weitao Ma', 'source': ['Seed', 'CitingPaper', 'RecommendedPaper'], 'sourceDesc': ['Original seed papers', 'citing 10.48550/arXiv.2406.10252', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424']}, {'authorId': '2112678409', 'name': 'Yuxuan Gu', 'source': ['Seed', 'CitingPaper', 'RecommendedPaper'], 'sourceDesc': ['Original seed papers', 'citing 10.48550/arXiv.2406.10252', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424']}, {'authorId': '2118640235', 'name': 'Baoxin Wang', 'source': ['Seed', 'CitingPaper', 'RecommendedPaper'], 'sourceDesc': ['Original seed papers', 'citing 10.48550/arXiv.2406.10252', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424']}, {'authorId': '2118208508', 'name': 'Dayong Wu'}, {'authorId': '2316008068', 'name': 'Guoping Hu'}, {'authorId': '2274093523', 'name': 'Ting Liu'}, {'authorId': '2257004102', 'name': 'Bing Qin'}], 'version': '', 'arxivUrl': 'https://arxiv.org/abs/2503.01424', 'arxivId': '2503.01424', 'DOI': '10.48550/arXiv.2503.01424', 'id': '10.48550/arXiv.2503.01424', 'source': ['Seed', 'CitingPaper', 'RecommendedPaper'], 'sourceDesc': ['Original seed papers', 'citing 10.48550/arXiv.2406.10252', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424']}, 'source': ['CitingPaper', 'RecommendedPaper'], 'sourceDesc': ['citing 10.48550/arXiv.2406.10252', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424'], 'ref_cnt': 3}\n",
      "From Hypothesis to Publication: A Comprehensive Survey of AI-Driven Research Support Systems 3\n",
      "{'type': 'node', 'id': '10.48550/arXiv.2503.08569', 'labels': ['Paper'], 'properties': {'s2PaperId': '60c8a127e6ae8c8e21dd7edfc187ff7f0d9ae2bd', 'externalIds': {'ArXiv': '2503.08569', 'CorpusId': 276929065}, 'corpusId': 276929065, 'publicationVenue': None, 's2Url': 'https://www.semanticscholar.org/paper/60c8a127e6ae8c8e21dd7edfc187ff7f0d9ae2bd', 'title': 'DeepReview: Improving LLM-based Paper Review with Human-like Deep Thinking Process', 'abstract': 'Large Language Models (LLMs) are increasingly utilized in scientific research assessment, particularly in automated paper review. However, existing LLM-based review systems face significant challenges, including limited domain expertise, hallucinated reasoning, and a lack of structured evaluation. To address these limitations, we introduce DeepReview, a multi-stage framework designed to emulate expert reviewers by incorporating structured analysis, literature retrieval, and evidence-based argumentation. Using DeepReview-13K, a curated dataset with structured annotations, we train DeepReviewer-14B, which outperforms CycleReviewer-70B with fewer tokens. In its best mode, DeepReviewer-14B achieves win rates of 88.21\\\\% and 80.20\\\\% against GPT-o1 and DeepSeek-R1 in evaluations. Our work sets a new benchmark for LLM-based paper review, with all resources publicly available. The code, model, dataset and demo have be released in http://ai-researcher.net.', 'venue': '', 'year': 2025, 'referenceCount': 65, 'citationCount': 0, 'influentialCitationCount': 0, 'isOpenAccess': True, 'openAccessPdf': 'https://arxiv.org/pdf/2503.08569', 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}], 'publicationTypes': ['Review'], 'publicationDate': '2025-03-11', 'journal': None, 'citationStyles': {'bibtex': '@Inproceedings{Zhu2025DeepReviewIL,\\n author = {Minjun Zhu and Yixuan Weng and Linyi Yang and Yue Zhang},\\n title = {DeepReview: Improving LLM-based Paper Review with Human-like Deep Thinking Process},\\n year = {2025}\\n}\\n'}, 'authors': [{'authorId': '2316827669', 'name': 'Minjun Zhu', 'source': ['InitialSearch', 'CitingPaper', 'RecommendedPaper', 'LLMQuery', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'citing 10.48550/arXiv.2406.10252', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424', 'LLM automated literature review', 'LLM automated literature review']}, {'authorId': '2349585725', 'name': 'Yixuan Weng', 'source': ['InitialSearch', 'RecommendedPaper', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424', 'LLM automated literature review']}, {'authorId': '2145500840', 'name': 'Linyi Yang', 'source': ['InitialSearch', 'CitedPaper', 'CitedPaper', 'CitingPaper', 'RecommendedPaper', 'RecommendedPaper', 'LLMQuery', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'citing 10.48550/arXiv.2406.10252', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424', 'LLM automated literature review', 'LLM automated literature review']}, {'authorId': '2325943212', 'name': 'Yue Zhang', 'source': ['InitialSearch', 'CitingPaper', 'CitingPaper', 'RecommendedPaper', 'LLMQuery', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'citing 10.48550/arXiv.2406.10252', 'citing 10.48550/arXiv.2406.10252', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424', 'LLM automated literature review', 'LLM automated literature review']}], 'version': '', 'arxivUrl': 'https://arxiv.org/abs/2503.08569', 'arxivId': '2503.08569', 'DOI': '10.48550/arXiv.2503.08569', 'id': '10.48550/arXiv.2503.08569', 'source': ['InitialSearch', 'RecommendedPaper', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424', 'LLM automated literature review']}, 'source': ['RecommendedPaper', 'LLMQuery'], 'sourceDesc': ['recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424', 'LLM automated literature review'], 'ref_cnt': 3}\n",
      "DeepReview: Improving LLM-based Paper Review with Human-like Deep Thinking Process 3\n",
      "{'type': 'node', 'id': '10.48550/arXiv.2406.10252', 'labels': ['Paper'], 'properties': {'s2PaperId': '9e57dda195973c4b6c81386b1cc44595ecfd4697', 'externalIds': {'DBLP': 'conf/nips/WangGYZZ0ZD0W0Z24', 'ArXiv': '2406.10252', 'DOI': '10.48550/arXiv.2406.10252', 'CorpusId': 270560509}, 'corpusId': 270560509, 'publicationVenue': {'id': 'd9720b90-d60b-48bc-9df8-87a30b9a60dd', 'name': 'Neural Information Processing Systems', 'type': 'conference', 'alternate_names': ['Neural Inf Process Syst', 'NeurIPS', 'NIPS'], 'url': 'http://neurips.cc/', 'source': ['Seed', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'LLMQuery'], 'sourceDesc': ['Original seed papers', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2402.12928', 'cited by 10.48550/arXiv.2402.12928', 'AI research support systems']}, 's2Url': 'https://www.semanticscholar.org/paper/9e57dda195973c4b6c81386b1cc44595ecfd4697', 'title': 'AutoSurvey: Large Language Models Can Automatically Write Surveys', 'abstract': \"This paper introduces AutoSurvey, a speedy and well-organized methodology for automating the creation of comprehensive literature surveys in rapidly evolving fields like artificial intelligence. Traditional survey paper creation faces challenges due to the vast volume and complexity of information, prompting the need for efficient survey methods. While large language models (LLMs) offer promise in automating this process, challenges such as context window limitations, parametric knowledge constraints, and the lack of evaluation benchmarks remain. AutoSurvey addresses these challenges through a systematic approach that involves initial retrieval and outline generation, subsection drafting by specialized LLMs, integration and refinement, and rigorous evaluation and iteration. Our contributions include a comprehensive solution to the survey problem, a reliable evaluation method, and experimental validation demonstrating AutoSurvey's effectiveness.We open our resources at \\\\url{https://github.com/AutoSurveys/AutoSurvey}.\", 'venue': 'Neural Information Processing Systems', 'year': 2024, 'referenceCount': 54, 'citationCount': 12, 'influentialCitationCount': 1, 'isOpenAccess': True, 'openAccessPdf': 'https://arxiv.org/pdf/2406.10252', 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle', 'Review'], 'publicationDate': '2024-06-10', 'journal': {'name': 'ArXiv', 'volume': 'abs/2406.10252'}, 'citationStyles': {'bibtex': '@Article{Wang2024AutoSurveyLL,\\n author = {Yidong Wang and Qi Guo and Wenjin Yao and Hongbo Zhang and Xin Zhang and Zhen Wu and Meishan Zhang and Xinyu Dai and Min Zhang and Qingsong Wen and Wei Ye and Shikun Zhang and Yue Zhang},\\n booktitle = {Neural Information Processing Systems},\\n journal = {ArXiv},\\n title = {AutoSurvey: Large Language Models Can Automatically Write Surveys},\\n volume = {abs/2406.10252},\\n year = {2024}\\n}\\n'}, 'authors': [{'authorId': '2108024279', 'name': 'Yidong Wang', 'source': ['Seed', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitingPaper', 'CitedPaper', 'CitedPaper'], 'sourceDesc': ['Original seed papers', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'citing 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2402.12928']}, {'authorId': '2273779175', 'name': 'Qi Guo', 'source': ['Seed', 'CitedPaper', 'CitedPaper'], 'sourceDesc': ['Original seed papers', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2402.12928']}, {'authorId': '2286328804', 'name': 'Wenjin Yao', 'source': ['Seed', 'CitedPaper', 'CitedPaper', 'CitedPaper'], 'sourceDesc': ['Original seed papers', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2402.12928']}, {'authorId': '2116271777', 'name': 'Hongbo Zhang', 'source': ['Seed', 'CitedPaper', 'CitedPaper'], 'sourceDesc': ['Original seed papers', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2402.12928']}, {'authorId': '2262020955', 'name': 'Xin Zhang', 'source': ['Seed', 'CitedPaper', 'CitedPaper'], 'sourceDesc': ['Original seed papers', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2402.12928']}, {'authorId': '2293356300', 'name': 'Zhen Wu', 'source': ['Seed', 'CitedPaper', 'CitedPaper'], 'sourceDesc': ['Original seed papers', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2402.12928']}, {'authorId': '2289004972', 'name': 'Meishan Zhang', 'source': ['Seed', 'CitedPaper', 'CitedPaper'], 'sourceDesc': ['Original seed papers', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2402.12928']}, {'authorId': '2257010530', 'name': 'Xinyu Dai', 'source': ['Seed', 'CitedPaper', 'CitedPaper'], 'sourceDesc': ['Original seed papers', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2402.12928']}, {'authorId': '2259709647', 'name': 'Min Zhang', 'source': ['Seed', 'CitedPaper', 'CitedPaper'], 'sourceDesc': ['Original seed papers', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2402.12928']}, {'authorId': '2307012818', 'name': 'Qingsong Wen', 'source': ['Seed', 'CitedPaper', 'CitedPaper'], 'sourceDesc': ['Original seed papers', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2402.12928']}, {'authorId': '2254442582', 'name': 'Wei Ye'}, {'authorId': '1705434', 'name': 'Shikun Zhang'}, {'authorId': '2250437942', 'name': 'Yue Zhang'}], 'version': '', 'arxivUrl': 'https://arxiv.org/abs/2406.10252', 'arxivId': '2406.10252', 'DOI': '10.48550/arXiv.2406.10252', 'id': '10.48550/arXiv.2406.10252', 'source': ['Seed', 'CitedPaper', 'CitedPaper'], 'sourceDesc': ['Original seed papers', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2402.12928']}, 'source': ['CitedPaper', 'CitedPaper'], 'sourceDesc': ['cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2402.12928'], 'ref_cnt': 2}\n",
      "AutoSurvey: Large Language Models Can Automatically Write Surveys 2\n",
      "{'type': 'node', 'id': '10.48550/arXiv.2412.10415', 'labels': ['Paper'], 'properties': {'s2PaperId': '9f3ae8055e227edb413c54417c9c216f1f554f52', 'externalIds': {'ArXiv': '2412.10415', 'DBLP': 'journals/corr/abs-2412-10415', 'DOI': '10.48550/arXiv.2412.10415', 'CorpusId': 274776902}, 'corpusId': 274776902, 'publicationVenue': {'id': '1901e811-ee72-4b20-8f7e-de08cd395a10', 'name': 'arXiv.org', 'alternate_names': ['ArXiv'], 'issn': '2331-8422', 'url': 'https://arxiv.org', 'source': ['Seed', 'InitialSearch', 'InitialSearch', 'InitialSearch', 'InitialSearch', 'InitialSearch', 'InitialSearch', 'InitialSearch', 'InitialSearch', 'InitialSearch', 'InitialSearch', 'InitialSearch', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitingPaper', 'CitingPaper', 'CitingPaper', 'CitingPaper', 'CitingPaper', 'CitingPaper', 'CitingPaper', 'CitingPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitingPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery'], 'sourceDesc': ['Original seed papers', 'Search from S2 based on user input', 'Search from S2 based on user input', 'Search from S2 based on user input', 'Search from S2 based on user input', 'Search from S2 based on user input', 'Search from S2 based on user input', 'Search from S2 based on user input', 'Search from S2 based on user input', 'Search from S2 based on user input', 'Search from S2 based on user input', 'Search from S2 based on user input', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'citing 10.48550/arXiv.2406.10252', 'citing 10.48550/arXiv.2406.10252', 'citing 10.48550/arXiv.2406.10252', 'citing 10.48550/arXiv.2406.10252', 'citing 10.48550/arXiv.2406.10252', 'citing 10.48550/arXiv.2406.10252', 'citing 10.48550/arXiv.2406.10252', 'citing 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2412.10415', 'citing 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2402.12928', 'cited by 10.48550/arXiv.2402.12928', 'cited by 10.48550/arXiv.2402.12928', 'cited by 10.48550/arXiv.2402.12928', 'cited by 10.48550/arXiv.2402.12928', 'cited by 10.48550/arXiv.2402.12928', 'cited by 10.48550/arXiv.2402.12928', 'cited by 10.48550/arXiv.2402.12928', 'cited by 10.48550/arXiv.2402.12928', 'cited by 10.48550/arXiv.2402.12928', 'cited by 10.48550/arXiv.2402.12928', 'cited by 10.48550/arXiv.2402.12928', 'cited by 10.48550/arXiv.2402.12928', 'cited by 10.48550/arXiv.2402.12928', 'cited by 10.48550/arXiv.2402.12928', 'cited by 10.48550/arXiv.2402.12928', 'LLM automated literature review', 'LLM automated literature review', 'LLM automated literature review', 'LLM automated literature review', 'LLM automated literature review', 'LLM automated literature review', 'LLM automated literature review', 'LLM automated literature review', 'LLM automated literature review', 'LLM automated literature review', 'LLM automated literature review', 'LLM automated literature review', 'LLM automated literature review', 'LLM automated literature review', 'LLM automated literature review', 'LLM automated literature review', 'LLM automated literature review', 'LLM automated literature review', 'LLM automated literature review', 'LLM automated literature review', 'LLM automated literature review', 'LLM automated literature review', 'AI peer review simulation', 'AI peer review simulation', 'AI peer review simulation', 'AI peer review simulation', 'AI peer review simulation', 'AI peer review simulation', 'AI peer review simulation', 'AI peer review simulation', 'AI peer review simulation', 'evaluation of AI-generated reviews', 'evaluation of AI-generated reviews', 'evaluation of AI-generated reviews', 'evaluation of AI-generated reviews', 'evaluation of AI-generated reviews', 'evaluation of AI-generated reviews', 'evaluation of AI-generated reviews', 'evaluation of AI-generated reviews', 'evaluation of AI-generated reviews', 'evaluation of AI-generated reviews', 'evaluation of AI-generated reviews', 'evaluation of AI-generated reviews', 'evaluation of AI-generated reviews', 'evaluation of AI-generated reviews', 'evaluation of AI-generated reviews']}, 's2Url': 'https://www.semanticscholar.org/paper/9f3ae8055e227edb413c54417c9c216f1f554f52', 'title': 'Generative Adversarial Reviews: When LLMs Become the Critic', 'abstract': \"The peer review process is fundamental to scientific progress, determining which papers meet the quality standards for publication. Yet, the rapid growth of scholarly production and increasing specialization in knowledge areas strain traditional scientific feedback mechanisms. In light of this, we introduce Generative Agent Reviewers (GAR), leveraging LLM-empowered agents to simulate faithful peer reviewers. To enable generative reviewers, we design an architecture that extends a large language model with memory capabilities and equips agents with reviewer personas derived from historical data. Central to this approach is a graph-based representation of manuscripts, condensing content and logically organizing information - linking ideas with evidence and technical details. GAR's review process leverages external knowledge to evaluate paper novelty, followed by detailed assessment using the graph representation and multi-round assessment. Finally, a meta-reviewer aggregates individual reviews to predict the acceptance decision. Our experiments demonstrate that GAR performs comparably to human reviewers in providing detailed feedback and predicting paper outcomes. Beyond mere performance comparison, we conduct insightful experiments, such as evaluating the impact of reviewer expertise and examining fairness in reviews. By offering early expert-level feedback, typically restricted to a limited group of researchers, GAR democratizes access to transparent and in-depth evaluation.\", 'venue': 'arXiv.org', 'year': 2024, 'referenceCount': 67, 'citationCount': 1, 'influentialCitationCount': 0, 'isOpenAccess': True, 'openAccessPdf': 'https://arxiv.org/pdf/2412.10415', 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle', 'Review'], 'publicationDate': '2024-12-09', 'journal': {'name': 'ArXiv', 'volume': 'abs/2412.10415'}, 'citationStyles': {'bibtex': '@Article{Bougie2024GenerativeAR,\\n author = {Nicolas Bougie and Narimasa Watanabe},\\n booktitle = {arXiv.org},\\n journal = {ArXiv},\\n title = {Generative Adversarial Reviews: When LLMs Become the Critic},\\n volume = {abs/2412.10415},\\n year = {2024}\\n}\\n'}, 'authors': [{'authorId': '2335566763', 'name': 'Nicolas Bougie', 'source': ['Seed', 'CitingPaper'], 'sourceDesc': ['Original seed papers', 'citing 10.48550/arXiv.2406.10252']}, {'authorId': '2335569348', 'name': 'Narimasa Watanabe', 'source': ['Seed', 'CitingPaper'], 'sourceDesc': ['Original seed papers', 'citing 10.48550/arXiv.2406.10252']}], 'version': '', 'arxivUrl': 'https://arxiv.org/abs/2412.10415', 'arxivId': '2412.10415', 'DOI': '10.48550/arXiv.2412.10415', 'id': '10.48550/arXiv.2412.10415', 'source': ['Seed', 'CitingPaper'], 'sourceDesc': ['Original seed papers', 'citing 10.48550/arXiv.2406.10252']}, 'source': ['CitingPaper'], 'sourceDesc': ['citing 10.48550/arXiv.2406.10252'], 'ref_cnt': 2}\n",
      "Generative Adversarial Reviews: When LLMs Become the Critic 2\n",
      "{'type': 'node', 'id': '10.48550/arXiv.2407.16148', 'labels': ['Paper'], 'properties': {'s2PaperId': '33b8824f3c8fc3035afabaa77ecee3afe1c9753c', 'externalIds': {'DBLP': 'journals/corr/abs-2407-16148', 'ArXiv': '2407.16148', 'DOI': '10.48550/arXiv.2407.16148', 'CorpusId': 271334330}, 'corpusId': 271334330, 'publicationVenue': {'id': '1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44', 'name': 'Annual Meeting of the Association for Computational Linguistics', 'type': 'conference', 'alternate_names': ['Annu Meet Assoc Comput Linguistics', 'Meeting of the Association for Computational Linguistics', 'ACL', 'Meet Assoc Comput Linguistics'], 'url': 'https://www.aclweb.org/anthology/venues/acl/', 'source': ['InitialSearch', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2412.10415', 'LLM automated literature review']}, 's2Url': 'https://www.semanticscholar.org/paper/33b8824f3c8fc3035afabaa77ecee3afe1c9753c', 'title': 'CHIME: LLM-Assisted Hierarchical Organization of Scientific Studies for Literature Review Support', 'abstract': 'Literature review requires researchers to synthesize a large amount of information and is increasingly challenging as the scientific literature expands. In this work, we investigate the potential of LLMs for producing hierarchical organizations of scientific studies to assist researchers with literature review. We define hierarchical organizations as tree structures where nodes refer to topical categories and every node is linked to the studies assigned to that category. Our naive LLM-based pipeline for hierarchy generation from a set of studies produces promising yet imperfect hierarchies, motivating us to collect CHIME, an expert-curated dataset for this task focused on biomedicine. Given the challenging and time-consuming nature of building hierarchies from scratch, we use a human-in-the-loop process in which experts correct errors (both links between categories and study assignment) in LLM-generated hierarchies. CHIME contains 2,174 LLM-generated hierarchies covering 472 topics, and expert-corrected hierarchies for a subset of 100 topics. Expert corrections allow us to quantify LLM performance, and we find that while they are quite good at generating and organizing categories, their assignment of studies to categories could be improved. We attempt to train a corrector model with human feedback which improves study assignment by 12.6 F1 points. We release our dataset and models to encourage research on developing better assistive tools for literature review.', 'venue': 'Annual Meeting of the Association for Computational Linguistics', 'year': 2024, 'referenceCount': 41, 'citationCount': 4, 'influentialCitationCount': 1, 'isOpenAccess': True, 'openAccessPdf': 'https://arxiv.org/pdf/2407.16148', 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle', 'Conference', 'Review'], 'publicationDate': '2024-07-23', 'journal': {'name': 'ArXiv', 'volume': 'abs/2407.16148'}, 'citationStyles': {'bibtex': '@Article{Hsu2024CHIMELH,\\n author = {Chao-Chun Hsu and Erin Bransom and Jenna Sparks and Bailey Kuehl and Chenhao Tan and David Wadden and Lucy Lu Wang and Aakanksha Naik},\\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\\n journal = {ArXiv},\\n title = {CHIME: LLM-Assisted Hierarchical Organization of Scientific Studies for Literature Review Support},\\n volume = {abs/2407.16148},\\n year = {2024}\\n}\\n'}, 'authors': [{'authorId': '23608432', 'name': 'Chao-Chun Hsu', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2203427167', 'name': 'Erin Bransom', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2052201732', 'name': 'Jenna Sparks', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2003338023', 'name': 'Bailey Kuehl', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2269860394', 'name': 'Chenhao Tan', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '30051202', 'name': 'David Wadden', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '31860505', 'name': 'Lucy Lu Wang', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2275210271', 'name': 'Aakanksha Naik', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}], 'version': '', 'arxivUrl': 'https://arxiv.org/abs/2407.16148', 'arxivId': '2407.16148', 'DOI': '10.48550/arXiv.2407.16148', 'id': '10.48550/arXiv.2407.16148', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review'], 'ref_cnt': 2}\n",
      "CHIME: LLM-Assisted Hierarchical Organization of Scientific Studies for Literature Review Support 2\n",
      "{'type': 'node', 'id': '10.48550/arXiv.2411.18583', 'labels': ['Paper'], 'properties': {'s2PaperId': 'd1797bef42d5192be92db3d7ebd7aa4df114f7f1', 'externalIds': {'ArXiv': '2411.18583', 'DBLP': 'journals/corr/abs-2411-18583', 'DOI': '10.48550/arXiv.2411.18583', 'CorpusId': 274305670}, 'corpusId': 274305670, 'publicationVenue': {'id': '1901e811-ee72-4b20-8f7e-de08cd395a10', 'name': 'arXiv.org', 'alternate_names': ['ArXiv'], 'issn': '2331-8422', 'url': 'https://arxiv.org'}, 's2Url': 'https://www.semanticscholar.org/paper/d1797bef42d5192be92db3d7ebd7aa4df114f7f1', 'title': 'Automated Literature Review Using NLP Techniques and LLM-Based Retrieval-Augmented Generation', 'abstract': 'This research presents and compares multiple approaches to automate the generation of literature reviews using several Natural Language Processing (NLP) techniques and retrieval-augmented generation (RAG) with a Large Language Model (LLM). The ever-increasing number of research articles provides a huge challenge for manual literature review. It has resulted in an increased demand for automation. Developing a system capable of automatically generating the literature reviews from only the PDF files as input is the primary objective of this research work. The effectiveness of several Natural Language Processing (NLP) strategies, such as the frequency-based method (spaCy), the transformer model (Simple T5), and retrieval-augmented generation (RAG) with Large Language Model (GPT-3.5-turbo), is evaluated to meet the primary objective. The SciTLDR dataset is chosen for this research experiment and three distinct techniques are utilized to implement three different systems for auto-generating the literature reviews. The ROUGE scores are used for the evaluation of all three systems. Based on the evaluation, the Large Language Model GPT-3.5-turbo achieved the highest ROUGE-1 score, 0.364. The transformer model comes in second place and spaCy is at the last position. Finally, a graphical user interface is created for the best system based on the large language model.', 'venue': 'arXiv.org', 'year': 2024, 'referenceCount': 0, 'citationCount': 0, 'influentialCitationCount': 0, 'isOpenAccess': True, 'openAccessPdf': 'https://arxiv.org/pdf/2411.18583', 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle', 'Review'], 'publicationDate': '2024-11-27', 'journal': {'name': 'ArXiv', 'volume': 'abs/2411.18583'}, 'citationStyles': {'bibtex': '@Article{Ali2024AutomatedLR,\\n author = {Nurshat Fateh Ali and Md. Mahdi Mohtasim and Shakil Mosharrof and T. G. Krishna},\\n booktitle = {arXiv.org},\\n journal = {ArXiv},\\n title = {Automated Literature Review Using NLP Techniques and LLM-Based Retrieval-Augmented Generation},\\n volume = {abs/2411.18583},\\n year = {2024}\\n}\\n'}, 'authors': [{'authorId': '2288033725', 'name': 'Nurshat Fateh Ali', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2332534804', 'name': 'Md. Mahdi Mohtasim', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2257033677', 'name': 'Shakil Mosharrof', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2332536516', 'name': 'T. G. Krishna', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}], 'version': '', 'arxivUrl': 'https://arxiv.org/abs/2411.18583', 'arxivId': '2411.18583', 'DOI': '10.48550/arXiv.2411.18583', 'id': '10.48550/arXiv.2411.18583', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review'], 'ref_cnt': 2}\n",
      "Automated Literature Review Using NLP Techniques and LLM-Based Retrieval-Augmented Generation 2\n",
      "{'type': 'node', 'id': '10.1109/SLAAI-ICAI63667.2024.10844968', 'labels': ['Paper'], 'properties': {'s2PaperId': '5a6fa63a1ef59dbd4bc28bde7c6ee84040fa92f4', 'externalIds': {'DOI': '10.1109/SLAAI-ICAI63667.2024.10844968', 'CorpusId': 275759920}, 'corpusId': 275759920, 'publicationVenue': None, 's2Url': 'https://www.semanticscholar.org/paper/5a6fa63a1ef59dbd4bc28bde7c6ee84040fa92f4', 'title': 'Quality Assurance for LLM-Generated Test Cases: A Systematic Literature Review', 'abstract': 'The rapid advancements in artificial intelligence have transformed software testing, with Large Language Models (LLMs) emerging as powerful tools for automating test case generation. This paper explores Quality Assurance (QA) for LLM-generated test cases in black-box testing through a systematic literature review. Though LLMs are increasingly used for test case generation, challenges in ensuring their quality remain. Following PRISMA guidelines, relevant studies were selected from databases focusing on critical quality attributes, QA frameworks, metrics, and challenges. LLMs demonstrate high efficiency but face numerous issues. A recommendation for future research is given on addressing standardized metrics and improving human-AI collaboration for enhanced testing outcomes.', 'venue': '2024 8th SLAAI International Conference on Artificial Intelligence (SLAAI-ICAI)', 'year': 2024, 'referenceCount': 72, 'citationCount': 0, 'influentialCitationCount': 0, 'isOpenAccess': False, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/SLAAI-ICAI63667.2024.10844968?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/SLAAI-ICAI63667.2024.10844968, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'fieldsOfStudy': None, 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 's2-fos-model'}], 'publicationTypes': ['Conference', 'Review'], 'publicationDate': '2024-12-18', 'journal': {'name': '2024 8th SLAAI International Conference on Artificial Intelligence (SLAAI-ICAI)', 'pages': '1-6'}, 'citationStyles': {'bibtex': '@Conference{Edirisinghe2024QualityAF,\\n author = {Hasali Edirisinghe and Dilani Wickramaarachchi},\\n booktitle = {2024 8th SLAAI International Conference on Artificial Intelligence (SLAAI-ICAI)},\\n journal = {2024 8th SLAAI International Conference on Artificial Intelligence (SLAAI-ICAI)},\\n pages = {1-6},\\n title = {Quality Assurance for LLM-Generated Test Cases: A Systematic Literature Review},\\n year = {2024}\\n}\\n'}, 'authors': [{'authorId': '2341349779', 'name': 'Hasali Edirisinghe', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2341358168', 'name': 'Dilani Wickramaarachchi', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}], 'arxivId': None, 'DOI': '10.1109/SLAAI-ICAI63667.2024.10844968', 'id': '10.1109/SLAAI-ICAI63667.2024.10844968', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review'], 'ref_cnt': 2}\n",
      "Quality Assurance for LLM-Generated Test Cases: A Systematic Literature Review 2\n",
      "{'type': 'node', 'id': '10.48550/arXiv.2404.04834', 'labels': ['Paper'], 'properties': {'s2PaperId': '027d9a3371c13ea567bca75e675db295022a300b', 'externalIds': {'ArXiv': '2404.04834', 'DOI': '10.1145/3712003', 'CorpusId': 274965784}, 'corpusId': 274965784, 'publicationVenue': {'id': '0730105a-4941-449f-9450-28cba8ae056b', 'name': 'ACM Transactions on Software Engineering and Methodology', 'type': 'journal', 'alternate_names': ['ACM Trans Softw Eng Methodol'], 'issn': '1049-331X', 'url': 'http://www.acm.org/pubs/contents/journals/tosem/', 'alternate_urls': ['https://tosem.acm.org/', 'http://tosem.acm.org/', 'http://www.acm.org/pubs/tosem/', 'http://portal.acm.org/tosem'], 'source': ['InitialSearch', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review', 'LLM automated literature review', 'LLM automated literature review', 'evaluation of AI-generated reviews']}, 's2Url': 'https://www.semanticscholar.org/paper/027d9a3371c13ea567bca75e675db295022a300b', 'title': 'LLM-Based Multi-Agent Systems for Software Engineering: Literature Review, Vision and the Road Ahead', 'abstract': 'Integrating Large Language Models (LLMs) into autonomous agents marks a significant shift in the research landscape by offering cognitive abilities that are competitive with human planning and reasoning. This paper explores the transformative potential of integrating Large Language Models into Multi-Agent (LMA) systems for addressing complex challenges in software engineering (SE). By leveraging the collaborative and specialized abilities of multiple agents, LMA systems enable autonomous problem-solving, improve robustness, and provide scalable solutions for managing the complexity of real-world software projects. In this paper, we conduct a systematic review of recent primary studies to map the current landscape of LMA applications across various stages of the software development lifecycle (SDLC). To illustrate current capabilities and limitations, we perform two case studies to demonstrate the effectiveness of state-of-the-art LMA frameworks. Additionally, we identify critical research gaps and propose a comprehensive research agenda focused on enhancing individual agent capabilities and optimizing agent synergy. Our work outlines a forward-looking vision for developing fully autonomous, scalable, and trustworthy LMA systems, laying the foundation for the evolution of Software Engineering 2.0.', 'venue': 'ACM Transactions on Software Engineering and Methodology', 'year': 2024, 'referenceCount': 170, 'citationCount': 2, 'influentialCitationCount': 0, 'isOpenAccess': True, 'openAccessPdf': 'https://arxiv.org/pdf/2404.04834', 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Engineering', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle', 'Review'], 'publicationDate': '2024-04-07', 'journal': {'name': 'ACM Transactions on Software Engineering and Methodology'}, 'citationStyles': {'bibtex': '@Article{He2024LLMBasedMS,\\n author = {Junda He and Christoph Treude and David Lo},\\n booktitle = {ACM Transactions on Software Engineering and Methodology},\\n journal = {ACM Transactions on Software Engineering and Methodology},\\n title = {LLM-Based Multi-Agent Systems for Software Engineering: Literature Review, Vision and the Road Ahead},\\n year = {2024}\\n}\\n'}, 'authors': [{'authorId': '2158107537', 'name': 'Junda He', 'source': ['InitialSearch', 'RecommendedPaper', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424', 'LLM automated literature review']}, {'authorId': '2257011464', 'name': 'Christoph Treude', 'source': ['InitialSearch', 'RecommendedPaper', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424', 'LLM automated literature review']}, {'authorId': '2275193225', 'name': 'David Lo', 'source': ['InitialSearch', 'RecommendedPaper', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424', 'LLM automated literature review']}], 'version': '', 'arxivUrl': 'https://arxiv.org/abs/2404.04834', 'arxivId': '2404.04834', 'DOI': '10.1145/3712003', 'id': '10.48550/arXiv.2404.04834', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review'], 'ref_cnt': 2}\n",
      "LLM-Based Multi-Agent Systems for Software Engineering: Literature Review, Vision and the Road Ahead 2\n",
      "{'type': 'node', 'id': '77d42c4dc1eb48c1c17e71acea0f7f870eba1594', 'labels': ['Paper'], 'properties': {'s2PaperId': '77d42c4dc1eb48c1c17e71acea0f7f870eba1594', 'externalIds': {'DBLP': 'conf/aied/AntuCR23', 'CorpusId': 262068993}, 'corpusId': 262068993, 'publicationVenue': None, 's2Url': 'https://www.semanticscholar.org/paper/77d42c4dc1eb48c1c17e71acea0f7f870eba1594', 'title': 'Using LLM (Large Language Model) to Improve Efficiency in Literature Review for Undergraduate Research', 'abstract': None, 'venue': 'LLM@AIED', 'year': 2023, 'referenceCount': 17, 'citationCount': 13, 'influentialCitationCount': 0, 'isOpenAccess': False, 'openAccessPdf': {'url': '', 'status': None, 'license': None}, 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Education', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle', 'Review'], 'publicationDate': None, 'journal': {'pages': '8-16'}, 'citationStyles': {'bibtex': '@Article{Antu2023UsingL,\\n author = {Shouvik Ahmed Antu and Haiyan Chen and Cindy K. Richards},\\n booktitle = {LLM@AIED},\\n pages = {8-16},\\n title = {Using LLM (Large Language Model) to Improve Efficiency in Literature Review for Undergraduate Research},\\n year = {2023}\\n}\\n'}, 'authors': [{'authorId': '2215899394', 'name': 'Shouvik Ahmed Antu', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2243378515', 'name': 'Haiyan Chen', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '37928234', 'name': 'Cindy K. Richards', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}], 'arxivId': None, 'DOI': None, 'id': '77d42c4dc1eb48c1c17e71acea0f7f870eba1594', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review'], 'ref_cnt': 2}\n",
      "Using LLM (Large Language Model) to Improve Efficiency in Literature Review for Undergraduate Research 2\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for item in sorted_data_lambda:\n",
    "    if i < 10:\n",
    "        if item['labels'] == ['Paper']:\n",
    "            print(item)\n",
    "            print(item['properties']['title'], item['ref_cnt'])\n",
    "            i += 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CITES', 'PRINTS_ON', 'RELEASES_IN', 'SIMILAR_TO', 'WRITES'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([x['relationshipType'] for x in paperbot.edges_json])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'relationship', 'relationshipType': 'SIMILAR_TO', 'startNodeId': '10.48550/arXiv.2406.10252', 'endNodeId': '10.48550/arXiv.2412.10415', 'properties': {'source': 'semantic similarity', 'weight': 0.699}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for item in paperbot.edges_json:\n",
    "    if item['relationshipType'] == 'SIMILAR_TO':\n",
    "        print(item)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for item in paperbot.edges_json:\n",
    "    if item['relationshipType'] == 'SIMILAR_TO':\n",
    "        if item['properties']['weight'] > 0.7:\n",
    "            tmp.append(item)\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        tmp.append(item)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8371, 100721)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmp), len(paperbot.edges_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "end_to_paper_dcts = [x for x in tmp if 'arXiv' in x['endNodeId']]\n",
    "\n",
    "target_key = 'endNodeId'\n",
    "value_counts = defaultdict(int)\n",
    "\n",
    "for item in end_to_paper_dcts:\n",
    "    if target_key in item:\n",
    "        value = item[target_key]\n",
    "        value_counts[value] += 1\n",
    "\n",
    "# 按照出现次数从高到低排序\n",
    "sorted_counts = sorted(value_counts.items(), key=lambda item: item[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'endNodeId' 对应的取值统计 (从高到低排序):\n",
      "10.48550/arXiv.2409.04600: 93\n",
      "The emergence of Large Language Models (LLM) as a tool in literature reviews: an LLM automated systematic review\n",
      "10.48550/arXiv.2412.15249: 81\n",
      "LLMs for Literature Review: Are we there yet?\n",
      "10.48550/arXiv.2403.08399: 65\n",
      "System for systematic literature review using multiple AI agents: Concept and an empirical evaluation\n",
      "10.48550/arXiv.2412.13612: 63\n",
      "Are LLMs Good Literature Review Writers? Evaluating the Literature Review Writing Ability of Large Language Models\n",
      "10.48550/arXiv.2406.10252: 61\n",
      "AutoSurvey: Large Language Models Can Automatically Write Surveys\n",
      "10.48550/arXiv.2308.10620: 61\n",
      "Large Language Models for Software Engineering: A Systematic Literature Review\n",
      "10.48550/arXiv.2503.08569: 56\n",
      "DeepReview: Improving LLM-based Paper Review with Human-like Deep Thinking Process\n",
      "10.48550/arXiv.2403.07183: 54\n",
      "Monitoring AI-Modified Content at Scale: A Case Study on the Impact of ChatGPT on AI Conference Peer Reviews\n",
      "10.48550/arXiv.2411.02451: 53\n",
      "High-performance automated abstract screening with large language model ensembles\n",
      "10.48550/arXiv.2503.01424: 51\n",
      "From Hypothesis to Publication: A Comprehensive Survey of AI-Driven Research Support Systems\n",
      "10.48550/arXiv.2412.10415: 50\n",
      "Generative Adversarial Reviews: When LLMs Become the Critic\n",
      "10.48550/arXiv.2411.18583: 49\n",
      "Automated Literature Review Using NLP Techniques and LLM-Based Retrieval-Augmented Generation\n",
      "10.48550/arXiv.2501.12557: 49\n",
      "Understanding the LLM-ification of CHI: Unpacking the Impact of LLMs at CHI through a Systematic Literature Review\n",
      "10.48550/arXiv.2405.02150: 49\n",
      "The AI Review Lottery: Widespread AI-Assisted Peer Reviews Boost Paper Scores and Acceptance Rates\n",
      "10.48550/arXiv.2405.01466: 46\n",
      "A Systematic Literature Review on Large Language Models for Automated Program Repair\n",
      "10.48550/arXiv.2405.06563: 46\n",
      "What Can Natural Language Processing Do for Peer Review?\n",
      "10.48550/arXiv.2402.01788: 45\n",
      "LitLLM: A Toolkit for Scientific Literature Review\n",
      "10.48550/arXiv.2403.09743: 45\n",
      "The Human Factor in Detecting Errors of Large Language Models: A Systematic Literature Review and Future Research Directions\n",
      "10.48550/arXiv.2407.20906: 45\n",
      "Automated Review Generation Method Based on Large Language Models\n",
      "10.48550/arXiv.2401.15641: 45\n",
      "PRE: A Peer Review Based Large Language Model Evaluator\n",
      "10.48550/arXiv.2412.00281: 45\n",
      "Streamlining the review process: AI-generated annotations in research manuscripts\n",
      "10.48550/arXiv.2412.01708: 44\n",
      "Are We There Yet? Revealing the Risks of Utilizing Large Language Models in Scholarly Peer Review\n",
      "10.48550/arXiv.2403.02574: 43\n",
      "ChatCite: LLM Agent with Human Workflow Guidance for Comparative Literature Summary\n",
      "10.48550/arXiv.2410.16349: 43\n",
      "Large Language Models in Computer Science Education: A Systematic Literature Review\n",
      "10.48550/arXiv.2309.12356: 42\n",
      "A Critical Examination of the Ethics of AI-Mediated Peer Review\n",
      "10.48550/arXiv.2410.12265: 42\n",
      "An Automatic and Cost-Efficient Peer-Review Framework for Language Generation Evaluation\n",
      "10.48550/arXiv.2310.17526: 41\n",
      "Can large language models replace humans in the systematic review process? Evaluating GPT-4's efficacy in screening and extracting data from peer-reviewed and grey literature in multiple languages\n",
      "10.48550/arXiv.2405.04760: 40\n",
      "Large Language Models for Cyber Security: A Systematic Literature Review\n",
      "10.48550/arXiv.2303.13379: 39\n",
      "Practical and Ethical Challenges of Large Language Models in Education: A Systematic Literature Review\n",
      "10.48550/arXiv.2406.12708: 39\n",
      "AgentReview: Exploring Peer Review Dynamics with LLM Agents\n",
      "10.48550/arXiv.2404.02525: 37\n",
      "Large Language Model for Vulnerability Detection and Repair: Literature Review and the Road Ahead\n",
      "10.48550/arXiv.2405.02559: 35\n",
      "A framework for human evaluation of large language models in healthcare derived from literature review\n",
      "10.48550/arXiv.2407.16148: 34\n",
      "CHIME: LLM-Assisted Hierarchical Organization of Scientific Studies for Literature Review Support\n",
      "10.48550/arXiv.2404.04834: 34\n",
      "LLM-Based Multi-Agent Systems for Software Engineering: Literature Review, Vision and the Road Ahead\n",
      "10.48550/arXiv.2402.10350: 34\n",
      "Large Language Models for Forecasting and Anomaly Detection: A Systematic Literature Review\n",
      "10.48550/arXiv.2309.00770: 33\n",
      "Bias and Fairness in Large Language Models: A Survey\n"
     ]
    }
   ],
   "source": [
    "print(f\"'{target_key}' 对应的取值统计 (从高到低排序):\")\n",
    "\n",
    "node_dois = [x['id'] for x in paperbot.nodes_json]\n",
    "\n",
    "next_dois = []\n",
    "for value, count in sorted_counts:\n",
    "    if count > 30:\n",
    "        print(f\"{value}: {count}\")\n",
    "        idx = node_dois.index(value)\n",
    "        print(paperbot.nodes_json[idx]['properties']['title'])\n",
    "        next_dois.append(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'startNodeId' 对应的取值统计 (从高到低排序):\n",
      "10.48550/arXiv.2402.12928: 112\n",
      "A Literature Review of Literature Reviews in Pattern Analysis and Machine Intelligence\n",
      "10.48550/arXiv.2412.10415: 101\n",
      "Generative Adversarial Reviews: When LLMs Become the Critic\n",
      "10.48550/arXiv.2409.04600: 83\n",
      "The emergence of Large Language Models (LLM) as a tool in literature reviews: an LLM automated systematic review\n",
      "10.48550/arXiv.2412.15249: 73\n",
      "LLMs for Literature Review: Are we there yet?\n",
      "10.48550/arXiv.2406.10252: 70\n",
      "AutoSurvey: Large Language Models Can Automatically Write Surveys\n",
      "10.48550/arXiv.2412.13612: 60\n",
      "Are LLMs Good Literature Review Writers? Evaluating the Literature Review Writing Ability of Large Language Models\n",
      "10.48550/arXiv.2308.10620: 47\n",
      "Large Language Models for Software Engineering: A Systematic Literature Review\n",
      "10.48550/arXiv.2403.08399: 47\n",
      "System for systematic literature review using multiple AI agents: Concept and an empirical evaluation\n",
      "10.48550/arXiv.2403.07183: 45\n",
      "Monitoring AI-Modified Content at Scale: A Case Study on the Impact of ChatGPT on AI Conference Peer Reviews\n",
      "10.48550/arXiv.2403.09743: 44\n",
      "The Human Factor in Detecting Errors of Large Language Models: A Systematic Literature Review and Future Research Directions\n",
      "10.48550/arXiv.2503.08569: 44\n",
      "DeepReview: Improving LLM-based Paper Review with Human-like Deep Thinking Process\n",
      "10.48550/arXiv.2405.02150: 44\n",
      "The AI Review Lottery: Widespread AI-Assisted Peer Reviews Boost Paper Scores and Acceptance Rates\n",
      "10.48550/arXiv.2411.02451: 43\n",
      "High-performance automated abstract screening with large language model ensembles\n",
      "10.48550/arXiv.2412.00281: 42\n",
      "Streamlining the review process: AI-generated annotations in research manuscripts\n",
      "10.48550/arXiv.2411.18583: 41\n",
      "Automated Literature Review Using NLP Techniques and LLM-Based Retrieval-Augmented Generation\n",
      "10.48550/arXiv.2401.15641: 40\n",
      "PRE: A Peer Review Based Large Language Model Evaluator\n",
      "10.48550/arXiv.2410.16349: 39\n",
      "Large Language Models in Computer Science Education: A Systematic Literature Review\n",
      "10.48550/arXiv.2309.12356: 39\n",
      "A Critical Examination of the Ethics of AI-Mediated Peer Review\n",
      "10.48550/arXiv.2310.17526: 38\n",
      "Can large language models replace humans in the systematic review process? Evaluating GPT-4's efficacy in screening and extracting data from peer-reviewed and grey literature in multiple languages\n",
      "10.48550/arXiv.2402.01788: 37\n",
      "LitLLM: A Toolkit for Scientific Literature Review\n",
      "10.48550/arXiv.2405.06563: 36\n",
      "What Can Natural Language Processing Do for Peer Review?\n",
      "10.48550/arXiv.2403.02574: 35\n",
      "ChatCite: LLM Agent with Human Workflow Guidance for Comparative Literature Summary\n",
      "10.48550/arXiv.2501.12557: 35\n",
      "Understanding the LLM-ification of CHI: Unpacking the Impact of LLMs at CHI through a Systematic Literature Review\n",
      "10.48550/arXiv.2407.20906: 35\n",
      "Automated Review Generation Method Based on Large Language Models\n",
      "10.48550/arXiv.2412.01708: 35\n",
      "Are We There Yet? Revealing the Risks of Utilizing Large Language Models in Scholarly Peer Review\n",
      "10.48550/arXiv.2410.12265: 34\n",
      "An Automatic and Cost-Efficient Peer-Review Framework for Language Generation Evaluation\n",
      "10.48550/arXiv.2406.12708: 33\n",
      "AgentReview: Exploring Peer Review Dynamics with LLM Agents\n",
      "10.48550/arXiv.2404.04834: 32\n",
      "LLM-Based Multi-Agent Systems for Software Engineering: Literature Review, Vision and the Road Ahead\n",
      "10.48550/arXiv.2405.01466: 32\n",
      "A Systematic Literature Review on Large Language Models for Automated Program Repair\n",
      "10.48550/arXiv.2404.02525: 31\n",
      "Large Language Model for Vulnerability Detection and Repair: Literature Review and the Road Ahead\n",
      "10.48550/arXiv.2405.04760: 31\n",
      "Large Language Models for Cyber Security: A Systematic Literature Review\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "start_from_paper_dcts = [x for x in tmp if 'arXiv' in x['startNodeId']]\n",
    "\n",
    "target_key = 'startNodeId'\n",
    "value_counts = defaultdict(int)\n",
    "\n",
    "for item in start_from_paper_dcts:\n",
    "    if target_key in item:\n",
    "        value = item[target_key]\n",
    "        value_counts[value] += 1\n",
    "\n",
    "# 按照出现次数从高到低排序\n",
    "sorted_counts = sorted(value_counts.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "print(f\"'{target_key}' 对应的取值统计 (从高到低排序):\")\n",
    "\n",
    "node_dois = [x['id'] for x in paperbot.nodes_json]\n",
    "\n",
    "for value, count in sorted_counts:\n",
    "    if count > 30:\n",
    "        print(f\"{value}: {count}\")\n",
    "        idx = node_dois.index(value)\n",
    "        print(paperbot.nodes_json[idx]['properties']['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Exapnsion (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(next_dois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_info = []\n",
    "for item in paperbot.nodes_json:\n",
    "    if item['labels'] == ['Paper']:\n",
    "        papers_info.append(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "603"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(papers_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_author_ids = []\n",
    "for item in papers_info:\n",
    "    if item['id'] in next_dois:\n",
    "        author_ids = [x['authorId'] for x in item['properties']['authors']][0:5]\n",
    "        for author_id in author_ids:\n",
    "            if author_id not in next_author_ids:\n",
    "                next_author_ids.append(author_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_data_lambda = sorted(data, key=lambda item: item['score'], reverse=True)\n",
    "print(sorted_data_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 15:28:44,284 - INFO - HTTP Request: POST https://api.semanticscholar.org/graph/v1/author/batch?fields=affiliations%2CauthorId%2CcitationCount%2CexternalIds%2ChIndex%2Chomepage%2Cname%2CpaperCount%2Cpapers%2Cpapers.abstract%2Cpapers.authors%2Cpapers.citationCount%2Cpapers.corpusId%2Cpapers.externalIds%2Cpapers.fieldsOfStudy%2Cpapers.influentialCitationCount%2Cpapers.isOpenAccess%2Cpapers.journal%2Cpapers.openAccessPdf%2Cpapers.paperId%2Cpapers.publicationDate%2Cpapers.publicationTypes%2Cpapers.publicationVenue%2Cpapers.referenceCount%2Cpapers.s2FieldsOfStudy%2Cpapers.title%2Cpapers.url%2Cpapers.venue%2Cpapers.year%2Curl \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from apis.s2_api import SemanticScholarKit\n",
    "\n",
    "s2 = SemanticScholarKit()\n",
    "authors = s2.search_author_by_ids(author_ids=next_author_ids[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affiliations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['authorId', 'externalIds', 'url', 'name', 'affiliations', 'homepage', 'paperCount', 'citationCount', 'hIndex', 'papers'])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_authors_id = [x['authorId'] for x in authors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_author_ids = []\n",
    "for item in papers_info:\n",
    "    hindex = 0 \n",
    "    if item['id'] in next_dois:\n",
    "        author_ids = [x['authorId'] for x in item['properties']['authors']][0:5]\n",
    "        for author_id in author_ids:\n",
    "            if author_id in find_authors_id:\n",
    "                idx = find_authors_id.index(author_id)\n",
    "                hindex += authors[idx].get('hIndex', 0)\n",
    "    item['authors_hindex'] = hindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'node', 'id': '10.48550/arXiv.2402.01788', 'labels': ['Paper'], 'properties': {'s2PaperId': 'fd30d3189b3bc3295ddad05ac1f683ce41f5e9cb', 'externalIds': {'ArXiv': '2402.01788', 'DBLP': 'journals/corr/abs-2402-01788', 'DOI': '10.48550/arXiv.2402.01788', 'CorpusId': 267412619}, 'corpusId': 267412619, 'publicationVenue': {'id': '1901e811-ee72-4b20-8f7e-de08cd395a10', 'name': 'arXiv.org', 'alternate_names': ['ArXiv'], 'issn': '2331-8422', 'url': 'https://arxiv.org'}, 's2Url': 'https://www.semanticscholar.org/paper/fd30d3189b3bc3295ddad05ac1f683ce41f5e9cb', 'title': 'LitLLM: A Toolkit for Scientific Literature Review', 'abstract': 'Conducting literature reviews for scientific papers is essential for understanding research, its limitations, and building on existing work. It is a tedious task which makes an automatic literature review generator appealing. Unfortunately, many existing works that generate such reviews using Large Language Models (LLMs) have significant limitations. They tend to hallucinate-generate non-actual information-and ignore the latest research they have not been trained on. To address these limitations, we propose a toolkit that operates on Retrieval Augmented Generation (RAG) principles, specialized prompting and instructing techniques with the help of LLMs. Our system first initiates a web search to retrieve relevant papers by summarizing user-provided abstracts into keywords using an off-the-shelf LLM. Authors can enhance the search by supplementing it with relevant papers or keywords, contributing to a tailored retrieval process. Second, the system re-ranks the retrieved papers based on the user-provided abstract. Finally, the related work section is generated based on the re-ranked results and the abstract. There is a substantial reduction in time and effort for literature review compared to traditional methods, establishing our toolkit as an efficient alternative. Our open-source toolkit is accessible at https://github.com/shubhamagarwal92/LitLLM and Huggingface space (https://huggingface.co/spaces/shubhamagarwal92/LitLLM) with the video demo at https://youtu.be/E2ggOZBAFw0.', 'venue': 'arXiv.org', 'year': 2024, 'referenceCount': 38, 'citationCount': 16, 'influentialCitationCount': 1, 'isOpenAccess': True, 'openAccessPdf': 'https://arxiv.org/pdf/2402.01788', 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle', 'Review'], 'publicationDate': '2024-02-02', 'journal': {'name': 'ArXiv', 'volume': 'abs/2402.01788'}, 'citationStyles': {'bibtex': '@Article{Agarwal2024LitLLMAT,\\n author = {Shubham Agarwal and I. Laradji and Laurent Charlin and Christopher Pal},\\n booktitle = {arXiv.org},\\n journal = {ArXiv},\\n title = {LitLLM: A Toolkit for Scientific Literature Review},\\n volume = {abs/2402.01788},\\n year = {2024}\\n}\\n'}, 'authors': [{'authorId': '2275258816', 'name': 'Shubham Agarwal', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '3266173', 'name': 'I. Laradji', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '1778839', 'name': 'Laurent Charlin', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2275240361', 'name': 'Christopher Pal', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}], 'version': '', 'arxivUrl': 'https://arxiv.org/abs/2402.01788', 'arxivId': '2402.01788', 'DOI': '10.48550/arXiv.2402.01788', 'id': '10.48550/arXiv.2402.01788', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review'], 'ref_cnt': 2, 'authors_hindex': 66}\n",
      "LitLLM: A Toolkit for Scientific Literature Review\n",
      "{'type': 'node', 'id': '10.48550/arXiv.2412.15249', 'labels': ['Paper'], 'properties': {'s2PaperId': '7eace4b98534c551d05eef1304fdd84c4ace61ed', 'externalIds': {'ArXiv': '2412.15249', 'DBLP': 'journals/corr/abs-2412-15249', 'DOI': '10.48550/arXiv.2412.15249', 'CorpusId': 274965768}, 'corpusId': 274965768, 'publicationVenue': {'id': '1901e811-ee72-4b20-8f7e-de08cd395a10', 'name': 'arXiv.org', 'alternate_names': ['ArXiv'], 'issn': '2331-8422', 'url': 'https://arxiv.org'}, 's2Url': 'https://www.semanticscholar.org/paper/7eace4b98534c551d05eef1304fdd84c4ace61ed', 'title': 'LLMs for Literature Review: Are we there yet?', 'abstract': \"Literature reviews are an essential component of scientific research, but they remain time-intensive and challenging to write, especially due to the recent influx of research papers. This paper explores the zero-shot abilities of recent Large Language Models (LLMs) in assisting with the writing of literature reviews based on an abstract. We decompose the task into two components: 1. Retrieving related works given a query abstract, and 2. Writing a literature review based on the retrieved results. We analyze how effective LLMs are for both components. For retrieval, we introduce a novel two-step search strategy that first uses an LLM to extract meaningful keywords from the abstract of a paper and then retrieves potentially relevant papers by querying an external knowledge base. Additionally, we study a prompting-based re-ranking mechanism with attribution and show that re-ranking doubles the normalized recall compared to naive search methods, while providing insights into the LLM's decision-making process. In the generation phase, we propose a two-step approach that first outlines a plan for the review and then executes steps in the plan to generate the actual review. To evaluate different LLM-based literature review methods, we create test sets from arXiv papers using a protocol designed for rolling use with newly released LLMs to avoid test set contamination in zero-shot evaluations. We release this evaluation protocol to promote additional research and development in this regard. Our empirical results suggest that LLMs show promising potential for writing literature reviews when the task is decomposed into smaller components of retrieval and planning. Further, we demonstrate that our planning-based approach achieves higher-quality reviews by minimizing hallucinated references in the generated review by 18-26% compared to existing simpler LLM-based generation methods.\", 'venue': 'arXiv.org', 'year': 2024, 'referenceCount': 63, 'citationCount': 0, 'influentialCitationCount': 0, 'isOpenAccess': True, 'openAccessPdf': 'https://arxiv.org/pdf/2412.15249', 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle', 'Review'], 'publicationDate': '2024-12-15', 'journal': {'name': 'ArXiv', 'volume': 'abs/2412.15249'}, 'citationStyles': {'bibtex': '@Article{Agarwal2024LLMsFL,\\n author = {Shubham Agarwal and Gaurav Sahu and Abhay Puri and I. Laradji and K. Dvijotham and Jason Stanley and Laurent Charlin and Christopher Pal},\\n booktitle = {arXiv.org},\\n journal = {ArXiv},\\n title = {LLMs for Literature Review: Are we there yet?},\\n volume = {abs/2412.15249},\\n year = {2024}\\n}\\n'}, 'authors': [{'authorId': '2275258816', 'name': 'Shubham Agarwal', 'source': ['InitialSearch'], 'sourceDesc': ['Search from S2 based on user input']}, {'authorId': '2267339519', 'name': 'Gaurav Sahu', 'source': ['InitialSearch'], 'sourceDesc': ['Search from S2 based on user input']}, {'authorId': '2310436656', 'name': 'Abhay Puri', 'source': ['InitialSearch'], 'sourceDesc': ['Search from S2 based on user input']}, {'authorId': '3266173', 'name': 'I. Laradji', 'source': ['InitialSearch'], 'sourceDesc': ['Search from S2 based on user input']}, {'authorId': '1729912', 'name': 'K. Dvijotham', 'source': ['InitialSearch'], 'sourceDesc': ['Search from S2 based on user input']}, {'authorId': '2336738047', 'name': 'Jason Stanley', 'source': ['InitialSearch'], 'sourceDesc': ['Search from S2 based on user input']}, {'authorId': '2336737850', 'name': 'Laurent Charlin', 'source': ['InitialSearch'], 'sourceDesc': ['Search from S2 based on user input']}, {'authorId': '2275240361', 'name': 'Christopher Pal', 'source': ['InitialSearch'], 'sourceDesc': ['Search from S2 based on user input']}], 'version': '', 'arxivUrl': 'https://arxiv.org/abs/2412.15249', 'arxivId': '2412.15249', 'DOI': '10.48550/arXiv.2412.15249', 'id': '10.48550/arXiv.2412.15249', 'source': ['InitialSearch'], 'sourceDesc': ['Search from S2 based on user input']}, 'ref_cnt': 1, 'authors_hindex': 66}\n",
      "LLMs for Literature Review: Are we there yet?\n",
      "{'type': 'node', 'id': '10.48550/arXiv.2309.00770', 'labels': ['Paper'], 'properties': {'s2PaperId': 'bcfa73aedf1b2d1ee4f168e21298a37ac55a37f7', 'externalIds': {'DBLP': 'journals/corr/abs-2309-00770', 'ArXiv': '2309.00770', 'DOI': '10.1162/coli_a_00524', 'CorpusId': 261530629}, 'corpusId': 261530629, 'publicationVenue': {'id': 'ee37a78c-f3d8-407a-bd24-bb97fe6dbab9', 'name': 'Computational Linguistics', 'type': 'journal', 'alternate_names': ['Comput Linguistics'], 'issn': '0891-2017', 'alternate_issns': ['1530-9312', '0362-613x', '0362-613X'], 'url': 'http://aclanthology.info/venues/cl', 'alternate_urls': ['http://mitpress.mit.edu/catalog/item/default.asp?ttype=4&tid=10', 'https://www.mitpressjournals.org/loi/coli'], 'source': ['CitedPaper'], 'sourceDesc': ['cited by 10.48550/arXiv.2412.10415']}, 's2Url': 'https://www.semanticscholar.org/paper/bcfa73aedf1b2d1ee4f168e21298a37ac55a37f7', 'title': 'Bias and Fairness in Large Language Models: A Survey', 'abstract': 'Abstract Rapid advancements of large language models (LLMs) have enabled the processing, understanding, and generation of human-like text, with increasing integration into systems that touch our social sphere. Despite this success, these models can learn, perpetuate, and amplify harmful social biases. In this article, we present a comprehensive survey of bias evaluation and mitigation techniques for LLMs. We first consolidate, formalize, and expand notions of social bias and fairness in natural language processing, defining distinct facets of harm and introducing several desiderata to operationalize fairness for LLMs. We then unify the literature by proposing three intuitive taxonomies, two for bias evaluation, namely, metrics and datasets, and one for mitigation. Our first taxonomy of metrics for bias evaluation disambiguates the relationship between metrics and evaluation datasets, and organizes metrics by the different levels at which they operate in a model: embeddings, probabilities, and generated text. Our second taxonomy of datasets for bias evaluation categorizes datasets by their structure as counterfactual inputs or prompts, and identifies the targeted harms and social groups; we also release a consolidation of publicly available datasets for improved access. Our third taxonomy of techniques for bias mitigation classifies methods by their intervention during pre-processing, in-training, intra-processing, and post-processing, with granular subcategories that elucidate research trends. Finally, we identify open problems and challenges for future work. Synthesizing a wide range of recent research, we aim to provide a clear guide of the existing literature that empowers researchers and practitioners to better understand and prevent the propagation of bias in LLMs.', 'venue': 'Computational Linguistics', 'year': 2023, 'referenceCount': 256, 'citationCount': 381, 'influentialCitationCount': 23, 'isOpenAccess': True, 'openAccessPdf': 'https://arxiv.org/pdf/2309.00770', 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle', 'Review'], 'publicationDate': '2023-09-02', 'journal': {'volume': '50', 'pages': '1097-1179', 'name': 'Computational Linguistics'}, 'citationStyles': {'bibtex': '@Article{Gallegos2023BiasAF,\\n author = {Isabel O. Gallegos and Ryan A. Rossi and Joe Barrow and Md. Mehrab Tanjim and Sungchul Kim and Franck Dernoncourt and Tong Yu and Ruiyi Zhang and Nesreen Ahmed},\\n booktitle = {Computational Linguistics},\\n journal = {Computational Linguistics},\\n pages = {1097-1179},\\n title = {Bias and Fairness in Large Language Models: A Survey},\\n volume = {50},\\n year = {2023}\\n}\\n'}, 'authors': [{'authorId': '2237806749', 'name': 'Isabel O. Gallegos', 'source': ['CitedPaper'], 'sourceDesc': ['cited by 10.48550/arXiv.2412.10415']}, {'authorId': '2066337266', 'name': 'Ryan A. Rossi', 'source': ['CitedPaper'], 'sourceDesc': ['cited by 10.48550/arXiv.2412.10415']}, {'authorId': '40080808', 'name': 'Joe Barrow', 'source': ['CitedPaper'], 'sourceDesc': ['cited by 10.48550/arXiv.2412.10415']}, {'authorId': '35631602', 'name': 'Md. Mehrab Tanjim', 'source': ['CitedPaper'], 'sourceDesc': ['cited by 10.48550/arXiv.2412.10415']}, {'authorId': '2109571021', 'name': 'Sungchul Kim', 'source': ['CitedPaper'], 'sourceDesc': ['cited by 10.48550/arXiv.2412.10415']}, {'authorId': '2462276', 'name': 'Franck Dernoncourt', 'source': ['CitedPaper'], 'sourceDesc': ['cited by 10.48550/arXiv.2412.10415']}, {'authorId': '1500399016', 'name': 'Tong Yu', 'source': ['CitedPaper'], 'sourceDesc': ['cited by 10.48550/arXiv.2412.10415']}, {'authorId': '1940556', 'name': 'Ruiyi Zhang', 'source': ['CitedPaper'], 'sourceDesc': ['cited by 10.48550/arXiv.2412.10415']}, {'authorId': '47699955', 'name': 'Nesreen Ahmed', 'source': ['CitedPaper'], 'sourceDesc': ['cited by 10.48550/arXiv.2412.10415']}], 'version': '', 'arxivUrl': 'https://arxiv.org/abs/2309.00770', 'arxivId': '2309.00770', 'DOI': '10.1162/coli_a_00524', 'id': '10.48550/arXiv.2309.00770', 'source': ['CitedPaper'], 'sourceDesc': ['cited by 10.48550/arXiv.2412.10415']}, 'ref_cnt': 1, 'authors_hindex': 52}\n",
      "Bias and Fairness in Large Language Models: A Survey\n",
      "{'type': 'node', 'id': '10.48550/arXiv.2308.10620', 'labels': ['Paper'], 'properties': {'s2PaperId': '000f964393dafe113a8e66734d63b2a145844159', 'externalIds': {'DBLP': 'journals/tosem/HouZLYWLLLGW24', 'ArXiv': '2308.10620', 'DOI': '10.48550/arXiv.2308.10620', 'CorpusId': 261048648}, 'corpusId': 261048648, 'publicationVenue': {'id': '0730105a-4941-449f-9450-28cba8ae056b', 'name': 'ACM Transactions on Software Engineering and Methodology', 'type': 'journal', 'alternate_names': ['ACM Trans Softw Eng Methodol'], 'issn': '1049-331X', 'url': 'http://www.acm.org/pubs/contents/journals/tosem/', 'alternate_urls': ['https://tosem.acm.org/', 'http://tosem.acm.org/', 'http://www.acm.org/pubs/tosem/', 'http://portal.acm.org/tosem'], 'source': ['InitialSearch'], 'sourceDesc': ['Search from S2 based on user input']}, 's2Url': 'https://www.semanticscholar.org/paper/000f964393dafe113a8e66734d63b2a145844159', 'title': 'Large Language Models for Software Engineering: A Systematic Literature Review', 'abstract': '\\n Large Language Models (LLMs) have significantly impacted numerous domains, including Software Engineering (SE). Many recent publications have explored LLMs applied to various SE tasks. Nevertheless, a comprehensive understanding of the application, effects, and possible limitations of LLMs on SE is still in its early stages. To bridge this gap, we conducted a systematic literature review (SLR) on LLM4SE, with a particular focus on understanding how LLMs can be exploited to optimize processes and outcomes. We selected and analyzed 395 research papers from January 2017 to January 2024 to answer four key research questions (RQs). In RQ1, we categorize different LLMs that have been employed in SE tasks, characterizing their distinctive features and uses. In RQ2, we analyze the methods used in data collection, preprocessing, and application, highlighting the role of well-curated datasets for successful LLM for SE implementation. RQ3 investigates the strategies employed to optimize and evaluate the performance of LLMs in SE. Finally, RQ4 examines the specific SE tasks where LLMs have shown success to date, illustrating their practical contributions to the field. From the answers to these RQs, we discuss the current state-of-the-art and trends, identifying gaps in existing research, and highlighting promising areas for future study. Our artifacts are publicly available at\\n https://github.com/xinyi-hou/LLM4SE_SLR\\n .\\n', 'venue': 'ACM Transactions on Software Engineering and Methodology', 'year': 2023, 'referenceCount': 404, 'citationCount': 261, 'influentialCitationCount': 16, 'isOpenAccess': True, 'openAccessPdf': 'https://arxiv.org/pdf/2308.10620', 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle', 'Review'], 'publicationDate': '2023-08-21', 'journal': {'name': 'ACM Trans. Softw. Eng. Methodol.', 'pages': '220:1-220:79', 'volume': '33'}, 'citationStyles': {'bibtex': '@Article{Hou2023LargeLM,\\n author = {Xinying Hou and Yanjie Zhao and Yue Liu and Zhou Yang and Kailong Wang and Li Li and Xiapu Luo and David Lo and John C. Grundy and Haoyu Wang},\\n booktitle = {ACM Transactions on Software Engineering and Methodology},\\n journal = {ACM Trans. Softw. Eng. Methodol.},\\n pages = {220:1-220:79},\\n title = {Large Language Models for Software Engineering: A Systematic Literature Review},\\n volume = {33},\\n year = {2023}\\n}\\n'}, 'authors': [{'authorId': '38542077', 'name': 'Xinying Hou', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2109712263', 'name': 'Yanjie Zhao', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2262400578', 'name': 'Yue Liu', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2139059234', 'name': 'Zhou Yang', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '3088630', 'name': 'Kailong Wang', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2156056522', 'name': 'Li Li', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2241568071', 'name': 'Xiapu Luo', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2150912791', 'name': 'David Lo', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2095462233', 'name': 'John C. Grundy', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': None, 'name': 'Haoyu Wang'}], 'version': '', 'arxivUrl': 'https://arxiv.org/abs/2308.10620', 'arxivId': '2308.10620', 'DOI': '10.48550/arXiv.2308.10620', 'id': '10.48550/arXiv.2308.10620', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review'], 'ref_cnt': 2, 'authors_hindex': 48}\n",
      "Large Language Models for Software Engineering: A Systematic Literature Review\n",
      "{'type': 'node', 'id': '10.48550/arXiv.2501.12557', 'labels': ['Paper'], 'properties': {'s2PaperId': '73b5b51d825a744611e782447f27dc0846069e0c', 'externalIds': {'ArXiv': '2501.12557', 'DBLP': 'journals/corr/abs-2501-12557', 'DOI': '10.48550/arXiv.2501.12557', 'CorpusId': 275788916}, 'corpusId': 275788916, 'publicationVenue': {'id': '1901e811-ee72-4b20-8f7e-de08cd395a10', 'name': 'arXiv.org', 'alternate_names': ['ArXiv'], 'issn': '2331-8422', 'url': 'https://arxiv.org'}, 's2Url': 'https://www.semanticscholar.org/paper/73b5b51d825a744611e782447f27dc0846069e0c', 'title': 'Understanding the LLM-ification of CHI: Unpacking the Impact of LLMs at CHI through a Systematic Literature Review', 'abstract': \"Large language models (LLMs) have been positioned to revolutionize HCI, by reshaping not only the interfaces, design patterns, and sociotechnical systems that we study, but also the research practices we use. To-date, however, there has been little understanding of LLMs' uptake in HCI. We address this gap via a systematic literature review of 153 CHI papers from 2020-24 that engage with LLMs. We taxonomize: (1) domains where LLMs are applied; (2) roles of LLMs in HCI projects; (3) contribution types; and (4) acknowledged limitations and risks. We find LLM work in 10 diverse domains, primarily via empirical and artifact contributions. Authors use LLMs in five distinct roles, including as research tools or simulated users. Still, authors often raise validity and reproducibility concerns, and overwhelmingly study closed models. We outline opportunities to improve HCI research with and on LLMs, and provide guiding questions for researchers to consider the validity and appropriateness of LLM-related work.\", 'venue': 'arXiv.org', 'year': 2025, 'referenceCount': 178, 'citationCount': 2, 'influentialCitationCount': 0, 'isOpenAccess': True, 'openAccessPdf': 'https://arxiv.org/pdf/2501.12557', 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle', 'Review'], 'publicationDate': '2025-01-22', 'journal': {'name': 'ArXiv', 'volume': 'abs/2501.12557'}, 'citationStyles': {'bibtex': '@Article{Pang2025UnderstandingTL,\\n author = {Rock Yuren Pang and Hope Schroeder and Kynnedy Simone Smith and Solon Barocas and Ziang Xiao and Emily Tseng and Danielle Bragg},\\n booktitle = {arXiv.org},\\n journal = {ArXiv},\\n title = {Understanding the LLM-ification of CHI: Unpacking the Impact of LLMs at CHI through a Systematic Literature Review},\\n volume = {abs/2501.12557},\\n year = {2025}\\n}\\n'}, 'authors': [{'authorId': '2161784423', 'name': 'Rock Yuren Pang', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2167320265', 'name': 'Hope Schroeder', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2218276228', 'name': 'Kynnedy Simone Smith', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2881033', 'name': 'Solon Barocas', 'source': ['InitialSearch', 'CitedPaper', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'cited by 10.48550/arXiv.2412.10415', 'LLM automated literature review']}, {'authorId': '2341879589', 'name': 'Ziang Xiao', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2341535817', 'name': 'Emily Tseng', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2341536310', 'name': 'Danielle Bragg', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}], 'version': '', 'arxivUrl': 'https://arxiv.org/abs/2501.12557', 'arxivId': '2501.12557', 'DOI': '10.48550/arXiv.2501.12557', 'id': '10.48550/arXiv.2501.12557', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review'], 'ref_cnt': 2, 'authors_hindex': 41}\n",
      "Understanding the LLM-ification of CHI: Unpacking the Impact of LLMs at CHI through a Systematic Literature Review\n",
      "{'type': 'node', 'id': '10.48550/arXiv.2503.01424', 'labels': ['Paper'], 'properties': {'s2PaperId': 'cdb34c0092a767848ca1de6fa7e3a6b822585fa4', 'externalIds': {'ArXiv': '2503.01424', 'CorpusId': 276775839}, 'corpusId': 276775839, 'publicationVenue': None, 's2Url': 'https://www.semanticscholar.org/paper/cdb34c0092a767848ca1de6fa7e3a6b822585fa4', 'title': 'From Hypothesis to Publication: A Comprehensive Survey of AI-Driven Research Support Systems', 'abstract': 'Research is a fundamental process driving the advancement of human civilization, yet it demands substantial time and effort from researchers. In recent years, the rapid development of artificial intelligence (AI) technologies has inspired researchers to explore how AI can accelerate and enhance research. To monitor relevant advancements, this paper presents a systematic review of the progress in this domain. Specifically, we organize the relevant studies into three main categories: hypothesis formulation, hypothesis validation, and manuscript publication. Hypothesis formulation involves knowledge synthesis and hypothesis generation. Hypothesis validation includes the verification of scientific claims, theorem proving, and experiment validation. Manuscript publication encompasses manuscript writing and the peer review process. Furthermore, we identify and discuss the current challenges faced in these areas, as well as potential future directions for research. Finally, we also offer a comprehensive overview of existing benchmarks and tools across various domains that support the integration of AI into the research process. We hope this paper serves as an introduction for beginners and fosters future research. Resources have been made publicly available at https://github.com/zkzhou126/AI-for-Research.', 'venue': '', 'year': 2025, 'referenceCount': 252, 'citationCount': 0, 'influentialCitationCount': 0, 'isOpenAccess': True, 'openAccessPdf': 'https://arxiv.org/pdf/2503.01424', 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}], 'publicationTypes': ['Review'], 'publicationDate': '2025-03-03', 'journal': None, 'citationStyles': {'bibtex': '@Inproceedings{Zhou2025FromHT,\\n author = {Zekun Zhou and Xiaocheng Feng and Lei Huang and Xiachong Feng and Ziyun Song and Ruihan Chen and Liang Zhao and Weitao Ma and Yuxuan Gu and Baoxin Wang and Dayong Wu and Guoping Hu and Ting Liu and Bing Qin},\\n title = {From Hypothesis to Publication: A Comprehensive Survey of AI-Driven Research Support Systems},\\n year = {2025}\\n}\\n'}, 'authors': [{'authorId': '2328342585', 'name': 'Zekun Zhou', 'source': ['Seed', 'CitingPaper', 'RecommendedPaper'], 'sourceDesc': ['Original seed papers', 'citing 10.48550/arXiv.2406.10252', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424']}, {'authorId': '2674998', 'name': 'Xiaocheng Feng', 'source': ['Seed', 'CitingPaper', 'RecommendedPaper'], 'sourceDesc': ['Original seed papers', 'citing 10.48550/arXiv.2406.10252', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424']}, {'authorId': '2265930173', 'name': 'Lei Huang', 'source': ['Seed', 'CitingPaper', 'RecommendedPaper'], 'sourceDesc': ['Original seed papers', 'citing 10.48550/arXiv.2406.10252', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424']}, {'authorId': '51056442', 'name': 'Xiachong Feng', 'source': ['Seed', 'CitingPaper', 'RecommendedPaper'], 'sourceDesc': ['Original seed papers', 'citing 10.48550/arXiv.2406.10252', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424']}, {'authorId': '2349068478', 'name': 'Ziyun Song', 'source': ['Seed', 'CitingPaper', 'RecommendedPaper'], 'sourceDesc': ['Original seed papers', 'citing 10.48550/arXiv.2406.10252', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424']}, {'authorId': '2337225259', 'name': 'Ruihan Chen', 'source': ['Seed', 'CitingPaper', 'RecommendedPaper'], 'sourceDesc': ['Original seed papers', 'citing 10.48550/arXiv.2406.10252', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424']}, {'authorId': '2216503559', 'name': 'Liang Zhao', 'source': ['Seed', 'CitingPaper', 'RecommendedPaper'], 'sourceDesc': ['Original seed papers', 'citing 10.48550/arXiv.2406.10252', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424']}, {'authorId': '2265878959', 'name': 'Weitao Ma', 'source': ['Seed', 'CitingPaper', 'RecommendedPaper'], 'sourceDesc': ['Original seed papers', 'citing 10.48550/arXiv.2406.10252', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424']}, {'authorId': '2112678409', 'name': 'Yuxuan Gu', 'source': ['Seed', 'CitingPaper', 'RecommendedPaper'], 'sourceDesc': ['Original seed papers', 'citing 10.48550/arXiv.2406.10252', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424']}, {'authorId': '2118640235', 'name': 'Baoxin Wang', 'source': ['Seed', 'CitingPaper', 'RecommendedPaper'], 'sourceDesc': ['Original seed papers', 'citing 10.48550/arXiv.2406.10252', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424']}, {'authorId': '2118208508', 'name': 'Dayong Wu'}, {'authorId': '2316008068', 'name': 'Guoping Hu'}, {'authorId': '2274093523', 'name': 'Ting Liu'}, {'authorId': '2257004102', 'name': 'Bing Qin'}], 'version': '', 'arxivUrl': 'https://arxiv.org/abs/2503.01424', 'arxivId': '2503.01424', 'DOI': '10.48550/arXiv.2503.01424', 'id': '10.48550/arXiv.2503.01424', 'source': ['Seed', 'CitingPaper', 'RecommendedPaper'], 'sourceDesc': ['Original seed papers', 'citing 10.48550/arXiv.2406.10252', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424']}, 'source': ['CitingPaper', 'RecommendedPaper'], 'sourceDesc': ['citing 10.48550/arXiv.2406.10252', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424'], 'ref_cnt': 3, 'authors_hindex': 38}\n",
      "From Hypothesis to Publication: A Comprehensive Survey of AI-Driven Research Support Systems\n",
      "{'type': 'node', 'id': '10.48550/arXiv.2407.16148', 'labels': ['Paper'], 'properties': {'s2PaperId': '33b8824f3c8fc3035afabaa77ecee3afe1c9753c', 'externalIds': {'DBLP': 'journals/corr/abs-2407-16148', 'ArXiv': '2407.16148', 'DOI': '10.48550/arXiv.2407.16148', 'CorpusId': 271334330}, 'corpusId': 271334330, 'publicationVenue': {'id': '1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44', 'name': 'Annual Meeting of the Association for Computational Linguistics', 'type': 'conference', 'alternate_names': ['Annu Meet Assoc Comput Linguistics', 'Meeting of the Association for Computational Linguistics', 'ACL', 'Meet Assoc Comput Linguistics'], 'url': 'https://www.aclweb.org/anthology/venues/acl/', 'source': ['InitialSearch', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2412.10415', 'LLM automated literature review']}, 's2Url': 'https://www.semanticscholar.org/paper/33b8824f3c8fc3035afabaa77ecee3afe1c9753c', 'title': 'CHIME: LLM-Assisted Hierarchical Organization of Scientific Studies for Literature Review Support', 'abstract': 'Literature review requires researchers to synthesize a large amount of information and is increasingly challenging as the scientific literature expands. In this work, we investigate the potential of LLMs for producing hierarchical organizations of scientific studies to assist researchers with literature review. We define hierarchical organizations as tree structures where nodes refer to topical categories and every node is linked to the studies assigned to that category. Our naive LLM-based pipeline for hierarchy generation from a set of studies produces promising yet imperfect hierarchies, motivating us to collect CHIME, an expert-curated dataset for this task focused on biomedicine. Given the challenging and time-consuming nature of building hierarchies from scratch, we use a human-in-the-loop process in which experts correct errors (both links between categories and study assignment) in LLM-generated hierarchies. CHIME contains 2,174 LLM-generated hierarchies covering 472 topics, and expert-corrected hierarchies for a subset of 100 topics. Expert corrections allow us to quantify LLM performance, and we find that while they are quite good at generating and organizing categories, their assignment of studies to categories could be improved. We attempt to train a corrector model with human feedback which improves study assignment by 12.6 F1 points. We release our dataset and models to encourage research on developing better assistive tools for literature review.', 'venue': 'Annual Meeting of the Association for Computational Linguistics', 'year': 2024, 'referenceCount': 41, 'citationCount': 4, 'influentialCitationCount': 1, 'isOpenAccess': True, 'openAccessPdf': 'https://arxiv.org/pdf/2407.16148', 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle', 'Conference', 'Review'], 'publicationDate': '2024-07-23', 'journal': {'name': 'ArXiv', 'volume': 'abs/2407.16148'}, 'citationStyles': {'bibtex': '@Article{Hsu2024CHIMELH,\\n author = {Chao-Chun Hsu and Erin Bransom and Jenna Sparks and Bailey Kuehl and Chenhao Tan and David Wadden and Lucy Lu Wang and Aakanksha Naik},\\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\\n journal = {ArXiv},\\n title = {CHIME: LLM-Assisted Hierarchical Organization of Scientific Studies for Literature Review Support},\\n volume = {abs/2407.16148},\\n year = {2024}\\n}\\n'}, 'authors': [{'authorId': '23608432', 'name': 'Chao-Chun Hsu', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2203427167', 'name': 'Erin Bransom', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2052201732', 'name': 'Jenna Sparks', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2003338023', 'name': 'Bailey Kuehl', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2269860394', 'name': 'Chenhao Tan', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '30051202', 'name': 'David Wadden', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '31860505', 'name': 'Lucy Lu Wang', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2275210271', 'name': 'Aakanksha Naik', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}], 'version': '', 'arxivUrl': 'https://arxiv.org/abs/2407.16148', 'arxivId': '2407.16148', 'DOI': '10.48550/arXiv.2407.16148', 'id': '10.48550/arXiv.2407.16148', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review'], 'ref_cnt': 2, 'authors_hindex': 35}\n",
      "CHIME: LLM-Assisted Hierarchical Organization of Scientific Studies for Literature Review Support\n",
      "{'type': 'node', 'id': '10.48550/arXiv.2405.01466', 'labels': ['Paper'], 'properties': {'s2PaperId': 'ad329f2e6a7302577ae255a7b78f94644817c40b', 'externalIds': {'ArXiv': '2405.01466', 'DBLP': 'journals/corr/abs-2405-01466', 'DOI': '10.48550/arXiv.2405.01466', 'CorpusId': 269502453}, 'corpusId': 269502453, 'publicationVenue': {'id': '1901e811-ee72-4b20-8f7e-de08cd395a10', 'name': 'arXiv.org', 'alternate_names': ['ArXiv'], 'issn': '2331-8422', 'url': 'https://arxiv.org'}, 's2Url': 'https://www.semanticscholar.org/paper/ad329f2e6a7302577ae255a7b78f94644817c40b', 'title': 'A Systematic Literature Review on Large Language Models for Automated Program Repair', 'abstract': 'Automated Program Repair (APR) attempts to patch software bugs and reduce manual debugging efforts. Very recently, with the advances in Large Language Models (LLMs), an increasing number of APR techniques have been proposed, facilitating software development and maintenance and demonstrating remarkable performance. However, due to ongoing explorations in the LLM-based APR field, it is challenging for researchers to understand the current achievements, challenges, and potential opportunities. This work provides the first systematic literature review to summarize the applications of LLMs in APR between 2020 and 2024. We analyze 127 relevant papers from LLMs, APR and their integration perspectives. First, we categorize existing popular LLMs that are applied to support APR and outline three types of utilization strategies for their deployment. Besides, we detail some specific repair scenarios that benefit from LLMs, e.g., semantic bugs and security vulnerabilities. Furthermore, we discuss several critical aspects of integrating LLMs into APR research, e.g., input forms and open science. Finally, we highlight a set of challenges remaining to be investigated and the potential guidelines for future research. Overall, our paper provides a systematic overview of the research landscape to the APR community, helping researchers gain a comprehensive understanding of achievements and promote future research.', 'venue': 'arXiv.org', 'year': 2024, 'referenceCount': 183, 'citationCount': 20, 'influentialCitationCount': 0, 'isOpenAccess': True, 'openAccessPdf': 'https://arxiv.org/pdf/2405.01466', 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle', 'Review'], 'publicationDate': '2024-05-02', 'journal': {'name': 'ArXiv', 'volume': 'abs/2405.01466'}, 'citationStyles': {'bibtex': '@Article{Zhang2024ASL,\\n author = {Quanjun Zhang and Chunrong Fang and Yang Xie and Yuxiang Ma and Weisong Sun and Yun Yang and Zhenyu Chen},\\n booktitle = {arXiv.org},\\n journal = {ArXiv},\\n title = {A Systematic Literature Review on Large Language Models for Automated Program Repair},\\n volume = {abs/2405.01466},\\n year = {2024}\\n}\\n'}, 'authors': [{'authorId': '1409701329', 'name': 'Quanjun Zhang', 'source': ['InitialSearch', 'LLMQuery', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review', 'LLM automated literature review']}, {'authorId': '2239197945', 'name': 'Chunrong Fang', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2276541220', 'name': 'Yang Xie', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2109179504', 'name': 'Yuxiang Ma', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '3433022', 'name': 'Weisong Sun', 'source': ['InitialSearch', 'LLMQuery', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review', 'LLM automated literature review']}, {'authorId': '2276454592', 'name': 'Yun Yang', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2238950128', 'name': 'Zhenyu Chen', 'source': ['InitialSearch', 'LLMQuery', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review', 'LLM automated literature review']}], 'version': '', 'arxivUrl': 'https://arxiv.org/abs/2405.01466', 'arxivId': '2405.01466', 'DOI': '10.48550/arXiv.2405.01466', 'id': '10.48550/arXiv.2405.01466', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review'], 'ref_cnt': 2, 'authors_hindex': 35}\n",
      "A Systematic Literature Review on Large Language Models for Automated Program Repair\n",
      "{'type': 'node', 'id': '10.48550/arXiv.2406.10252', 'labels': ['Paper'], 'properties': {'s2PaperId': '9e57dda195973c4b6c81386b1cc44595ecfd4697', 'externalIds': {'DBLP': 'conf/nips/WangGYZZ0ZD0W0Z24', 'ArXiv': '2406.10252', 'DOI': '10.48550/arXiv.2406.10252', 'CorpusId': 270560509}, 'corpusId': 270560509, 'publicationVenue': {'id': 'd9720b90-d60b-48bc-9df8-87a30b9a60dd', 'name': 'Neural Information Processing Systems', 'type': 'conference', 'alternate_names': ['Neural Inf Process Syst', 'NeurIPS', 'NIPS'], 'url': 'http://neurips.cc/', 'source': ['Seed', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'LLMQuery'], 'sourceDesc': ['Original seed papers', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2402.12928', 'cited by 10.48550/arXiv.2402.12928', 'AI research support systems']}, 's2Url': 'https://www.semanticscholar.org/paper/9e57dda195973c4b6c81386b1cc44595ecfd4697', 'title': 'AutoSurvey: Large Language Models Can Automatically Write Surveys', 'abstract': \"This paper introduces AutoSurvey, a speedy and well-organized methodology for automating the creation of comprehensive literature surveys in rapidly evolving fields like artificial intelligence. Traditional survey paper creation faces challenges due to the vast volume and complexity of information, prompting the need for efficient survey methods. While large language models (LLMs) offer promise in automating this process, challenges such as context window limitations, parametric knowledge constraints, and the lack of evaluation benchmarks remain. AutoSurvey addresses these challenges through a systematic approach that involves initial retrieval and outline generation, subsection drafting by specialized LLMs, integration and refinement, and rigorous evaluation and iteration. Our contributions include a comprehensive solution to the survey problem, a reliable evaluation method, and experimental validation demonstrating AutoSurvey's effectiveness.We open our resources at \\\\url{https://github.com/AutoSurveys/AutoSurvey}.\", 'venue': 'Neural Information Processing Systems', 'year': 2024, 'referenceCount': 54, 'citationCount': 12, 'influentialCitationCount': 1, 'isOpenAccess': True, 'openAccessPdf': 'https://arxiv.org/pdf/2406.10252', 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle', 'Review'], 'publicationDate': '2024-06-10', 'journal': {'name': 'ArXiv', 'volume': 'abs/2406.10252'}, 'citationStyles': {'bibtex': '@Article{Wang2024AutoSurveyLL,\\n author = {Yidong Wang and Qi Guo and Wenjin Yao and Hongbo Zhang and Xin Zhang and Zhen Wu and Meishan Zhang and Xinyu Dai and Min Zhang and Qingsong Wen and Wei Ye and Shikun Zhang and Yue Zhang},\\n booktitle = {Neural Information Processing Systems},\\n journal = {ArXiv},\\n title = {AutoSurvey: Large Language Models Can Automatically Write Surveys},\\n volume = {abs/2406.10252},\\n year = {2024}\\n}\\n'}, 'authors': [{'authorId': '2108024279', 'name': 'Yidong Wang', 'source': ['Seed', 'CitedPaper', 'CitedPaper', 'CitedPaper', 'CitingPaper', 'CitedPaper', 'CitedPaper'], 'sourceDesc': ['Original seed papers', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'citing 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2402.12928']}, {'authorId': '2273779175', 'name': 'Qi Guo', 'source': ['Seed', 'CitedPaper', 'CitedPaper'], 'sourceDesc': ['Original seed papers', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2402.12928']}, {'authorId': '2286328804', 'name': 'Wenjin Yao', 'source': ['Seed', 'CitedPaper', 'CitedPaper', 'CitedPaper'], 'sourceDesc': ['Original seed papers', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2402.12928']}, {'authorId': '2116271777', 'name': 'Hongbo Zhang', 'source': ['Seed', 'CitedPaper', 'CitedPaper'], 'sourceDesc': ['Original seed papers', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2402.12928']}, {'authorId': '2262020955', 'name': 'Xin Zhang', 'source': ['Seed', 'CitedPaper', 'CitedPaper'], 'sourceDesc': ['Original seed papers', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2402.12928']}, {'authorId': '2293356300', 'name': 'Zhen Wu', 'source': ['Seed', 'CitedPaper', 'CitedPaper'], 'sourceDesc': ['Original seed papers', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2402.12928']}, {'authorId': '2289004972', 'name': 'Meishan Zhang', 'source': ['Seed', 'CitedPaper', 'CitedPaper'], 'sourceDesc': ['Original seed papers', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2402.12928']}, {'authorId': '2257010530', 'name': 'Xinyu Dai', 'source': ['Seed', 'CitedPaper', 'CitedPaper'], 'sourceDesc': ['Original seed papers', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2402.12928']}, {'authorId': '2259709647', 'name': 'Min Zhang', 'source': ['Seed', 'CitedPaper', 'CitedPaper'], 'sourceDesc': ['Original seed papers', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2402.12928']}, {'authorId': '2307012818', 'name': 'Qingsong Wen', 'source': ['Seed', 'CitedPaper', 'CitedPaper'], 'sourceDesc': ['Original seed papers', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2402.12928']}, {'authorId': '2254442582', 'name': 'Wei Ye'}, {'authorId': '1705434', 'name': 'Shikun Zhang'}, {'authorId': '2250437942', 'name': 'Yue Zhang'}], 'version': '', 'arxivUrl': 'https://arxiv.org/abs/2406.10252', 'arxivId': '2406.10252', 'DOI': '10.48550/arXiv.2406.10252', 'id': '10.48550/arXiv.2406.10252', 'source': ['Seed', 'CitedPaper', 'CitedPaper'], 'sourceDesc': ['Original seed papers', 'cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2402.12928']}, 'source': ['CitedPaper', 'CitedPaper'], 'sourceDesc': ['cited by 10.48550/arXiv.2412.10415', 'cited by 10.48550/arXiv.2402.12928'], 'ref_cnt': 2, 'authors_hindex': 31}\n",
      "AutoSurvey: Large Language Models Can Automatically Write Surveys\n",
      "{'type': 'node', 'id': '10.48550/arXiv.2405.02559', 'labels': ['Paper'], 'properties': {'s2PaperId': 'a8d23d47b617f345a8fb3587d23edd83fcb53c55', 'externalIds': {'DBLP': 'journals/npjdm/TamSKSPMOWVFMCSPW24', 'PubMedCentral': '11437138', 'ArXiv': '2405.02559', 'DOI': '10.1038/s41746-024-01258-7', 'CorpusId': 269605872, 'PubMed': '39333376'}, 'corpusId': 269605872, 'publicationVenue': None, 's2Url': 'https://www.semanticscholar.org/paper/a8d23d47b617f345a8fb3587d23edd83fcb53c55', 'title': 'A framework for human evaluation of large language models in healthcare derived from literature review', 'abstract': 'With generative artificial intelligence (GenAI), particularly large language models (LLMs), continuing to make inroads in healthcare, assessing LLMs with human evaluations is essential to assuring safety and effectiveness. This study reviews existing literature on human evaluation methodologies for LLMs in healthcare across various medical specialties and addresses factors such as evaluation dimensions, sample types and sizes, selection, and recruitment of evaluators, frameworks and metrics, evaluation process, and statistical analysis type. Our literature review of 142 studies shows gaps in reliability, generalizability, and applicability of current human evaluation practices. To overcome such significant obstacles to healthcare LLM developments and deployments, we propose QUEST, a comprehensive and practical framework for human evaluation of LLMs covering three phases of workflow: Planning, Implementation and Adjudication, and Scoring and Review. QUEST is designed with five proposed evaluation principles: Quality of Information, Understanding and Reasoning, Expression Style and Persona, Safety and Harm, and Trust and Confidence.', 'venue': 'npj Digit. Medicine', 'year': 2024, 'referenceCount': 110, 'citationCount': 15, 'influentialCitationCount': 0, 'isOpenAccess': True, 'openAccessPdf': 'https://arxiv.org/pdf/2405.02559', 'fieldsOfStudy': ['Medicine', 'Computer Science'], 's2FieldsOfStudy': [{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle', 'Review'], 'publicationDate': '2024-05-04', 'journal': {'name': 'NPJ Digital Medicine', 'volume': '7'}, 'citationStyles': {'bibtex': '@Article{Tam2024AFF,\\n author = {Thomas Yu Chow Tam and Sonish Sivarajkumar and S. Kapoor and Alisa V Stolyar and Katelyn Polanska and Karleigh R McCarthy and Hunter Osterhoudt and Xizhi Wu and Shyam Visweswaran and S. Fu and Piyush Mathur and Giovanni E. Cacciamani and Cong Sun and Yifan Peng and Yanshan Wang},\\n booktitle = {npj Digit. Medicine},\\n journal = {NPJ Digital Medicine},\\n title = {A framework for human evaluation of large language models in healthcare derived from literature review},\\n volume = {7},\\n year = {2024}\\n}\\n'}, 'authors': [{'authorId': '2291923131', 'name': 'Thomas Yu Chow Tam', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2158366736', 'name': 'Sonish Sivarajkumar', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '49244137', 'name': 'S. Kapoor', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2300097837', 'name': 'Alisa V Stolyar', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2280147434', 'name': 'Katelyn Polanska', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2300098342', 'name': 'Karleigh R McCarthy', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2184774326', 'name': 'Hunter Osterhoudt', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2280196831', 'name': 'Xizhi Wu', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2280965329', 'name': 'Shyam Visweswaran', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '145097134', 'name': 'S. Fu', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2140146392', 'name': 'Piyush Mathur'}, {'authorId': '2275807580', 'name': 'Giovanni E. Cacciamani'}, {'authorId': '2300133659', 'name': 'Cong Sun'}, {'authorId': '2300197324', 'name': 'Yifan Peng'}, {'authorId': '2274069026', 'name': 'Yanshan Wang'}], 'version': '', 'arxivUrl': 'https://arxiv.org/abs/2405.02559', 'arxivId': '2405.02559', 'DOI': '10.1038/s41746-024-01258-7', 'id': '10.48550/arXiv.2405.02559', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review'], 'ref_cnt': 2, 'authors_hindex': 30}\n",
      "A framework for human evaluation of large language models in healthcare derived from literature review\n",
      "{'type': 'node', 'id': '10.48550/arXiv.2404.02525', 'labels': ['Paper'], 'properties': {'s2PaperId': '5a440c1a3d9e955450a73938181a8321db0ee060', 'externalIds': {'ArXiv': '2404.02525', 'DBLP': 'journals/corr/abs-2404-02525', 'DOI': '10.48550/arXiv.2404.02525', 'CorpusId': 268876353}, 'corpusId': 268876353, 'publicationVenue': {'id': '0730105a-4941-449f-9450-28cba8ae056b', 'name': 'ACM Transactions on Software Engineering and Methodology', 'type': 'journal', 'alternate_names': ['ACM Trans Softw Eng Methodol'], 'issn': '1049-331X', 'url': 'http://www.acm.org/pubs/contents/journals/tosem/', 'alternate_urls': ['https://tosem.acm.org/', 'http://tosem.acm.org/', 'http://www.acm.org/pubs/tosem/', 'http://portal.acm.org/tosem'], 'source': ['InitialSearch'], 'sourceDesc': ['Search from S2 based on user input']}, 's2Url': 'https://www.semanticscholar.org/paper/5a440c1a3d9e955450a73938181a8321db0ee060', 'title': 'Large Language Model for Vulnerability Detection and Repair: Literature Review and the Road Ahead', 'abstract': 'The significant advancements in Large Language Models (LLMs) have resulted in their widespread adoption across various tasks within Software Engineering (SE), including vulnerability detection and repair. Numerous studies have investigated the application of LLMs to enhance vulnerability detection and repair tasks. Despite the increasing research interest, there is currently no existing survey that focuses on the utilization of LLMs for vulnerability detection and repair. In this paper, we aim to bridge this gap by offering a systematic literature review of approaches aimed at improving vulnerability detection and repair through the utilization of LLMs. The review encompasses research work from leading SE, AI, and Security conferences and journals, encompassing 43 papers published across 25 distinct venues, along with 15 high-quality preprint papers, bringing the total to 58 papers. By answering three key research questions, we aim to (1) summarize the LLMs employed in the relevant literature, (2) categorize various LLM adaptation techniques in vulnerability detection, and (3) classify various LLM adaptation techniques in vulnerability repair. Based on our findings, we have identified a series of limitations of existing studies. Additionally, we have outlined a roadmap highlighting potential opportunities that we believe are pertinent and crucial for future research endeavors.', 'venue': 'ACM Transactions on Software Engineering and Methodology', 'year': 2024, 'referenceCount': 122, 'citationCount': 8, 'influentialCitationCount': 0, 'isOpenAccess': True, 'openAccessPdf': 'https://arxiv.org/pdf/2404.02525', 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle', 'Review'], 'publicationDate': '2024-04-03', 'journal': {'name': 'ArXiv', 'volume': 'abs/2404.02525'}, 'citationStyles': {'bibtex': '@Article{Zhou2024LargeLM,\\n author = {Xin Zhou and Sicong Cao and Xiaobing Sun and David Lo},\\n booktitle = {ACM Transactions on Software Engineering and Methodology},\\n journal = {ArXiv},\\n title = {Large Language Model for Vulnerability Detection and Repair: Literature Review and the Road Ahead},\\n volume = {abs/2404.02525},\\n year = {2024}\\n}\\n'}, 'authors': [{'authorId': '2148928671', 'name': 'Xin Zhou', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2109519289', 'name': 'Sicong Cao', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2146085643', 'name': 'Xiaobing Sun', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2292590742', 'name': 'David Lo', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}], 'version': '', 'arxivUrl': 'https://arxiv.org/abs/2404.02525', 'arxivId': '2404.02525', 'DOI': '10.48550/arXiv.2404.02525', 'id': '10.48550/arXiv.2404.02525', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review'], 'ref_cnt': 2, 'authors_hindex': 29}\n",
      "Large Language Model for Vulnerability Detection and Repair: Literature Review and the Road Ahead\n",
      "{'type': 'node', 'id': '10.48550/arXiv.2403.02574', 'labels': ['Paper'], 'properties': {'s2PaperId': '258a9c9ff34b1739e701d25ae277a412c47aa7dd', 'externalIds': {'DBLP': 'journals/corr/abs-2403-02574', 'ArXiv': '2403.02574', 'DOI': '10.48550/arXiv.2403.02574', 'CorpusId': 268248855}, 'corpusId': 268248855, 'publicationVenue': {'id': 'f51ff783-cdff-4e22-94fb-28e6336d17b3', 'name': 'International Conference on Computational Linguistics', 'type': 'conference', 'alternate_names': ['Int Conf Comput Linguistics', 'COLING'], 'url': 'https://www.aclweb.org/anthology/venues/coling/', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, 's2Url': 'https://www.semanticscholar.org/paper/258a9c9ff34b1739e701d25ae277a412c47aa7dd', 'title': 'ChatCite: LLM Agent with Human Workflow Guidance for Comparative Literature Summary', 'abstract': 'The literature review is an indispensable step in the research process. It provides the benefit of comprehending the research problem and understanding the current research situation while conducting a comparative analysis of prior works. However, literature summary is challenging and time consuming. The previous LLM-based studies on literature review mainly focused on the complete process, including literature retrieval, screening, and summarization. However, for the summarization step, simple CoT method often lacks the ability to provide extensive comparative summary. In this work, we firstly focus on the independent literature summarization step and introduce ChatCite, an LLM agent with human workflow guidance for comparative literature summary. This agent, by mimicking the human workflow, first extracts key elements from relevant literature and then generates summaries using a Reflective Incremental Mechanism. In order to better evaluate the quality of the generated summaries, we devised a LLM-based automatic evaluation metric, G-Score, in refer to the human evaluation criteria. The ChatCite agent outperformed other models in various dimensions in the experiments. The literature summaries generated by ChatCite can also be directly used for drafting literature reviews.', 'venue': 'International Conference on Computational Linguistics', 'year': 2024, 'referenceCount': 17, 'citationCount': 11, 'influentialCitationCount': 0, 'isOpenAccess': True, 'openAccessPdf': 'https://arxiv.org/pdf/2403.02574', 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle', 'Conference', 'Review'], 'publicationDate': '2024-03-05', 'journal': {'pages': '3613-3630'}, 'citationStyles': {'bibtex': '@Article{Li2024ChatCiteLA,\\n author = {Yutong Li and Lu Chen and Aiwei Liu and Kai Yu and Lijie Wen},\\n booktitle = {International Conference on Computational Linguistics},\\n pages = {3613-3630},\\n title = {ChatCite: LLM Agent with Human Workflow Guidance for Comparative Literature Summary},\\n year = {2024}\\n}\\n'}, 'authors': [{'authorId': '2290025036', 'name': 'Yutong Li', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2290061713', 'name': 'Lu Chen', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '10017193', 'name': 'Aiwei Liu', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2290937590', 'name': 'Kai Yu', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2284684419', 'name': 'Lijie Wen', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}], 'version': '', 'arxivUrl': 'https://arxiv.org/abs/2403.02574', 'arxivId': '2403.02574', 'DOI': '10.48550/arXiv.2403.02574', 'id': '10.48550/arXiv.2403.02574', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review'], 'ref_cnt': 2, 'authors_hindex': 22}\n",
      "ChatCite: LLM Agent with Human Workflow Guidance for Comparative Literature Summary\n",
      "{'type': 'node', 'id': '10.48550/arXiv.2503.08569', 'labels': ['Paper'], 'properties': {'s2PaperId': '60c8a127e6ae8c8e21dd7edfc187ff7f0d9ae2bd', 'externalIds': {'ArXiv': '2503.08569', 'CorpusId': 276929065}, 'corpusId': 276929065, 'publicationVenue': None, 's2Url': 'https://www.semanticscholar.org/paper/60c8a127e6ae8c8e21dd7edfc187ff7f0d9ae2bd', 'title': 'DeepReview: Improving LLM-based Paper Review with Human-like Deep Thinking Process', 'abstract': 'Large Language Models (LLMs) are increasingly utilized in scientific research assessment, particularly in automated paper review. However, existing LLM-based review systems face significant challenges, including limited domain expertise, hallucinated reasoning, and a lack of structured evaluation. To address these limitations, we introduce DeepReview, a multi-stage framework designed to emulate expert reviewers by incorporating structured analysis, literature retrieval, and evidence-based argumentation. Using DeepReview-13K, a curated dataset with structured annotations, we train DeepReviewer-14B, which outperforms CycleReviewer-70B with fewer tokens. In its best mode, DeepReviewer-14B achieves win rates of 88.21\\\\% and 80.20\\\\% against GPT-o1 and DeepSeek-R1 in evaluations. Our work sets a new benchmark for LLM-based paper review, with all resources publicly available. The code, model, dataset and demo have be released in http://ai-researcher.net.', 'venue': '', 'year': 2025, 'referenceCount': 65, 'citationCount': 0, 'influentialCitationCount': 0, 'isOpenAccess': True, 'openAccessPdf': 'https://arxiv.org/pdf/2503.08569', 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}], 'publicationTypes': ['Review'], 'publicationDate': '2025-03-11', 'journal': None, 'citationStyles': {'bibtex': '@Inproceedings{Zhu2025DeepReviewIL,\\n author = {Minjun Zhu and Yixuan Weng and Linyi Yang and Yue Zhang},\\n title = {DeepReview: Improving LLM-based Paper Review with Human-like Deep Thinking Process},\\n year = {2025}\\n}\\n'}, 'authors': [{'authorId': '2316827669', 'name': 'Minjun Zhu', 'source': ['InitialSearch', 'CitingPaper', 'RecommendedPaper', 'LLMQuery', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'citing 10.48550/arXiv.2406.10252', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424', 'LLM automated literature review', 'LLM automated literature review']}, {'authorId': '2349585725', 'name': 'Yixuan Weng', 'source': ['InitialSearch', 'RecommendedPaper', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424', 'LLM automated literature review']}, {'authorId': '2145500840', 'name': 'Linyi Yang', 'source': ['InitialSearch', 'CitedPaper', 'CitedPaper', 'CitingPaper', 'RecommendedPaper', 'RecommendedPaper', 'LLMQuery', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'cited by 10.48550/arXiv.2406.10252', 'cited by 10.48550/arXiv.2406.10252', 'citing 10.48550/arXiv.2406.10252', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424', 'LLM automated literature review', 'LLM automated literature review']}, {'authorId': '2325943212', 'name': 'Yue Zhang', 'source': ['InitialSearch', 'CitingPaper', 'CitingPaper', 'RecommendedPaper', 'LLMQuery', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'citing 10.48550/arXiv.2406.10252', 'citing 10.48550/arXiv.2406.10252', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424', 'LLM automated literature review', 'LLM automated literature review']}], 'version': '', 'arxivUrl': 'https://arxiv.org/abs/2503.08569', 'arxivId': '2503.08569', 'DOI': '10.48550/arXiv.2503.08569', 'id': '10.48550/arXiv.2503.08569', 'source': ['InitialSearch', 'RecommendedPaper', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424', 'LLM automated literature review']}, 'source': ['RecommendedPaper', 'LLMQuery'], 'sourceDesc': ['recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424', 'LLM automated literature review'], 'ref_cnt': 3, 'authors_hindex': 19}\n",
      "DeepReview: Improving LLM-based Paper Review with Human-like Deep Thinking Process\n",
      "{'type': 'node', 'id': '10.48550/arXiv.2405.04760', 'labels': ['Paper'], 'properties': {'s2PaperId': 'db6ca4fe83e22a1a3a95761e62fe072460ee6d1c', 'externalIds': {'ArXiv': '2405.04760', 'DBLP': 'journals/corr/abs-2405-04760', 'DOI': '10.48550/arXiv.2405.04760', 'CorpusId': 269626255}, 'corpusId': 269626255, 'publicationVenue': {'id': '1901e811-ee72-4b20-8f7e-de08cd395a10', 'name': 'arXiv.org', 'alternate_names': ['ArXiv'], 'issn': '2331-8422', 'url': 'https://arxiv.org'}, 's2Url': 'https://www.semanticscholar.org/paper/db6ca4fe83e22a1a3a95761e62fe072460ee6d1c', 'title': 'Large Language Models for Cyber Security: A Systematic Literature Review', 'abstract': 'The rapid advancement of Large Language Models (LLMs) has opened up new opportunities for leveraging artificial intelligence in various domains, including cybersecurity. As the volume and sophistication of cyber threats continue to grow, there is an increasing need for intelligent systems that can automatically detect vulnerabilities, analyze malware, and respond to attacks. In this survey, we conduct a comprehensive review of the literature on the application of LLMs in cybersecurity (LLM4Security). By comprehensively collecting over 30K relevant papers and systematically analyzing 127 papers from top security and software engineering venues, we aim to provide a holistic view of how LLMs are being used to solve diverse problems across the cybersecurity domain. Through our analysis, we identify several key findings. First, we observe that LLMs are being applied to a wide range of cybersecurity tasks, including vulnerability detection, malware analysis, network intrusion detection, and phishing detection. Second, we find that the datasets used for training and evaluating LLMs in these tasks are often limited in size and diversity, highlighting the need for more comprehensive and representative datasets. Third, we identify several promising techniques for adapting LLMs to specific cybersecurity domains, such as fine-tuning, transfer learning, and domain-specific pre-training. Finally, we discuss the main challenges and opportunities for future research in LLM4Security, including the need for more interpretable and explainable models, the importance of addressing data privacy and security concerns, and the potential for leveraging LLMs for proactive defense and threat hunting. Overall, our survey provides a comprehensive overview of the current state-of-the-art in LLM4Security and identifies several promising directions for future research.', 'venue': 'arXiv.org', 'year': 2024, 'referenceCount': 230, 'citationCount': 19, 'influentialCitationCount': 1, 'isOpenAccess': True, 'openAccessPdf': 'https://arxiv.org/pdf/2405.04760', 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle', 'Review'], 'publicationDate': '2024-05-08', 'journal': {'name': 'ArXiv', 'volume': 'abs/2405.04760'}, 'citationStyles': {'bibtex': '@Article{Xu2024LargeLM,\\n author = {Hanxiang Xu and Shenao Wang and Ningke Li and Kailong Wang and Yanjie Zhao and Kai Chen and Ting Yu and Yang Liu and Haoyu Wang},\\n booktitle = {arXiv.org},\\n journal = {ArXiv},\\n title = {Large Language Models for Cyber Security: A Systematic Literature Review},\\n volume = {abs/2405.04760},\\n year = {2024}\\n}\\n'}, 'authors': [{'authorId': '2300487835', 'name': 'Hanxiang Xu', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '2265946266', 'name': 'Shenao Wang', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '2177447932', 'name': 'Ningke Li', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '2265727621', 'name': 'Kailong Wang', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '2268172135', 'name': 'Yanjie Zhao', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '2300368154', 'name': 'Kai Chen', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '2300996607', 'name': 'Ting Yu', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '2277257260', 'name': 'Yang Liu', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '2297724844', 'name': 'Haoyu Wang', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}], 'version': '', 'arxivUrl': 'https://arxiv.org/abs/2405.04760', 'arxivId': '2405.04760', 'DOI': '10.48550/arXiv.2405.04760', 'id': '10.48550/arXiv.2405.04760', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, 'ref_cnt': 1, 'authors_hindex': 19}\n",
      "Large Language Models for Cyber Security: A Systematic Literature Review\n",
      "{'type': 'node', 'id': '10.48550/arXiv.2404.04834', 'labels': ['Paper'], 'properties': {'s2PaperId': '027d9a3371c13ea567bca75e675db295022a300b', 'externalIds': {'ArXiv': '2404.04834', 'DOI': '10.1145/3712003', 'CorpusId': 274965784}, 'corpusId': 274965784, 'publicationVenue': {'id': '0730105a-4941-449f-9450-28cba8ae056b', 'name': 'ACM Transactions on Software Engineering and Methodology', 'type': 'journal', 'alternate_names': ['ACM Trans Softw Eng Methodol'], 'issn': '1049-331X', 'url': 'http://www.acm.org/pubs/contents/journals/tosem/', 'alternate_urls': ['https://tosem.acm.org/', 'http://tosem.acm.org/', 'http://www.acm.org/pubs/tosem/', 'http://portal.acm.org/tosem'], 'source': ['InitialSearch', 'LLMQuery', 'LLMQuery', 'LLMQuery', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review', 'LLM automated literature review', 'LLM automated literature review', 'evaluation of AI-generated reviews']}, 's2Url': 'https://www.semanticscholar.org/paper/027d9a3371c13ea567bca75e675db295022a300b', 'title': 'LLM-Based Multi-Agent Systems for Software Engineering: Literature Review, Vision and the Road Ahead', 'abstract': 'Integrating Large Language Models (LLMs) into autonomous agents marks a significant shift in the research landscape by offering cognitive abilities that are competitive with human planning and reasoning. This paper explores the transformative potential of integrating Large Language Models into Multi-Agent (LMA) systems for addressing complex challenges in software engineering (SE). By leveraging the collaborative and specialized abilities of multiple agents, LMA systems enable autonomous problem-solving, improve robustness, and provide scalable solutions for managing the complexity of real-world software projects. In this paper, we conduct a systematic review of recent primary studies to map the current landscape of LMA applications across various stages of the software development lifecycle (SDLC). To illustrate current capabilities and limitations, we perform two case studies to demonstrate the effectiveness of state-of-the-art LMA frameworks. Additionally, we identify critical research gaps and propose a comprehensive research agenda focused on enhancing individual agent capabilities and optimizing agent synergy. Our work outlines a forward-looking vision for developing fully autonomous, scalable, and trustworthy LMA systems, laying the foundation for the evolution of Software Engineering 2.0.', 'venue': 'ACM Transactions on Software Engineering and Methodology', 'year': 2024, 'referenceCount': 170, 'citationCount': 2, 'influentialCitationCount': 0, 'isOpenAccess': True, 'openAccessPdf': 'https://arxiv.org/pdf/2404.04834', 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Engineering', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle', 'Review'], 'publicationDate': '2024-04-07', 'journal': {'name': 'ACM Transactions on Software Engineering and Methodology'}, 'citationStyles': {'bibtex': '@Article{He2024LLMBasedMS,\\n author = {Junda He and Christoph Treude and David Lo},\\n booktitle = {ACM Transactions on Software Engineering and Methodology},\\n journal = {ACM Transactions on Software Engineering and Methodology},\\n title = {LLM-Based Multi-Agent Systems for Software Engineering: Literature Review, Vision and the Road Ahead},\\n year = {2024}\\n}\\n'}, 'authors': [{'authorId': '2158107537', 'name': 'Junda He', 'source': ['InitialSearch', 'RecommendedPaper', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424', 'LLM automated literature review']}, {'authorId': '2257011464', 'name': 'Christoph Treude', 'source': ['InitialSearch', 'RecommendedPaper', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424', 'LLM automated literature review']}, {'authorId': '2275193225', 'name': 'David Lo', 'source': ['InitialSearch', 'RecommendedPaper', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'recommended by s2 given papers 10.48550/arXiv.2406.10252,10.48550/arXiv.2412.10415,10.48550/arXiv.2402.12928,10.48550/arXiv.2503.01424', 'LLM automated literature review']}], 'version': '', 'arxivUrl': 'https://arxiv.org/abs/2404.04834', 'arxivId': '2404.04834', 'DOI': '10.1145/3712003', 'id': '10.48550/arXiv.2404.04834', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review'], 'ref_cnt': 2, 'authors_hindex': 15}\n",
      "LLM-Based Multi-Agent Systems for Software Engineering: Literature Review, Vision and the Road Ahead\n",
      "{'type': 'node', 'id': '10.48550/arXiv.2310.17526', 'labels': ['Paper'], 'properties': {'s2PaperId': '70813142dcee9fd455b0f587153e21deaf7b8005', 'externalIds': {'ArXiv': '2310.17526', 'DBLP': 'journals/corr/abs-2310-17526', 'DOI': '10.1002/jrsm.1715', 'CorpusId': 264490974, 'PubMed': '38484744'}, 'corpusId': 264490974, 'publicationVenue': {'id': '677c9577-156b-4396-a0ea-3fa9d8038443', 'name': 'Research Synthesis Methods', 'type': 'journal', 'alternate_names': ['Res Synth Method'], 'issn': '1759-2879', 'url': 'http://onlinelibrary.wiley.com/journal/10.1002/(ISSN)1759-2887', 'alternate_urls': ['https://onlinelibrary.wiley.com/journal/17592887'], 'source': ['InitialSearch'], 'sourceDesc': ['Search from S2 based on user input']}, 's2Url': 'https://www.semanticscholar.org/paper/70813142dcee9fd455b0f587153e21deaf7b8005', 'title': \"Can large language models replace humans in the systematic review process? Evaluating GPT-4's efficacy in screening and extracting data from peer-reviewed and grey literature in multiple languages\", 'abstract': 'Systematic reviews are vital for guiding practice, research and policy, although they are often slow and labour-intensive. Large language models (LLMs) could speed up and automate systematic reviews, but their performance in such tasks has yet to be comprehensively evaluated against humans, and no study has tested Generative Pre-Trained Transformer (GPT)-4, the biggest LLM so far. This pre-registered study uses a \"human-out-of-the-loop\" approach to evaluate GPT-4\\'s capability in title/abstract screening, full-text review and data extraction across various literature types and languages. Although GPT-4 had accuracy on par with human performance in some tasks, results were skewed by chance agreement and dataset imbalance. Adjusting for these caused performance scores to drop across all stages: for data extraction, performance was moderate, and for screening, it ranged from none in highly balanced literature datasets (~1:1) to moderate in those datasets where the ratio of inclusion to exclusion in studies was imbalanced (~1:3). When screening full-text literature using highly reliable prompts, GPT-4\\'s performance was more robust, reaching \"human-like\" levels. Although our findings indicate that, currently, substantial caution should be exercised if LLMs are being used to conduct systematic reviews, they also offer preliminary evidence that, for certain review tasks delivered under specific conditions, LLMs can rival human performance.', 'venue': 'Research Synthesis Methods', 'year': 2023, 'referenceCount': 40, 'citationCount': 51, 'influentialCitationCount': 1, 'isOpenAccess': True, 'openAccessPdf': 'https://arxiv.org/pdf/2310.17526', 'fieldsOfStudy': ['Computer Science', 'Medicine'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}, {'category': 'Medicine', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle', 'Review'], 'publicationDate': '2023-10-26', 'journal': {'name': 'Research synthesis methods'}, 'citationStyles': {'bibtex': \"@Article{Khraisha2023CanLL,\\n author = {Qusai Khraisha and Sophie Put and Johanna Kappenberg and Azza Warraitch and Kristin Hadfield},\\n booktitle = {Research Synthesis Methods},\\n journal = {Research synthesis methods},\\n title = {Can large language models replace humans in the systematic review process? Evaluating GPT-4's efficacy in screening and extracting data from peer-reviewed and grey literature in multiple languages},\\n year = {2023}\\n}\\n\"}, 'authors': [{'authorId': '2219501303', 'name': 'Qusai Khraisha', 'source': ['InitialSearch'], 'sourceDesc': ['Search from S2 based on user input']}, {'authorId': '2261739261', 'name': 'Sophie Put', 'source': ['InitialSearch'], 'sourceDesc': ['Search from S2 based on user input']}, {'authorId': '2261738184', 'name': 'Johanna Kappenberg', 'source': ['InitialSearch'], 'sourceDesc': ['Search from S2 based on user input']}, {'authorId': '1907502938', 'name': 'Azza Warraitch', 'source': ['InitialSearch'], 'sourceDesc': ['Search from S2 based on user input']}, {'authorId': '2261740395', 'name': 'Kristin Hadfield', 'source': ['InitialSearch'], 'sourceDesc': ['Search from S2 based on user input']}], 'version': '', 'arxivUrl': 'https://arxiv.org/abs/2310.17526', 'arxivId': '2310.17526', 'DOI': '10.1002/jrsm.1715', 'id': '10.48550/arXiv.2310.17526', 'source': ['InitialSearch'], 'sourceDesc': ['Search from S2 based on user input']}, 'ref_cnt': 1, 'authors_hindex': 15}\n",
      "Can large language models replace humans in the systematic review process? Evaluating GPT-4's efficacy in screening and extracting data from peer-reviewed and grey literature in multiple languages\n",
      "{'type': 'node', 'id': '10.48550/arXiv.2411.02451', 'labels': ['Paper'], 'properties': {'s2PaperId': '75a25dc3dcddb1d0654215de983684f8640b3217', 'externalIds': {'DBLP': 'journals/corr/abs-2411-02451', 'ArXiv': '2411.02451', 'DOI': '10.48550/arXiv.2411.02451', 'CorpusId': 273821440}, 'corpusId': 273821440, 'publicationVenue': {'id': '1901e811-ee72-4b20-8f7e-de08cd395a10', 'name': 'arXiv.org', 'alternate_names': ['ArXiv'], 'issn': '2331-8422', 'url': 'https://arxiv.org'}, 's2Url': 'https://www.semanticscholar.org/paper/75a25dc3dcddb1d0654215de983684f8640b3217', 'title': 'High-performance automated abstract screening with large language model ensembles', 'abstract': 'Large language models (LLMs) excel in tasks requiring processing and interpretation of input text. Abstract screening is a labour-intensive component of systematic review involving repetitive application of inclusion and exclusion criteria on a large volume of studies identified by a literature search. Here, LLMs (GPT-3.5 Turbo, GPT-4 Turbo, GPT-4o, Llama 3 70B, Gemini 1.5 Pro, and Claude Sonnet 3.5) were trialled on systematic reviews in a full issue of the Cochrane Library to evaluate their accuracy in zero-shot binary classification for abstract screening. Trials over a subset of 800 records identified optimal prompting strategies and demonstrated superior performance of LLMs to human researchers in terms of sensitivity (LLM-max = 1.000, human-max = 0.775), precision (LLM-max = 0.927, human-max = 0.911), and balanced accuracy (LLM-max = 0.904, human-max = 0.865). The best performing LLM-prompt combinations were trialled across every replicated search result (n = 119,691), and exhibited consistent sensitivity (range 0.756-1.000) but diminished precision (range 0.004-0.096). 66 LLM-human and LLM-LLM ensembles exhibited perfect sensitivity with a maximal precision of 0.458, with less observed performance drop in larger trials. Significant variation in performance was observed between reviews, highlighting the importance of domain-specific validation before deployment. LLMs may reduce the human labour cost of systematic review with maintained or improved accuracy and sensitivity. Systematic review is the foundation of evidence synthesis across academic disciplines, including evidence-based medicine, and LLMs may increase the efficiency and quality of this mode of research.', 'venue': 'arXiv.org', 'year': 2024, 'referenceCount': 0, 'citationCount': 0, 'influentialCitationCount': 0, 'isOpenAccess': True, 'openAccessPdf': 'https://arxiv.org/pdf/2411.02451', 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle', 'Review'], 'publicationDate': '2024-11-03', 'journal': {'name': 'ArXiv', 'volume': 'abs/2411.02451'}, 'citationStyles': {'bibtex': '@Article{Sanghera2024HighperformanceAA,\\n author = {Rohan Sanghera and Arun J. Thirunavukarasu and Marc El Khoury and Jessica O’Logbon and Yuqing Chen and Archie Watt and Mustafa Mahmood and Hamid Butt and George Nishimura and Andrew Soltan},\\n booktitle = {arXiv.org},\\n journal = {ArXiv},\\n title = {High-performance automated abstract screening with large language model ensembles},\\n volume = {abs/2411.02451},\\n year = {2024}\\n}\\n'}, 'authors': [{'authorId': '1436263785', 'name': 'Rohan Sanghera', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '2297151474', 'name': 'Arun J. Thirunavukarasu', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '2238458693', 'name': 'Marc El Khoury', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '1729260216', 'name': 'Jessica O’Logbon', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '2329310395', 'name': 'Yuqing Chen', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '2329185741', 'name': 'Archie Watt', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '2329186535', 'name': 'Mustafa Mahmood', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '2329186287', 'name': 'Hamid Butt', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '2329185225', 'name': 'George Nishimura', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '2329184057', 'name': 'Andrew Soltan', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}], 'version': '', 'arxivUrl': 'https://arxiv.org/abs/2411.02451', 'arxivId': '2411.02451', 'DOI': '10.48550/arXiv.2411.02451', 'id': '10.48550/arXiv.2411.02451', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, 'ref_cnt': 1, 'authors_hindex': 13}\n",
      "High-performance automated abstract screening with large language model ensembles\n",
      "{'type': 'node', 'id': '10.48550/arXiv.2407.20906', 'labels': ['Paper'], 'properties': {'s2PaperId': 'fdee3c8d37f99514d4044ad1bbabc28bd2af9cb6', 'externalIds': {'DBLP': 'journals/corr/abs-2407-20906', 'ArXiv': '2407.20906', 'DOI': '10.48550/arXiv.2407.20906', 'CorpusId': 271544398}, 'corpusId': 271544398, 'publicationVenue': {'id': '1901e811-ee72-4b20-8f7e-de08cd395a10', 'name': 'arXiv.org', 'alternate_names': ['ArXiv'], 'issn': '2331-8422', 'url': 'https://arxiv.org'}, 's2Url': 'https://www.semanticscholar.org/paper/fdee3c8d37f99514d4044ad1bbabc28bd2af9cb6', 'title': 'Automated Review Generation Method Based on Large Language Models', 'abstract': \"Literature research, vital for scientific work, faces the challenge of surging information volumes exceeding researchers' processing capabilities. We present an automated review generation method based on large language models (LLMs) to overcome efficiency bottlenecks and reduce cognitive load. Our statistically validated evaluation framework demonstrates that the generated reviews match or exceed manual quality, offering broad applicability across research fields without requiring users' domain knowledge. Applied to propane dehydrogenation (PDH) catalysts, our method swiftly analyzed 343 articles, averaging seconds per article per LLM account, producing comprehensive reviews spanning 35 topics, with extended analysis of 1041 articles providing insights into catalysts' properties. Through multi-layered quality control, we effectively mitigated LLMs' hallucinations, with expert verification confirming accuracy and citation integrity while demonstrating hallucination risks reduced to below 0.5\\\\% with 95\\\\% confidence. Released Windows application enables one-click review generation, enhancing research productivity and literature recommendation efficiency while setting the stage for broader scientific explorations.\", 'venue': 'arXiv.org', 'year': 2024, 'referenceCount': 79, 'citationCount': 0, 'influentialCitationCount': 0, 'isOpenAccess': True, 'openAccessPdf': 'https://arxiv.org/pdf/2407.20906', 'fieldsOfStudy': ['Computer Science', 'Physics'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Chemistry', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle', 'Review'], 'publicationDate': '2024-07-30', 'journal': {'name': 'ArXiv', 'volume': 'abs/2407.20906'}, 'citationStyles': {'bibtex': '@Article{Wu2024AutomatedRG,\\n author = {Shican Wu and Xiao Ma and Dehui Luo and Lulu Li and Xiangcheng Shi and Xin Chang and Xiaoyun Lin and Ran Luo and Chunlei Pei and Zhijian Zhao and Jinlong Gong},\\n booktitle = {arXiv.org},\\n journal = {ArXiv},\\n title = {Automated Review Generation Method Based on Large Language Models},\\n volume = {abs/2407.20906},\\n year = {2024}\\n}\\n'}, 'authors': [{'authorId': '2142349414', 'name': 'Shican Wu', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '2313884864', 'name': 'Xiao Ma', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '2313733635', 'name': 'Dehui Luo', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '2277565237', 'name': 'Lulu Li', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '2289200637', 'name': 'Xiangcheng Shi', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '2289200103', 'name': 'Xin Chang', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '2152842807', 'name': 'Xiaoyun Lin', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '2075340202', 'name': 'Ran Luo', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '48471690', 'name': 'Chunlei Pei', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '12144921', 'name': 'Zhijian Zhao', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '2258427381', 'name': 'Jinlong Gong'}], 'version': '', 'arxivUrl': 'https://arxiv.org/abs/2407.20906', 'arxivId': '2407.20906', 'DOI': '10.48550/arXiv.2407.20906', 'id': '10.48550/arXiv.2407.20906', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, 'ref_cnt': 1, 'authors_hindex': 10}\n",
      "Automated Review Generation Method Based on Large Language Models\n",
      "{'type': 'node', 'id': '10.48550/arXiv.2402.10350', 'labels': ['Paper'], 'properties': {'s2PaperId': 'ce7a2ea8774b996e7022b3bd712c13b75365fc96', 'externalIds': {'ArXiv': '2402.10350', 'DBLP': 'journals/corr/abs-2402-10350', 'DOI': '10.48550/arXiv.2402.10350', 'CorpusId': 267740683}, 'corpusId': 267740683, 'publicationVenue': {'id': '1901e811-ee72-4b20-8f7e-de08cd395a10', 'name': 'arXiv.org', 'alternate_names': ['ArXiv'], 'issn': '2331-8422', 'url': 'https://arxiv.org'}, 's2Url': 'https://www.semanticscholar.org/paper/ce7a2ea8774b996e7022b3bd712c13b75365fc96', 'title': 'Large Language Models for Forecasting and Anomaly Detection: A Systematic Literature Review', 'abstract': \"This systematic literature review comprehensively examines the application of Large Language Models (LLMs) in forecasting and anomaly detection, highlighting the current state of research, inherent challenges, and prospective future directions. LLMs have demonstrated significant potential in parsing and analyzing extensive datasets to identify patterns, predict future events, and detect anomalous behavior across various domains. However, this review identifies several critical challenges that impede their broader adoption and effectiveness, including the reliance on vast historical datasets, issues with generalizability across different contexts, the phenomenon of model hallucinations, limitations within the models' knowledge boundaries, and the substantial computational resources required. Through detailed analysis, this review discusses potential solutions and strategies to overcome these obstacles, such as integrating multimodal data, advancements in learning methodologies, and emphasizing model explainability and computational efficiency. Moreover, this review outlines critical trends that are likely to shape the evolution of LLMs in these fields, including the push toward real-time processing, the importance of sustainable modeling practices, and the value of interdisciplinary collaboration. Conclusively, this review underscores the transformative impact LLMs could have on forecasting and anomaly detection while emphasizing the need for continuous innovation, ethical considerations, and practical solutions to realize their full potential.\", 'venue': 'arXiv.org', 'year': 2024, 'referenceCount': 0, 'citationCount': 66, 'influentialCitationCount': 0, 'isOpenAccess': True, 'openAccessPdf': 'https://arxiv.org/pdf/2402.10350', 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle', 'Review'], 'publicationDate': '2024-02-15', 'journal': {'name': 'ArXiv', 'volume': 'abs/2402.10350'}, 'citationStyles': {'bibtex': '@Article{Su2024LargeLM,\\n author = {Jing Su and Chufeng Jiang and Xin Jin and Yuxin Qiao and Tingsong Xiao and Hongda Ma and Rong Wei and Zhi Jing and Jiajun Xu and Junhong Lin},\\n booktitle = {arXiv.org},\\n journal = {ArXiv},\\n title = {Large Language Models for Forecasting and Anomaly Detection: A Systematic Literature Review},\\n volume = {abs/2402.10350},\\n year = {2024}\\n}\\n'}, 'authors': [{'authorId': '2116967910', 'name': 'Jing Su', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '2283937122', 'name': 'Chufeng Jiang', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '2284759893', 'name': 'Xin Jin', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': None, 'name': 'Yuxin Qiao'}, {'authorId': '2284598614', 'name': 'Tingsong Xiao', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '2284731807', 'name': 'Hongda Ma', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '2284594383', 'name': 'Rong Wei', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '15217571', 'name': 'Zhi Jing', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '2284638322', 'name': 'Jiajun Xu', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, {'authorId': '2284641943', 'name': 'Junhong Lin', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}], 'version': '', 'arxivUrl': 'https://arxiv.org/abs/2402.10350', 'arxivId': '2402.10350', 'DOI': '10.48550/arXiv.2402.10350', 'id': '10.48550/arXiv.2402.10350', 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review']}, 'ref_cnt': 1, 'authors_hindex': 10}\n",
      "Large Language Models for Forecasting and Anomaly Detection: A Systematic Literature Review\n",
      "{'type': 'node', 'id': '10.48550/arXiv.2409.04600', 'labels': ['Paper'], 'properties': {'s2PaperId': '65871d16002bb4c2d34f804801cb60f9774140b0', 'externalIds': {'ArXiv': '2409.04600', 'DBLP': 'journals/corr/abs-2409-04600', 'DOI': '10.48550/arXiv.2409.04600', 'CorpusId': 272524543}, 'corpusId': 272524543, 'publicationVenue': {'id': '1901e811-ee72-4b20-8f7e-de08cd395a10', 'name': 'arXiv.org', 'alternate_names': ['ArXiv'], 'issn': '2331-8422', 'url': 'https://arxiv.org'}, 's2Url': 'https://www.semanticscholar.org/paper/65871d16002bb4c2d34f804801cb60f9774140b0', 'title': 'The emergence of Large Language Models (LLM) as a tool in literature reviews: an LLM automated systematic review', 'abstract': 'Objective: This study aims to summarize the usage of Large Language Models (LLMs) in the process of creating a scientific review. We look at the range of stages in a review that can be automated and assess the current state-of-the-art research projects in the field. Materials and Methods: The search was conducted in June 2024 in PubMed, Scopus, Dimensions, and Google Scholar databases by human reviewers. Screening and extraction process took place in Covidence with the help of LLM add-on which uses OpenAI gpt-4o model. ChatGPT was used to clean extracted data and generate code for figures in this manuscript, ChatGPT and Scite.ai were used in drafting all components of the manuscript, except the methods and discussion sections. Results: 3,788 articles were retrieved, and 172 studies were deemed eligible for the final review. ChatGPT and GPT-based LLM emerged as the most dominant architecture for review automation (n=126, 73.2%). A significant number of review automation projects were found, but only a limited number of papers (n=26, 15.1%) were actual reviews that used LLM during their creation. Most citations focused on automation of a particular stage of review, such as Searching for publications (n=60, 34.9%), and Data extraction (n=54, 31.4%). When comparing pooled performance of GPT-based and BERT-based models, the former were better in data extraction with mean precision 83.0% (SD=10.4), and recall 86.0% (SD=9.8), while being slightly less accurate in title and abstract screening stage (Maccuracy=77.3%, SD=13.0). Discussion/Conclusion: Our LLM-assisted systematic review revealed a significant number of research projects related to review automation using LLMs. The results looked promising, and we anticipate that LLMs will change in the near future the way the scientific reviews are conducted.', 'venue': 'arXiv.org', 'year': 2024, 'referenceCount': 0, 'citationCount': 2, 'influentialCitationCount': 0, 'isOpenAccess': True, 'openAccessPdf': 'https://arxiv.org/pdf/2409.04600', 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle', 'Review'], 'publicationDate': '2024-09-06', 'journal': {'name': 'ArXiv', 'volume': 'abs/2409.04600'}, 'citationStyles': {'bibtex': '@Article{Scherbakov2024TheEO,\\n author = {Dmitry Scherbakov and Nina C. Hubig and V. Jansari and Alexander Bakumenko and Leslie A Lenert},\\n booktitle = {arXiv.org},\\n journal = {ArXiv},\\n title = {The emergence of Large Language Models (LLM) as a tool in literature reviews: an LLM automated systematic review},\\n volume = {abs/2409.04600},\\n year = {2024}\\n}\\n'}, 'authors': [{'authorId': '2273913510', 'name': 'Dmitry Scherbakov', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '1999324', 'name': 'Nina C. Hubig', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2007176690', 'name': 'V. Jansari', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2320303855', 'name': 'Alexander Bakumenko', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, {'authorId': '2261910331', 'name': 'Leslie A Lenert', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}], 'version': '', 'arxivUrl': 'https://arxiv.org/abs/2409.04600', 'arxivId': '2409.04600', 'DOI': '10.48550/arXiv.2409.04600', 'id': '10.48550/arXiv.2409.04600', 'source': ['InitialSearch', 'LLMQuery'], 'sourceDesc': ['Search from S2 based on user input', 'LLM automated literature review']}, 'source': ['LLMQuery'], 'sourceDesc': ['LLM automated literature review'], 'ref_cnt': 2, 'authors_hindex': 9}\n",
      "The emergence of Large Language Models (LLM) as a tool in literature reviews: an LLM automated systematic review\n"
     ]
    }
   ],
   "source": [
    "sorted_data_lambda = sorted(papers_info, key=lambda item: item['authors_hindex'], reverse=True)\n",
    "\n",
    "i = 0\n",
    "for item in sorted_data_lambda:\n",
    "    if i < 20:\n",
    "        print(item)\n",
    "        print(item['properties']['title'])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand References for Highly Correlated Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_dois = []\n",
    "for edge in paperbot.edges_json:\n",
    "    if edge['relationshipType'] == 'SIMILAR_TO' and edge['startNodeId'] in init_paper_dois:\n",
    "        if edge['properties']['weight'] > 0.75 and edge['properties']['weight'] < 0.9:\n",
    "            id = edge['startNodeId']\n",
    "            if id not in next_dois:\n",
    "                next_dois.append(edge['startNodeId'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "for paper_doi in next_dois:\n",
    "    paperbot.get_cited_papers(paper_doi) \n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exapnd Key Cited Papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "identify key papers from seed papers' reference list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cited_paper_dois = []\n",
    "\n",
    "next_dois = []\n",
    "for edge in paperbot.edges_json:\n",
    "    if edge['relationshipType'] == 'SIMILAR_TO' and edge['startNodeId'] in init_paper_dois:\n",
    "        if edge['properties']['weight'] > 0.75 and edge['properties']['weight'] < 0.9:\n",
    "            id = edge['startNodeId']\n",
    "            if id not in next_dois:\n",
    "                next_dois.append(edge['startNodeId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dois, filtered_nodes, filtered_relationships = [], [], []\n",
    "\n",
    "# seed paper\n",
    "filtered_dois.extend(init_paper_dois)\n",
    "\n",
    "\n",
    "for node in paperbot.nodes_json:\n",
    "    # reference for seed paper\n",
    "    if node['id'] in init_paper_dois and 'CitedPaper' in node['properties']['source']:\n",
    "        filtered_dois.append(node['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node['properties']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in paperbot.nodes_json:\n",
    "    # reference for seed paper\n",
    "    if node['labels'] == ['Paper'] and 'RecommendedPaper' in node['properties']['source']:\n",
    "        print(node['properties']['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in paperbot.nodes_json:\n",
    "    # reference for seed paper\n",
    "    if node['labels'] == ['Paper'] and node['id'] in init_paper_dois :\n",
    "        print(node['properties']['title'], '\\n', node['properties']['abstract'])\n",
    "        print('-'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai4fun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
