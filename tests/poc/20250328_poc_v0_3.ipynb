{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Tree Interactive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seed dois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_dois = ['10.48550/arXiv.2406.10252',  # AutoSurvey: Large Language Models Can Automatically Write Surveys\n",
    "             '10.48550/arXiv.2412.10415',  # Generative Adversarial Reviews: When LLMs Become the Critic\n",
    "             '10.48550/arXiv.2402.12928',  # A Literature Review of Literature Reviews in Pattern Analysis and Machine Intelligence \n",
    "             '10.48550/arXiv.1905.07870',  # PaperRobot: Incremental Draft Generation of Scientific Ideas\n",
    "             '10.48550/arXiv.2503.01424'   # From Hypothesis to Publication: A Comprehensive Survey of AI-Driven Research Support Systems\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "filename = \"paper_nodes_json.jsonl\"\n",
    "\n",
    "nodes_json = []\n",
    "with open(filename, 'r') as f:\n",
    "    for item in f:\n",
    "        nodes_json.append(json.loads(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "filename = \"paper_edges_json.jsonl\"\n",
    "\n",
    "edges_json = []\n",
    "with open(filename, 'r') as f:\n",
    "    for item in f:\n",
    "        edges_json.append(json.loads(item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load working path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jiezi/Code/GitHub/ResearchTree/src\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "print(parent_dir)\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import toml\n",
    "\n",
    "config_file = \"config.toml\"\n",
    "try:\n",
    "    with open(config_file, 'r', encoding='utf-8') as toml_file:\n",
    "        config_param = toml.load(toml_file)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Config file '{config_file}' not found. Please ensure it exists.\")\n",
    "    config_param = {} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_api_key = config_param.get('models', {}).get('llm', {}).get('api_key')\n",
    "llm_model_name = config_param.get('models', {}).get('llm', {}).get('model_name')\n",
    "embed_api_key = config_param.get('models', {}).get('embed', {}).get('api_key')\n",
    "embed_model_name = config_param.get('models', {}).get('embed', {}).get('model_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citation Tree - Hop 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initially focused only on cites relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Hop 1 Citation Papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get hop 1 citation paper dois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_types = ['CITES']\n",
    "\n",
    "hop_1_dois = []\n",
    "for edge in edges_json:\n",
    "    # seed paper cites other papers\n",
    "    if edge['startNodeId'] in seed_dois and edge['relationshipType'] == 'CITES':\n",
    "        doi = edge['endNodeId']\n",
    "        if doi not in hop_1_dois:\n",
    "            hop_1_dois.append(doi)\n",
    "\n",
    "    # seed paper cited by other papers\n",
    "    elif edge['endNodeId'] in seed_dois and edge['relationshipType'] == 'CITES':\n",
    "        doi = edge['startNodeId']\n",
    "        if doi not in hop_1_dois:\n",
    "            hop_1_dois.append(doi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 210\n"
     ]
    }
   ],
   "source": [
    "print(len(seed_dois), len(hop_1_dois))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10.48550/arXiv.1905.07870', '10.48550/arXiv.2406.10252'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(seed_dois) & set(hop_1_dois)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get hop 1 citation paper metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_paper_metadata, hop_1_paper_metadata =[], []\n",
    "\n",
    "node_ids = [x['id'] for x in nodes_json]\n",
    "\n",
    "for doi in seed_dois:\n",
    "    idx = node_ids.index(doi)\n",
    "    seed_paper_metadata.append(nodes_json[idx])\n",
    "\n",
    "for doi in hop_1_dois:\n",
    "    idx = node_ids.index(doi)\n",
    "    hop_1_paper_metadata.append(nodes_json[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 210\n"
     ]
    }
   ],
   "source": [
    "print(len(seed_paper_metadata), len(hop_1_paper_metadata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find missing abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "paperids_abs_missing = []\n",
    "for item in (seed_paper_metadata + hop_1_paper_metadata):\n",
    "    paper_id = item['properties']['s2PaperId']\n",
    "    abstract = item['properties']['abstract']\n",
    "    if abstract is None and paper_id not in paperids_abs_missing:\n",
    "        paperids_abs_missing.append(paper_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181\n"
     ]
    }
   ],
   "source": [
    "print(len(paperids_abs_missing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search again for papers with missing abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 13:07:03,757 - INFO - HTTP Request: POST https://api.semanticscholar.org/graph/v1/paper/batch?fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear \"HTTP/1.1 429 \"\n",
      "2025-03-28 13:07:34,891 - INFO - HTTP Request: POST https://api.semanticscholar.org/graph/v1/paper/batch?fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear \"HTTP/1.1 429 \"\n",
      "2025-03-28 13:08:06,742 - INFO - HTTP Request: POST https://api.semanticscholar.org/graph/v1/paper/batch?fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear \"HTTP/1.1 200 OK\"\n",
      "2025-03-28 13:08:20,250 - INFO - HTTP Request: POST https://api.semanticscholar.org/graph/v1/paper/batch?fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear \"HTTP/1.1 429 \"\n",
      "2025-03-28 13:08:51,899 - INFO - HTTP Request: POST https://api.semanticscholar.org/graph/v1/paper/batch?fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from apis.s2_api import SemanticScholarKit \n",
    "s2 = SemanticScholarKit()\n",
    "tmp_paper_metadata = s2.search_paper_by_ids(id_list=paperids_abs_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmp_paper_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update papers with abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_paper_dict = {item['paperId']: item['abstract'] for item in tmp_paper_metadata if 'paperId' in item and 'abstract' in item and item['abstract'] is not None}\n",
    "\n",
    "for item in hop_1_paper_metadata:\n",
    "    if 'properties' in item and 's2PaperId' in item['properties'] and item['properties'].get('abstract') is None:\n",
    "        paper_id = item['properties']['s2PaperId']\n",
    "        abstract = tmp_paper_dict.get(paper_id)\n",
    "        if abstract is not None:\n",
    "            item['properties']['abstract'] = abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Similarity of Hop-1 Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_paper_info = {item['id']: f\"{item['properties']['title']}\\n{item['properties']['abstract']}\"\n",
    "                   for item in seed_paper_metadata if item.get('properties', {}).get('title') is not None\n",
    "                     and item.get('properties', {}).get('abstract') is not None}\n",
    "\n",
    "hop_1_paper_info = {item['id']: f\"{item['properties']['title']}\\n{item['properties']['abstract']}\"\n",
    "                   for item in hop_1_paper_metadata if item.get('properties', {}).get('title') is not None\n",
    "                     and item.get('properties', {}).get('abstract') is not None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_texts = [item[1] for item in seed_paper_info.items()]\n",
    "hop_1_texts = [item[1] for item in hop_1_paper_info.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from models.embedding_models import gemini_embedding_async\n",
    "\n",
    "embeds = await gemini_embedding_async(embed_api_key, embed_model_name, seed_texts+hop_1_texts, 10) # Assuming texts_embed_gen is an async function for IO-bound operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(embeds) == len(seed_texts) + len(hop_1_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from models.embedding_models import semantic_similarity_matrix\n",
    "\n",
    "seed_text_embeds = embeds[0:len(seed_texts)]\n",
    "hop_1_text_embeds = embeds[len(seed_texts):]\n",
    "sim_matrix = semantic_similarity_matrix(seed_text_embeds, hop_1_text_embeds)\n",
    "sim_matrix = np.array(sim_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_cnt, col_cnt = sim_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_col_max, sim_col_min, sim_col_avg = [], [], [] \n",
    "for j in range(col_cnt):\n",
    "    col_sim = sim_matrix[:, j]\n",
    "    col_max = col_sim.max() # get colum max\n",
    "    col_min = col_sim.min() # get colum min\n",
    "    col_avg = np.average(col_sim)\n",
    "    sim_col_max.append(col_max)\n",
    "    sim_col_min.append(col_min)\n",
    "    sim_col_avg.append(sim_col_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dict = []\n",
    "for idx, key in enumerate(hop_1_paper_info):\n",
    "    sim_score = sim_col_max[idx]\n",
    "    if sim_score > 0.7:\n",
    "        tmp_dict.append({key:sim_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dict = {key:sim_col_max[idx] for idx, key in enumerate(hop_1_paper_info) if sim_col_max[idx] > 0.7 and sim_col_max[idx] < 0.9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_sorted_items = sorted(tmp_dict.items(), key=lambda item: item[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK! These items could be seen as similar researches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI-Driven Review Systems: Evaluating LLMs in Scalable and Bias-Aware Academic Reviews 0.8214457401590604\n",
      "Automatically Evaluating the Paper Reviewing Capability of Large Language Models 0.8033233477497779\n",
      "ResearchAgent: Iterative Research Idea Generation over Scientific Literature with Large Language Models 0.7848394476347019\n",
      "Is Your Paper Being Reviewed by an LLM? Investigating AI Text Detectability in Peer Review 0.7806782233064347\n",
      "ReviewerGPT? An Exploratory Study on Using Large Language Models for Paper Reviewing 0.778227406526185\n",
      "Peer Review as A Multi-Turn and Long-Context Dialogue with Role-Based Interactions 0.762231407990481\n",
      "Instruct Large Language Models to Generate Scientific Literature Survey Step by Step 0.7609768344004895\n",
      "Can large language models provide useful feedback on research papers? A large-scale empirical analysis 0.7570811958501278\n",
      "CycleResearcher: Improving Automated Research via Automated Review 0.7552594032048701\n",
      "Artificial intelligence to automate the systematic review of scientific literature 0.7545330234756262\n",
      "GPT4 is Slightly Helpful for Peer-Review Assistance: A Pilot Study 0.74741144579407\n",
      "A Survey on Large Language Model based Autonomous Agents 0.7409060687649061\n",
      "The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery 0.7279497775929844\n",
      "LAG: LLM agents for Leaderboard Auto Generation on Demanding 0.7224645156508397\n",
      "A Survey on Evaluation of Large Language Models 0.7166817782249582\n",
      "A Survey of Large Language Models 0.7107352849503522\n",
      "Can Large Language Models Be an Alternative to Human Evaluations? 0.7055714223126198\n"
     ]
    }
   ],
   "source": [
    "tmp_titles = {item['id']: item['properties']['title']\n",
    "              for item in hop_1_paper_metadata if item.get('properties', {}).get('title') is not None}\n",
    "\n",
    "for item in tmp_sorted_items:\n",
    "    doi = item[0]\n",
    "    sim_score = item[1]\n",
    "    title = tmp_titles.get(doi)\n",
    "    print(title, sim_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citation Tree - Hop 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Hop 2 Citation Papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get top-k similar papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "top_k_dois = [x[0] for x in tmp_sorted_items[0:k]]\n",
    "tmp_ref = {item['id']: item['properties']['s2PaperId']\n",
    "              for item in hop_1_paper_metadata if item.get('properties', {}).get('s2PaperId') is not None}\n",
    "top_k_paperids = [tmp_ref.get(x) for x in top_k_dois]\n",
    "print(len(top_k_dois), len(top_k_paperids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['924956d6c788c9ea67ecdc80b63742d74350549e',\n",
       " '987d0cbe751780b9b993ebf8e670fb0d18fdaabe',\n",
       " '51b7b3ad7645a69e3c1c80cae69473b8bd472f67',\n",
       " '94fb5a19f86d81a746bb5502a5debf2659814e8e',\n",
       " '62729cff7dda7614f648a84e8967076d8878a5ff',\n",
       " '2424b7935cee3551deeea4a98b1a07abddf93649',\n",
       " '374d1e5fd7385353a4a0add1fadce23667662265',\n",
       " 'f2209eb5ac6747319a29b87dedabb97770be3243',\n",
       " '92c82a51ad13c361d052987694cf93d6a72d5789',\n",
       " 'f2d23bd0a60f46a5d99475977c2ad507b103eca7']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_paperids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve paper metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "from apis.s2_api import SemanticScholarKit\n",
    "\n",
    "class ParallelSemanticScholar:\n",
    "    def __init__(self):\n",
    "        self.s2 = SemanticScholarKit()\n",
    "        self.ref_infos = []\n",
    "        self.lock = threading.Lock()\n",
    "        self.max_concurrent_requests = 10  # 根据 Semantic Scholar API 的限制调整\n",
    "\n",
    "    def fetch_ref_info(self, paper_id):\n",
    "        try:\n",
    "            ref_paper_info = self.s2.get_s2_cited_papers(paper_id=paper_id)\n",
    "            with self.lock:\n",
    "                self.ref_infos.append(ref_paper_info)\n",
    "            time.sleep(5)  # 保留原始代码中的延迟，如果需要的话\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching info for {paper_id}: {e}\")\n",
    "\n",
    "    def worker(self, paper_id, semaphore):\n",
    "        try:\n",
    "            semaphore.acquire()\n",
    "            self.fetch_ref_info(paper_id)\n",
    "        finally:\n",
    "            semaphore.release()\n",
    "\n",
    "    def get_cited_papers_parallel(self, top_k_paperids):\n",
    "        threads = []\n",
    "        semaphore = threading.Semaphore(self.max_concurrent_requests)\n",
    "        for paper_id in top_k_paperids:\n",
    "            thread = threading.Thread(target=self.worker, args=(paper_id, semaphore))\n",
    "            threads.append(thread)\n",
    "            thread.start()\n",
    "\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "\n",
    "        return self.ref_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 14:32:03,811 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/987d0cbe751780b9b993ebf8e670fb0d18fdaabe/references?fields=contexts%2Cintents%2CcontextsWithIntent%2CisInfluential%2Cabstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=100 \"HTTP/1.1 200 OK\"\n",
      "2025-03-28 14:32:03,818 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/94fb5a19f86d81a746bb5502a5debf2659814e8e/references?fields=contexts%2Cintents%2CcontextsWithIntent%2CisInfluential%2Cabstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=100 \"HTTP/1.1 200 OK\"\n",
      "2025-03-28 14:32:03,846 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/51b7b3ad7645a69e3c1c80cae69473b8bd472f67/references?fields=contexts%2Cintents%2CcontextsWithIntent%2CisInfluential%2Cabstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=100 \"HTTP/1.1 200 OK\"\n",
      "2025-03-28 14:32:03,853 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/374d1e5fd7385353a4a0add1fadce23667662265/references?fields=contexts%2Cintents%2CcontextsWithIntent%2CisInfluential%2Cabstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=100 \"HTTP/1.1 200 OK\"\n",
      "2025-03-28 14:32:03,860 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/924956d6c788c9ea67ecdc80b63742d74350549e/references?fields=contexts%2Cintents%2CcontextsWithIntent%2CisInfluential%2Cabstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=100 \"HTTP/1.1 200 OK\"\n",
      "2025-03-28 14:32:03,949 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/f2d23bd0a60f46a5d99475977c2ad507b103eca7/references?fields=contexts%2Cintents%2CcontextsWithIntent%2CisInfluential%2Cabstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=100 \"HTTP/1.1 200 OK\"\n",
      "2025-03-28 14:32:04,473 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/f2209eb5ac6747319a29b87dedabb97770be3243/references?fields=contexts%2Cintents%2CcontextsWithIntent%2CisInfluential%2Cabstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=100 \"HTTP/1.1 200 OK\"\n",
      "2025-03-28 14:32:09,030 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/2424b7935cee3551deeea4a98b1a07abddf93649/references?fields=contexts%2Cintents%2CcontextsWithIntent%2CisInfluential%2Cabstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=100 \"HTTP/1.1 200 OK\"\n",
      "2025-03-28 14:32:09,138 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/62729cff7dda7614f648a84e8967076d8878a5ff/references?fields=contexts%2Cintents%2CcontextsWithIntent%2CisInfluential%2Cabstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=100 \"HTTP/1.1 200 OK\"\n",
      "2025-03-28 14:32:09,347 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/92c82a51ad13c361d052987694cf93d6a72d5789/references?fields=contexts%2Cintents%2CcontextsWithIntent%2CisInfluential%2Cabstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=100 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved information for 10 papers in 12.99 seconds.\n"
     ]
    }
   ],
   "source": [
    "parallel_s2 = ParallelSemanticScholar()\n",
    "start_time = time.time()\n",
    "ref_infos = parallel_s2.get_cited_papers_parallel(top_k_paperids)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Retrieved information for {len(ref_infos)} papers in {end_time - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Paper Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_2_paper_metadata = []\n",
    "for refs in ref_infos:\n",
    "    for item in refs:\n",
    "        paper = item.get('citedPaper')\n",
    "        hop_2_paper_metadata.append(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "538"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hop_2_paper_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Common Citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_titles = {item['paperId']: item['title']\n",
    "              for item in hop_2_paper_metadata if item.get('title') is not None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "target_key = 'paperId'\n",
    "value_counts = defaultdict(int)\n",
    "\n",
    "for item in hop_2_paper_metadata:\n",
    "    if target_key in item:\n",
    "        value = item[target_key]\n",
    "        value_counts[value] += 1\n",
    "\n",
    "# 按照出现次数从高到低排序\n",
    "sorted_counts = sorted(value_counts.items(), key=lambda item: item[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_1_paper_ids = [item['properties']['s2PaperId'] for item in hop_1_paper_metadata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'paperId' 对应的取值统计 (从高到低排序):\n",
      "GPT-4 Technical Report: 6, In citation: YES\n",
      "The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery: 5, In citation: YES\n",
      "Can large language models provide useful feedback on research papers? A large-scale empirical analysis: 5, In citation: YES\n",
      "GPT4 is Slightly Helpful for Peer-Review Assistance: A Pilot Study: 5, In citation: YES\n",
      "ReviewerGPT? An Exploratory Study on Using Large Language Models for Paper Reviewing: 4, In citation: YES\n",
      "Judging LLM-as-a-judge with MT-Bench and Chatbot Arena: 3, In citation: YES\n",
      "Qwen Technical Report: 3, In citation: NO\n",
      "RoBERTa: A Robustly Optimized BERT Pretraining Approach: 3, In citation: NO\n",
      "Training language models to follow instructions with human feedback: 3, In citation: NO\n",
      "Fighting reviewer fatigue or amplifying bias? Considerations and recommendations for use of ChatGPT and other large language models in scholarly peer review: 3, In citation: NO\n",
      "Investigating Fairness Disparities in Peer Review: A Language Model Enhanced Approach: 3, In citation: NO\n",
      "Challenges, experiments, and computational solutions in peer review: 3, In citation: NO\n",
      "AI-Driven Review Systems: Evaluating LLMs in Scalable and Bias-Aware Academic Reviews: 2, In citation: YES\n",
      "LLMs Assist NLP Researchers: Critique Paper (Meta-)Reviewing: 2, In citation: NO\n",
      "The AI Review Lottery: Widespread AI-Assisted Peer Reviews Boost Paper Scores and Acceptance Rates: 2, In citation: NO\n",
      "LLMs as Meta-Reviewers' Assistants: A Case Study: 2, In citation: NO\n",
      "MARG: Multi-Agent Review Generation for Scientific Papers: 2, In citation: NO\n",
      "Peer review analyze: A novel benchmark resource for computational analysis of peer reviews: 2, In citation: NO\n",
      "Aspect-based Sentiment Analysis of Scientific Reviews: 2, In citation: NO\n",
      "Is LLM a Reliable Reviewer? A Comprehensive Evaluation of LLM on Automatic Paper Reviewing Tasks: 2, In citation: NO\n",
      "Peer Review as A Multi-Turn and Long-Context Dialogue with Role-Based Interactions: 2, In citation: YES\n",
      "Lost in the Middle: How Language Models Use Long Contexts: 2, In citation: YES\n",
      "Is the future of peer review automated?: 2, In citation: NO\n",
      "Predicting Paper Acceptance via Interpretable Decision Sets: 2, In citation: NO\n",
      "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter: 2, In citation: NO\n",
      "The Impact of Large Language Models on Scientific Discovery: a Preliminary Study using GPT-4: 2, In citation: NO\n",
      "Large Language Models for Automated Open-domain Scientific Hypotheses Discovery: 2, In citation: NO\n",
      "Improving Factuality and Reasoning in Language Models through Multiagent Debate: 2, In citation: NO\n",
      "AutoSurvey: Large Language Models Can Automatically Write Surveys: 2, In citation: YES\n",
      "Chain of Thought Prompting Elicits Reasoning in Large Language Models: 2, In citation: YES\n",
      "ROUGE: A Package for Automatic Evaluation of Summaries: 2, In citation: NO\n",
      "Scientific discovery in the age of artificial intelligence: 2, In citation: YES\n",
      "Using Transformer Language Models to Validate Peer-Assigned Essay Scores in Massive Open Online Courses (MOOCs): 2, In citation: NO\n",
      "Emergent Abilities of Large Language Models: 2, In citation: NO\n",
      "Generative Adversarial Reviews: When LLMs Become the Critic: 1, In citation: NO\n",
      "Are We There Yet? Revealing the Risks of Utilizing Large Language Models in Scholarly Peer Review: 1, In citation: NO\n",
      "Evaluating and Enhancing Large Language Models for Novelty Assessment in Scholarly Publications: 1, In citation: NO\n",
      "Automated Focused Feedback Generation for Scientific Writing Assistance: 1, In citation: NO\n",
      "MetaWriter: Exploring the Potential and Perils of AI Writing Support in Scientific Peer Review: 1, In citation: NO\n",
      "The crisis of peer review: Part of the evolution of science: 1, In citation: NO\n",
      "Exploring the potential of ChatGPT in the peer review process: An observational study.: 1, In citation: NO\n",
      "Evaluating Literature Reviews Conducted by Humans Versus ChatGPT: Comparative Study: 1, In citation: NO\n",
      "Summarizing Multiple Documents with Conversational Structure for Meta-Review Generation: 1, In citation: NO\n",
      "Fighting reviewer fatigue or amplifying bias? Considerations and recommendations for use of ChatGPT and other Large Language Models in scholarly peer review: 1, In citation: NO\n",
      "AutoEval Done Right: Using Synthetic Data for Model Evaluation: 1, In citation: NO\n",
      "Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference: 1, In citation: NO\n",
      "Meta-Prompting: Enhancing Language Models with Task-Agnostic Scaffolding: 1, In citation: NO\n",
      "Peer Reviews of Peer Reviews: A Randomized Controlled Trial and Other Experiments: 1, In citation: NO\n",
      "AI model GPT-3 (dis)informs us better than humans: 1, In citation: NO\n",
      "AI-assisted peer review: 1, In citation: NO\n",
      "EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks: 1, In citation: NO\n",
      "Peer reviewers unmasked: largest global survey reveals trends: 1, In citation: NO\n",
      "Blinded with science: Trivial graphs and formulas increase ad persuasiveness and belief in product efficacy: 1, In citation: NO\n",
      "A Clearer Picture: The Contribution of Visuals and Text to Framing Effects: 1, In citation: NO\n",
      "Algorithms for Hyper-Parameter Optimization: 1, In citation: NO\n",
      "Construction and interference in learning from multiple representation: 1, In citation: NO\n",
      "WordNet: A Lexical Database for English: 1, In citation: NO\n",
      "Dual coding theory and the mental lexicon: 1, In citation: NO\n",
      "Chain of Ideas: Revolutionizing Research Via Novel Idea Development with LLM Agents: 1, In citation: NO\n",
      "The ART of LLM Refinement: Ask, Refine, and Trust: 1, In citation: NO\n",
      "Knowledge-Augmented Large Language Models for Personalized Contextual Query Suggestion: 1, In citation: NO\n",
      "We are Who We Cite: Bridges of Influence Between Natural Language Processing and Other Academic Fields: 1, In citation: NO\n",
      "How AI Processing Delays Foster Creativity: Exploring Research Question Co-Creation with an LLM-based Agent: 1, In citation: NO\n",
      "Retrieve-Rewrite-Answer: A KG-to-Text Enhanced LLMs Framework for Knowledge Graph Question Answering: 1, In citation: NO\n",
      "Llama 2: Open Foundation and Fine-Tuned Chat Models: 1, In citation: NO\n",
      "Self-Refine: Iterative Refinement with Self-Feedback: 1, In citation: NO\n",
      "G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment: 1, In citation: NO\n",
      "In-Context Retrieval-Augmented Language Models: 1, In citation: NO\n",
      "REPLUG: Retrieval-Augmented Black-Box Language Models: 1, In citation: NO\n",
      "Generating Sequences by Learning to Self-Correct: 1, In citation: NO\n",
      "Technique for Producing Ideas: 1, In citation: NO\n",
      "A Computational Inflection for Scientific Discovery: 1, In citation: NO\n",
      "Scientific Language Models for Biomedical Knowledge Base Completion: An Empirical Study: 1, In citation: NO\n",
      "AGATHA: Automatic Graph Mining And Transformer based Hypothesis Generation Approach: 1, In citation: NO\n",
      "Scalable Zero-shot Entity Linking with Dense Entity Retrieval: 1, In citation: NO\n",
      "Unsupervised word embeddings capture latent knowledge from materials science literature: 1, In citation: NO\n",
      "Applications of machine learning in drug discovery and development: 1, In citation: NO\n",
      "Over-optimization of academic publishing metrics: observing Goodhart’s Law in action: 1, In citation: NO\n",
      "Literature Based Discovery: Models, methods, and trends: 1, In citation: NO\n",
      "Undiscovered Public Knowledge: 1, In citation: NO\n",
      "A Coefficient of Agreement for Nominal Scales: 1, In citation: NO\n",
      "Knowledge-Augmented Language Model Prompting for Zero-Shot Knowledge Graph Question Answering: 1, In citation: NO\n",
      "Bridger: Toward Bursting Scientific Filter Bubbles and Boosting Innovation via Novel Author Discovery: 1, In citation: NO\n",
      "The Llama 3 Herd of Models: 1, In citation: NO\n",
      "The great detectives: humans versus AI detectors in catching large language model-generated medical writing: 1, In citation: NO\n",
      "What Can Natural Language Processing Do for Peer Review?: 1, In citation: NO\n",
      "Monitoring AI-Modified Content at Scale: A Case Study on the Impact of ChatGPT on AI Conference Peer Reviews: 1, In citation: NO\n",
      "An Empirical Study of AI Generated Text Detection Tools: 1, In citation: NO\n",
      "MAGE: Machine-generated Text Detection in the Wild: 1, In citation: NO\n",
      "GPT detectors are biased against non-native English writers: 1, In citation: NO\n",
      "DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature: 1, In citation: NO\n",
      "How Close is ChatGPT to Human Experts? Comparison Corpus, Evaluation, and Detection: 1, In citation: NO\n",
      "Automatic Detection of Machine Generated Text: A Critical Survey: 1, In citation: NO\n",
      "Authorship Attribution for Neural Text Generation: 1, In citation: NO\n",
      "TweepFake: About detecting deepfake tweets: 1, In citation: NO\n",
      "Longformer: The Long-Document Transformer: 1, In citation: YES\n",
      "Automatic Detection of Generated Text is Easiest when Humans are Fooled: 1, In citation: NO\n",
      "Release Strategies and the Social Impacts of Language Models: 1, In citation: NO\n",
      "Real or Fake? Learning to Discriminate Machine from Human Generated Text: 1, In citation: NO\n",
      "GLTR: Statistical Detection and Visualization of Generated Text: 1, In citation: NO\n",
      "Defending Against Neural Fake News: 1, In citation: NO\n",
      "Bag of Tricks for Efficient Text Classification: 1, In citation: NO\n",
      "Distinguishing Fact from Fiction: A Benchmark Dataset for Identifying Machine-Generated Scientific Papers in the LLM Era.: 1, In citation: NO\n",
      "Navigating the Path of Writing: Outline-guided Text Generation with Large Language Models: 1, In citation: NO\n",
      "Long-context LLMs Struggle with Long In-context Learning: 1, In citation: YES\n",
      "Mapping the Increasing Use of LLMs in Scientific Papers: 1, In citation: NO\n",
      "LooGLE: Can Long-Context Language Models Understand Long Contexts?: 1, In citation: YES\n",
      "Efficient Streaming Language Models with Attention Sinks: 1, In citation: NO\n",
      "LongNet: Scaling Transformers to 1, 000, 000, 000 Tokens: 1, In citation: NO\n",
      "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness: 1, In citation: NO\n",
      "On Interpretability of Artificial Neural Networks: A Survey: 1, In citation: NO\n",
      "The Prompt Report: A Systematic Survey of Prompting Techniques: 1, In citation: NO\n",
      "Overview of the NLPCC2024 Shared Task 6: Scientific Literature Survey Generation: 1, In citation: NO\n",
      "DOC: Improving Long Story Coherence With Detailed Outline Control: 1, In citation: NO\n",
      "Conducting Research Literature Reviews From The Internet To Paper: 1, In citation: NO\n",
      "The Claude 3 Model Family: Opus, Sonnet, Haiku: 1, In citation: NO\n",
      "Automation of systematic literature reviews: A systematic literature review: 1, In citation: NO\n",
      "Machine learning reduced workload with minimal risk of missing studies: development and evaluation of a randomized controlled trial classifier for Cochrane Reviews: 1, In citation: NO\n",
      "Secondary Studies in the Academic Context: A Systematic Mapping and Survey: 1, In citation: NO\n",
      "The semi-automation of title and abstract screening: a retrospective exploration of ways to leverage Abstrackr’s relevance predictions in systematic and rapid reviews: 1, In citation: NO\n",
      "The Concept of System for Automated Scientific Literature Reviews Generation: 1, In citation: NO\n",
      "A comprehensive survey on support vector machine classification: Applications, challenges and trends: 1, In citation: NO\n",
      "Machine learning for screening prioritization in systematic reviews: comparative performance of Abstrackr and EPPI-Reviewer: 1, In citation: NO\n",
      "Toward systematic review automation: a practical guide to using machine learning tools in research synthesis: 1, In citation: NO\n",
      "Usage of automation tools in systematic reviews: 1, In citation: NO\n",
      "Machine learning algorithms for systematic review: reducing workload in a preclinical review of animal studies and reducing human screening error: 1, In citation: NO\n",
      "How do midwives facilitate women to give birth during physiological second stage of labour? A protocol for a systematic review: 1, In citation: NO\n",
      "Improving the conduct of systematic reviews: a process mining perspective.: 1, In citation: NO\n",
      "Discriminating between empirical studies and nonempirical works using automated text classification: 1, In citation: NO\n",
      "Making progress with the automation of systematic reviews: principles of the International Collaboration for the Automation of Systematic Reviews (ICASR): 1, In citation: NO\n",
      "A semi-supervised approach using label propagation to support citation screening: 1, In citation: NO\n",
      "Text mining for search term development in systematic reviewing: A discussion of some methods and challenges: 1, In citation: NO\n",
      "A Machine Learning Approach for Semi-Automated Search and Selection in Literature Studies: 1, In citation: NO\n",
      "FAST2: An intelligent assistant for finding relevant papers: 1, In citation: NO\n",
      "RevManHAL: towards automatic text generation in systematic reviews: 1, In citation: NO\n",
      "Finding better active learners for faster literature reviews: 1, In citation: NO\n",
      "Knowledge extraction for literature review: 1, In citation: NO\n",
      "A critical analysis of studies that address the use of text mining for citation screening in systematic reviews: 1, In citation: NO\n",
      "Data Sampling and Supervised Learning for HIV Literature Screening: 1, In citation: NO\n",
      "A method to support search string building in systematic literature reviews through visual text mining: 1, In citation: NO\n",
      "Using text mining for study identification in systematic reviews: a systematic review of current approaches: 1, In citation: NO\n",
      "Preferred reporting items for systematic review and meta-analysis protocols (PRISMA-P) 2015 statement: 1, In citation: NO\n",
      "Semi-automatic selection of primary studies in systematic literature reviews: is it reasonable?: 1, In citation: NO\n",
      "Systematic Approaches to a Successful Literature Review: 1, In citation: NO\n",
      "Systematic review automation technologies: 1, In citation: NO\n",
      "Systematic approaches to a successful literature review: 1, In citation: NO\n",
      "Automatic text classification to support systematic reviews in medicine: 1, In citation: NO\n",
      "An SVM-based high-quality article classifier for systematic reviews: 1, In citation: NO\n",
      "Tools to Support Systematic Literature Reviews in Software Engineering: A Mapping Study: 1, In citation: NO\n",
      "A systematic review of systematic review process research in software engineering: 1, In citation: NO\n",
      "‘Clustering’ documents automatically to support scoping reviews of research: a case study: 1, In citation: NO\n",
      "Seeing beyond reading: a survey on visual text analytics: 1, In citation: NO\n",
      "A visual analysis approach to validate the selection review of primary studies in systematic reviews: 1, In citation: NO\n",
      "Towards evidence-based ontology for supporting Systematic Literature Review: 1, In citation: NO\n",
      "Deploying an interactive machine learning system in an evidence-based practice center: abstrackr: 1, In citation: NO\n",
      "Formulating the Evidence Based Practice Question: A Review of the Frameworks: 1, In citation: NO\n",
      "Building Systematic Reviews Using Automatic Text Classification Techniques: 1, In citation: NO\n",
      "Cochrane Handbook for Systematic Reviews of Interventions: 1, In citation: NO\n",
      "A new algorithm for reducing the workload of experts in performing systematic reviews: 1, In citation: NO\n",
      "Automatic Question Generation for Literature Review Writing Support: 1, In citation: NO\n",
      "Semi-automating the manual literature search for systematic reviews increases efficiency.: 1, In citation: NO\n",
      "Research Paper: Cross-Topic Learning for Work Prioritization in Systematic Review Creation and Update: 1, In citation: NO\n",
      "The PRISMA Statement for Reporting Systematic Reviews and Meta-Analyses of Studies That Evaluate Health Care Interventions: Explanation and Elaboration: 1, In citation: NO\n",
      "Searching for Studies: 1, In citation: NO\n",
      "Performing systematic literature reviews in software engineering: 1, In citation: NO\n",
      "Reducing workload in systematic review preparation using automated citation classification.: 1, In citation: NO\n",
      "? An Empirical Study of Threats to Replicating SLR Searches: 1, In citation: NO\n",
      "Improving Endpoint Detection to Support Automated Systematic Reviews: 1, In citation: NO\n",
      "Modeling Discriminative Global Inference: 1, In citation: NO\n",
      "Procedures for Performing Systematic Reviews: 1, In citation: NO\n",
      "Experimental evidence on the productivity effects of generative artificial intelligence: 1, In citation: NO\n",
      "Art and the science of generative AI: 1, In citation: NO\n",
      "Comparing Physician and Artificial Intelligence Chatbot Responses to Patient Questions Posted to a Public Social Media Forum.: 1, In citation: NO\n",
      "The Impact of AI on Developer Productivity: Evidence from GitHub Copilot: 1, In citation: NO\n",
      "Performance of ChatGPT on USMLE: Potential for AI-assisted medical education using large language models: 1, In citation: NO\n",
      "Evaluating Human-Language Model Interaction: 1, In citation: NO\n",
      "Women are credited less in science than men: 1, In citation: NO\n",
      "REAL ML: Recognizing, Exploring, and Articulating Limitations of Machine Learning Research: 1, In citation: YES\n",
      "Nature is trialling transparent peer review — the early results are encouraging: 1, In citation: NO\n",
      "Reduced, Reused and Recycled: The Life of a Dataset in Machine Learning Research: 1, In citation: NO\n",
      "A billion-dollar donation: estimating the cost of researchers’ time spent on peer review: 1, In citation: NO\n",
      "Do Datasets Have Politics? Disciplinary Values in Computer Vision Dataset Development: 1, In citation: NO\n",
      "The Values Encoded in Machine Learning Research: 1, In citation: YES\n",
      "Language Models are Few-Shot Learners: 1, In citation: NO\n",
      "An online platform for interactive feedback in biomedical machine learning: 1, In citation: NO\n",
      "Nature will publish peer review reports as a trial: 1, In citation: NO\n",
      "The changing forms and expectations of peer review: 1, In citation: NO\n",
      "Cultural Reproduction and Social Reproduction: 1, In citation: NO\n",
      "Slowed canonical progress in large fields of science: 1, In citation: NO\n",
      "From Little Science to Big Science: 1, In citation: NO\n",
      "Are Ideas Getting Harder to Find?: 1, In citation: NO\n",
      "A Supervised Approach to Extractive Summarisation of Scientific Papers: 1, In citation: NO\n",
      "The Global Burden of Journal Peer Review in the Biomedical Literature: Strong Imbalance in the Collective Enterprise: 1, In citation: NO\n",
      "The prevalence of statistical reporting errors in psychology (1985–2013): 1, In citation: NO\n",
      "A large annotated corpus for learning natural language inference: 1, In citation: NO\n",
      "Household Surveys in Crisis: 1, In citation: NO\n",
      "The publishing delay in scholarly peer-reviewed journals: 1, In citation: NO\n",
      "Dynamic Pooling and Unfolding Recursive Autoencoders for Paraphrase Detection: 1, In citation: NO\n",
      "A Quick Guide to Writing a Solid Peer Review: 1, In citation: NO\n",
      "Latent semantic analysis: 1, In citation: NO\n",
      "Reviewing Peer Review: 1, In citation: NO\n",
      "The Burden of Knowledge and the 'Death of the Renaissance Man': Is Innovation Getting Harder?: 1, In citation: NO\n",
      "LexRank: Graph-based Lexical Centrality as Salience in Text Summarization: 1, In citation: NO\n",
      "TextRank: Bringing Order into Text: 1, In citation: NO\n",
      "The pilot study.: 1, In citation: NO\n",
      "Manuscript Quality before and after Peer Review and Editing at Annals of Internal Medicine: 1, In citation: NO\n",
      "New Methods in Automatic Extracting: 1, In citation: NO\n",
      "The Matthew Effect in Science: 1, In citation: NO\n",
      "The Automatic Creation of Literature Abstracts: 1, In citation: NO\n",
      "Bias in peer review: 1, In citation: NO\n",
      "A Mathematical Theory of Communication: 1, In citation: NO\n",
      "The . Matthew Effect 0 m Science The reward and communication systems of science are considered: 1, In citation: NO\n",
      "Writing Your Report: 1, In citation: NO\n",
      "Little science.: 1, In citation: NO\n",
      "The Matthew effect in science. The reward and communication systems of science are considered.: 1, In citation: NO\n",
      "[How to write a report].: 1, In citation: NO\n",
      "Retrieval Meets Reasoning: Even High-school Textbook Knowledge Benefits Multimodal Reasoning: 1, In citation: NO\n",
      "LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models: 1, In citation: NO\n",
      "Gemma: Open Models Based on Gemini Research and Technology: 1, In citation: NO\n",
      "Learning to Generate Instruction Tuning Datasets for Zero-Shot Task Adaptation: 1, In citation: NO\n",
      "FinBen: A Holistic Financial Benchmark for Large Language Models: 1, In citation: NO\n",
      "Revolutionizing Finance with LLMs: An Overview of Applications and Insights: 1, In citation: NO\n",
      "DeepSeek LLM: Scaling Open-Source Language Models with Longtermism: 1, In citation: NO\n",
      "YUAN 2.0: A Large Language Model with Localized Filtering-based Attention: 1, In citation: NO\n",
      "Boosting the Power of Small Multimodal Reasoning Models to Match Larger Models with Self-Consistency Training: 1, In citation: NO\n",
      "FinGPT: Instruction Tuning Benchmark for Open-Source Large Language Models in Financial Datasets: 1, In citation: NO\n",
      "Baichuan 2: Open Large-scale Language Models: 1, In citation: NO\n",
      "Zhongjing: Enhancing the Chinese Medical Capabilities of Large Language Model through Expert Feedback and Real-world Multi-turn Dialogue: 1, In citation: NO\n",
      "Enhancing Human-like Multi-Modal Reasoning: A New Challenging Dataset and Comprehensive Framework: 1, In citation: NO\n",
      "Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models: 1, In citation: NO\n",
      "Zero is Not Hero Yet: Benchmarking Zero-Shot Performance of LLMs for Financial Tasks: 1, In citation: NO\n",
      "Enhancing Chat Language Models by Scaling High-quality Instructional Conversations: 1, In citation: NO\n",
      "Towards Expert-Level Medical Question Answering with Large Language Models: 1, In citation: NO\n",
      "ChatGPT is a Breakthrough in Science and Education but Fails a Test in Sports and Exercise Psychology: 1, In citation: NO\n",
      "Chinese Open Instruction Generalist: A Preliminary Release: 1, In citation: NO\n",
      "Can ChatGPT be used to generate scientific hypotheses?: 1, In citation: NO\n",
      "The utility of ChatGPT for cancer treatment information: 1, In citation: NO\n",
      "On the Educational Impact of ChatGPT: Is Artificial Intelligence Ready to Obtain a University Degree?: 1, In citation: NO\n",
      "Does Synthetic Data Generation of LLMs Help Clinical Text Mining?: 1, In citation: NO\n",
      "Will Affective Computing Emerge from Foundation Models and General AI? A First Evaluation on ChatGPT: 1, In citation: NO\n",
      "A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT: 1, In citation: YES\n",
      "Unnatural Instructions: Tuning Language Models with (Almost) No Human Labor: 1, In citation: NO\n",
      "ChatGPT: The End of Online Exam Integrity?: 1, In citation: NO\n",
      "MogaNet: Multi-order Gated Aggregation Network: 1, In citation: NO\n",
      "Scaling Instruction-Finetuned Language Models: 1, In citation: NO\n",
      "GLM-130B: An Open Bilingual Pre-trained Model: 1, In citation: NO\n",
      "PiFold: Toward effective and efficient protein inverse folding: 1, In citation: NO\n",
      "What Language Model Architecture and Pretraining Objective Work Best for Zero-Shot Generalization?: 1, In citation: NO\n",
      "PaLM: Scaling Language Modeling with Pathways: 1, In citation: NO\n",
      "Multitask Prompted Training Enables Zero-Shot Task Generalization: 1, In citation: NO\n",
      "Co-learning: Learning from Noisy Labels with Self-supervision: 1, In citation: NO\n",
      "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing: 1, In citation: NO\n",
      "Pre-Trained Models: Past, Present and Future: 1, In citation: NO\n",
      "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity: 1, In citation: NO\n",
      "Scaling Laws for Neural Language Models: 1, In citation: NO\n",
      "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations: 1, In citation: NO\n",
      "PubMedQA: A Dataset for Biomedical Research Question Answering: 1, In citation: NO\n",
      "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding: 1, In citation: NO\n",
      "Attention is All you Need: 1, In citation: NO\n",
      "SQuAD: 100,000+ Questions for Machine Comprehension of Text: 1, In citation: NO\n",
      "Open Scholarship and Peer Review: a Time for Experimentation: 1, In citation: NO\n",
      "METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments: 1, In citation: NO\n",
      "Bleu: a Method for Automatic Evaluation of Machine Translation: 1, In citation: NO\n",
      "Communications: 1, In citation: NO\n",
      "On the Evaluations of ChatGPT and Emotion-enhanced Prompting for Mental Health Analysis: 1, In citation: NO\n",
      "SimVP: Towards Simple yet Powerful Spatiotemporal Predictive Learning: 1, In citation: NO\n",
      "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding: 1, In citation: NO\n",
      "Language Models are Unsupervised Multitask Learners: 1, In citation: NO\n",
      "Voyager: An Open-Ended Embodied Agent with Large Language Models: 1, In citation: NO\n",
      "Large Language Models are Few-Shot Health Learners: 1, In citation: NO\n",
      "LLM-empowered Chatbots for Psychiatrist and Patient Simulation: Application and Evaluation: 1, In citation: NO\n",
      "How Language Model Hallucinations Can Snowball: 1, In citation: NO\n",
      "PaLM 2 Technical Report: 1, In citation: NO\n",
      "Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting: 1, In citation: NO\n",
      "Prompt as Triggers for Backdoor Attack: Examining the Vulnerability in Language Models: 1, In citation: NO\n",
      "Causal Reasoning and Large Language Models: Opening a New Frontier for Causality: 1, In citation: NO\n",
      "A Comprehensive Benchmark Study on Biomedical Text Generation and Mining with ChatGPT: 1, In citation: NO\n",
      "Evaluating Large Language Models in Generating Synthetic HCI Research Data: a Case Study: 1, In citation: NO\n",
      "Can Large Language Models Transform Computational Social Science?: 1, In citation: YES\n",
      "Generative Agents: Interactive Simulacra of Human Behavior: 1, In citation: YES\n",
      "A Gold Standard Dataset for the Reviewer Assignment Problem: 1, In citation: NO\n",
      "Sparks of Artificial General Intelligence: Early experiments with GPT-4: 1, In citation: NO\n",
      "LLaMA: Open and Efficient Foundation Language Models: 1, In citation: YES\n",
      "Not What You've Signed Up For: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection: 1, In citation: NO\n",
      "Large Language Models Fail on Trivial Alterations to Theory-of-Mind Tasks: 1, In citation: NO\n",
      "Large Language Models as Corporate Lobbyists: 1, In citation: NO\n",
      "Training Trajectories of Language Models Across Scales: 1, In citation: NO\n",
      "LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models: 1, In citation: NO\n",
      "How do authors’ perceptions of their papers compare with co-authors’ perceptions and peer-review decisions?: 1, In citation: NO\n",
      "Reflection of Thought: Inversely Eliciting Numerical Reasoning in Language Models via Solving Linear Systems: 1, In citation: NO\n",
      "When to Make Exceptions: Exploring Language Models as Accounts of Human Moral Judgment: 1, In citation: NO\n",
      "Nobel and novice: Author prominence affects peer review: 1, In citation: NO\n",
      "Social Simulacra: Creating Populated Prototypes for Social Computing Systems: 1, In citation: NO\n",
      "A Dataset on Malicious Paper Bidding in Peer Review: 1, In citation: NO\n",
      "Large Language Models are Zero-Shot Reasoners: 1, In citation: NO\n",
      "Revise and Resubmit: An Intertextual Model of Text-based Collaboration in Peer Review: 1, In citation: NO\n",
      "Impact of Pretraining Term Frequencies on Few-Shot Reasoning: 1, In citation: NO\n",
      "Survey of Hallucination in Natural Language Generation: 1, In citation: YES\n",
      "WANLI: Worker and AI Collaboration for Natural Language Inference Dataset Creation: 1, In citation: NO\n",
      "DISAPERE: A Dataset for Discourse Structure in Peer Review Discussions: 1, In citation: NO\n",
      "Want To Reduce Labeling Cost? GPT-3 Can Help: 1, In citation: NO\n",
      "Collusion rings threaten the integrity of computer science research: 1, In citation: NO\n",
      "Generating Datasets with Pretrained Language Models: 1, In citation: NO\n",
      "Can We Automate Scientific Reviewing?: 1, In citation: NO\n",
      "Argument Mining Driven Analysis of Peer-Reviews: 1, In citation: NO\n",
      "Uncovering Latent Biases in Text: Method and Application to Peer Review: 1, In citation: NO\n",
      "ReviewRobot: Explainable Paper Review Generation based on Knowledge Synthesis: 1, In citation: NO\n",
      "Catch Me if I Can: Detecting Strategic Behaviour in Peer Assessment: 1, In citation: NO\n",
      "Large-scale language analysis of peer review reports: 1, In citation: NO\n",
      "Mitigating Manipulation in Peer Review via Randomized Reviewer Assignments: 1, In citation: NO\n",
      "SPECTER: Document-level Representation Learning using Citation-informed Transformers: 1, In citation: YES\n",
      "Distributed peer review enhanced with natural language processing and machine learning: 1, In citation: NO\n",
      "Blog Post: 1, In citation: NO\n",
      "The Myth of Double-Blind Review Revisited: ACL vs. EMNLP: 1, In citation: NO\n",
      "Academic Plagiarism Detection: 1, In citation: NO\n",
      "Simple and Effective Paraphrastic Similarity from Parallel Translations: 1, In citation: NO\n",
      "Paper Matching with Local Fairness Constraints: 1, In citation: NO\n",
      "Argument Mining for Understanding Peer Reviews: 1, In citation: NO\n",
      "Deep Paper Gestalt: 1, In citation: NO\n",
      "Loss Functions, Axioms, and Peer Review: 1, In citation: NO\n",
      "PeerReview4All: Fair and Accurate Reviewer Assignment in Peer Review: 1, In citation: NO\n",
      "A Dataset of Peer Reviews (PeerRead): Collection, Insights and NLP Applications: 1, In citation: NO\n",
      "Reviewer bias in single- versus double-blind peer review: 1, In citation: NO\n",
      "Commensuration Bias in Peer Review: 1, In citation: NO\n",
      "Estimation from Pairwise Comparisons: Sharp Minimax Bounds with Topology Dependence: 1, In citation: NO\n",
      "The Toronto Paper Matching System: An automated paper-reviewer assignment system: 1, In citation: NO\n",
      "What errors do peer reviewers detect, and does training improve their ability to detect them?: 1, In citation: NO\n",
      "Effects of training on quality of peer review: randomised controlled trial: 1, In citation: NO\n",
      "The myth of the double-blind review?: author identification using only citations: 1, In citation: NO\n",
      "Who reviews the reviewers? Feasibility of using a fictitious manuscript to evaluate peer reviewer performance.: 1, In citation: NO\n",
      "Effect on the quality of peer review of blinding reviewers and asking them to sign their reports: a randomized controlled trial.: 1, In citation: NO\n",
      "RANK ANALYSIS OF INCOMPLETE BLOCK DESIGNS THE METHOD OF PAIRED COMPARISONS: 1, In citation: NO\n",
      "Navigating the Grey Area: Expressions of Overconfidence and Uncertainty in Language Models: 1, In citation: NO\n",
      "An Overview of Challenges, Experiments, and Computational Solutions in Peer Review (Extended Version): 1, In citation: NO\n",
      "Citations Beyond Self Citations: Identifying Authors, Affiliations, and Nationalities in Scientific Papers: 1, In citation: NO\n",
      "Individual Choice Behavior: 1, In citation: NO\n",
      "Simulating 500 million years of evolution with a language model: 1, In citation: NO\n",
      "Locking Down the Finetuned LLMs Safety: 1, In citation: NO\n",
      "MOSS: Enabling Code-Driven Evolution and Context Management for AI Agents: 1, In citation: NO\n",
      "Scideator: Human-LLM Scientific Idea Generation Grounded in Research-Paper Facet Recombination: 1, In citation: NO\n",
      "Can LLMs Generate Novel Research Ideas? A Large-Scale Human Study with 100+ NLP Researchers: 1, In citation: NO\n",
      "Generative Verifiers: Reward Modeling as Next-Token Prediction: 1, In citation: NO\n",
      "Collective Predictive Coding as Model of Science: Formalizing Scientific Activities Towards Generative Science: 1, In citation: NO\n",
      "MLR-Copilot: Autonomous Machine Learning Research based on Large Language Models Agents: 1, In citation: NO\n",
      "Analysis of the ICML 2023 Ranking Data: Can Authors' Opinions of Their Own Papers Assist Peer Review in Machine Learning?: 1, In citation: NO\n",
      "Automated Design of Agentic Systems: 1, In citation: NO\n",
      "Qwen2 Technical Report: 1, In citation: NO\n",
      "LoRA-GA: Low-Rank Adaptation with Gradient Approximation: 1, In citation: NO\n",
      "Iterative Length-Regularized Direct Preference Optimization: A Case Study on Improving 7B Language Models to GPT-4 Level: 1, In citation: NO\n",
      "SimPO: Simple Preference Optimization with a Reference-Free Reward: 1, In citation: NO\n",
      "Iterative Reasoning Preference Optimization: 1, In citation: NO\n",
      "ResearchAgent: Iterative Research Idea Generation over Scientific Literature with Large Language Models: 1, In citation: YES\n",
      "Hallucination Detection in Foundation Models for Decision-Making: A Flexible Definition and Review of the State of the Art: 1, In citation: NO\n",
      "Integrated Systems for Computational Scientific Discovery: 1, In citation: NO\n",
      "RewardBench: Evaluating Reward Models for Language Modeling: 1, In citation: NO\n",
      "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context: 1, In citation: NO\n",
      "Vision-Language Models Provide Promptable Representations for Reinforcement Learning: 1, In citation: NO\n",
      "Self-Rewarding Language Models: 1, In citation: NO\n",
      "Iterative Preference Learning from Human Feedback: Bridging Theory and Practice for RLHF under KL-constraint: 1, In citation: NO\n",
      "Mathematical discoveries from program search with large language models: 1, In citation: NO\n",
      "Vision-Language Models as a Source of Rewards: 1, In citation: NO\n",
      "Toward General-Purpose Robots via Foundation Models: A Survey and Meta-Analysis: 1, In citation: NO\n",
      "LiFT: Unsupervised Reinforcement Learning with Foundation Models as Teachers: 1, In citation: NO\n",
      "FoMo Rewards: Can we cast foundation models as reward functions?: 1, In citation: NO\n",
      "Scaling deep learning for materials discovery: 1, In citation: NO\n",
      "CLIP-Motion: Learning Reward Functions for Robotic Actions Using Consecutive Observations: 1, In citation: NO\n",
      "AI for Open Science: A Multi-Agent Perspective for Ethically Translating Data to Knowledge: 1, In citation: NO\n",
      "Vision-Language Models are Zero-Shot Reward Models for Reinforcement Learning: 1, In citation: NO\n",
      "STORM: Efficient Stochastic Transformer based World Models for Reinforcement Learning: 1, In citation: NO\n",
      "Mistral 7B: 1, In citation: NO\n",
      "Fast-DetectGPT: Efficient Zero-Shot Detection of Machine-Generated Text via Conditional Probability Curvature: 1, In citation: NO\n",
      "MLAgentBench: Evaluating Language Agents on Machine Learning Experimentation: 1, In citation: YES\n",
      "LLM Lies: Hallucinations are not Bugs, but Features as Adversarial Examples: 1, In citation: NO\n",
      "Motif: Intrinsic Motivation from Artificial Intelligence Feedback: 1, In citation: NO\n",
      "GAIA-1: A Generative World Model for Autonomous Driving: 1, In citation: NO\n",
      "RLAIF vs. RLHF: Scaling Reinforcement Learning from Human Feedback with AI Feedback: 1, In citation: NO\n",
      "Language Reward Modulation for Pretraining Reinforcement Learning: 1, In citation: NO\n",
      "Predicting Grokking Long Before it Happens: A look into the loss landscape of models which grok: 1, In citation: NO\n",
      "Inverse Scaling: When Bigger Isn't Better: 1, In citation: NO\n",
      "LIV: Language-Image Representations and Rewards for Robotic Control: 1, In citation: NO\n",
      "Bigger, Better, Faster: Human-level Atari with human-level efficiency: 1, In citation: NO\n",
      "Direct Preference Optimization: Your Language Model is Secretly a Reward Model: 1, In citation: NO\n",
      "SciMON: Scientific Inspiration Machines Optimized for Novelty: 1, In citation: YES\n",
      "Evaluating Object Hallucination in Large Vision-Language Models: 1, In citation: NO\n",
      "The Quantization Model of Neural Scaling: 1, In citation: NO\n",
      "Reflexion: language agents with verbal reinforcement learning: 1, In citation: NO\n",
      "Vision-Language Models as Success Detectors: 1, In citation: NO\n",
      "Unifying Grokking and Double Descent: 1, In citation: NO\n",
      "A Toy Model of Universality: Reverse Engineering How Networks Learn Group Operations: 1, In citation: NO\n",
      "Data Selection for Language Models via Importance Resampling: 1, In citation: NO\n",
      "Distilling Internet-Scale Vision-Language Models into Embodied Agents: 1, In citation: NO\n",
      "Mastering Diverse Domains through World Models: 1, In citation: NO\n",
      "Large Language Models are Better Reasoners with Self-Verification: 1, In citation: NO\n",
      "Phenaki: Variable Length Video Generation From Open Domain Textual Description: 1, In citation: NO\n",
      "VIP: Towards Universal Visual Reward and Representation via Value-Implicit Pre-Training: 1, In citation: NO\n",
      "FP8 Quantization: The Power of the Exponent: 1, In citation: NO\n",
      "Beyond neural scaling laws: beating power law scaling via data pruning: 1, In citation: NO\n",
      "The Slingshot Mechanism: An Empirical Study of Adaptive Optimizers and the Grokking Phenomenon: 1, In citation: NO\n",
      "Towards Understanding Grokking: An Effective Theory of Representation Learning: 1, In citation: NO\n",
      "Accelerating materials discovery using artificial intelligence, high performance computing and robotics: 1, In citation: NO\n",
      "Do As I Can, Not As I Say: Grounding Language in Robotic Affordances: 1, In citation: NO\n",
      "R3M: A Universal Visual Representation for Robot Manipulation: 1, In citation: NO\n",
      "TransDreamer: Reinforcement Learning with Transformer World Models: 1, In citation: NO\n",
      "Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets: 1, In citation: NO\n",
      "Procedural Generalization by Planning with Self-Supervised World Models: 1, In citation: NO\n",
      "Teaching Science as a Process, Not a Set of Facts: 1, In citation: NO\n",
      "Vector-quantized Image Modeling with Improved VQGAN: 1, In citation: NO\n",
      "Benchmarking the Spectrum of Agent Capabilities: 1, In citation: NO\n",
      "Mastering Visual Continuous Control: Improved Data-Augmented Reinforcement Learning: 1, In citation: NO\n",
      "Highly accurate protein structure prediction with AlphaFold: 1, In citation: NO\n",
      "LoRA: Low-Rank Adaptation of Large Language Models: 1, In citation: NO\n",
      "Vector Quantized Models for Planning: 1, In citation: NO\n",
      "Learning Transferable Visual Models From Natural Language Supervision: 1, In citation: NO\n",
      "Understanding deep learning (still) requires rethinking generalization: 1, In citation: NO\n",
      "Transformer Feed-Forward Layers Are Key-Value Memories: 1, In citation: NO\n",
      "Taming Transformers for High-Resolution Image Synthesis: 1, In citation: NO\n",
      "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale: 1, In citation: YES\n",
      "Mastering Atari with Discrete World Models: 1, In citation: NO\n",
      "Data-Efficient Reinforcement Learning with Self-Predictive Representations: 1, In citation: NO\n",
      "DeepSpeed: System Optimizations Enable Training Deep Learning Models with Over 100 Billion Parameters: 1, In citation: NO\n"
     ]
    }
   ],
   "source": [
    "print(f\"'{target_key}' 对应的取值统计 (从高到低排序):\")\n",
    "for paper_id, count in sorted_counts:\n",
    "    if paper_id is not None:\n",
    "        title = tmp_titles.get(paper_id)\n",
    "        in_seed_citation = 'YES' if paper_id in hop_1_paper_ids else 'NO'\n",
    "        print(f\"{title}: {count}, In citation: {in_seed_citation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai4fun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
